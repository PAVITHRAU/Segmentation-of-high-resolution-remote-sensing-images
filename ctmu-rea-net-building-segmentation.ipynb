{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import cv2\n",
    "from skimage.io import imsave, imread, imshow\n",
    "from skimage import color\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from tensorflow.keras.metrics import MeanIoU, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T06:48:07.484322Z",
     "iopub.status.busy": "2024-02-16T06:48:07.483907Z",
     "iopub.status.idle": "2024-02-16T06:48:07.492944Z",
     "shell.execute_reply": "2024-02-16T06:48:07.490858Z",
     "shell.execute_reply.started": "2024-02-16T06:48:07.484271Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T06:48:09.084979Z",
     "iopub.status.busy": "2024-02-16T06:48:09.084641Z",
     "iopub.status.idle": "2024-02-16T06:48:09.090989Z",
     "shell.execute_reply": "2024-02-16T06:48:09.089919Z",
     "shell.execute_reply.started": "2024-02-16T06:48:09.084953Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-02-12T05:40:37.86988Z",
     "iopub.status.busy": "2024-02-12T05:40:37.869476Z",
     "iopub.status.idle": "2024-02-12T05:40:37.877678Z",
     "shell.execute_reply": "2024-02-12T05:40:37.876678Z",
     "shell.execute_reply.started": "2024-02-12T05:40:37.86985Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def extract_padded_patches(image, patch_size=(512, 512)):\n",
    "#     height, width = image.shape[:2]\n",
    "#     patch_height, patch_width = patch_size\n",
    "\n",
    "#     num_patches_y = (height + patch_height - 1) // patch_height\n",
    "#     num_patches_x = (width + patch_width - 1) // patch_width\n",
    "\n",
    "#     # Calculate padding\n",
    "#     pad_y = num_patches_y * patch_height - height\n",
    "#     pad_x = num_patches_x * patch_width - width\n",
    "\n",
    "#     # Pad the image\n",
    "#     padded_image = np.pad(image, ((0, pad_y), (0, pad_x), (0, 0)), mode='constant')\n",
    "#     #print(padded_image.shape)\n",
    "    \n",
    "#     # Extract patches\n",
    "#     patches = []\n",
    "\n",
    "#     for y in range(0, num_patches_y * patch_height, patch_height):\n",
    "#         for x in range(0, num_patches_x * patch_width, patch_width):\n",
    "#             patch = padded_image[y:y+patch_height, x:x+patch_width]\n",
    "#             #plt.imshow(patch/255)\n",
    "#             patches.append(patch)\n",
    "\n",
    "#     return np.array(patches)\n",
    "\n",
    "# #load the .npz file\n",
    "# def load_images(path,name, labels):\n",
    "#     npzfile=np.load(path+\"{}.npz\".format(name))\n",
    "#     images=npzfile['arr_0']\n",
    "#     #patches_image=np.zeros()\n",
    "#     images =[extract_padded_patches(image, (512, 512)) for image in images]\n",
    "#     images = [patch for patches in images for patch in patches]\n",
    "\n",
    "\n",
    "#     npzfile=np.load(path+\"{}.npz\".format(labels))\n",
    "#     labels=npzfile['arr_0']\n",
    "#     #labels=[color.rgb2gray(resize(x,(512,512),mode='constant', preserve_range=True)) for x in labels]\n",
    "    \n",
    "#     labels =[extract_padded_patches(image, (512, 512)) for image in labels]\n",
    "#     labels = [patch for patches in labels for patch in patches]\n",
    "#     labels = np.array(labels)\n",
    "#     labels=[cv2.threshold(color.rgb2gray(gt), 128, 1, cv2.THRESH_BINARY)[1] for gt in labels]\n",
    "    \n",
    "#     return np.array(images),  np.reshape(np.array(labels), (-1, 512, 512, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:40:14.232448Z",
     "iopub.status.busy": "2024-01-19T04:40:14.231441Z",
     "iopub.status.idle": "2024-01-19T04:40:14.236668Z",
     "shell.execute_reply": "2024-01-19T04:40:14.235671Z",
     "shell.execute_reply.started": "2024-01-19T04:40:14.232397Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assume 'patches' is a list of images obtained from extract_padded_patches function\n",
    "\n",
    "# # Create a figure with subplots\n",
    "# fig, axs = plt.subplots(1, len(patches), figsize=(15, 5))\n",
    "\n",
    "# # Iterate through patches and display them\n",
    "# for i, patch in enumerate(patches):\n",
    "#     axs[i].imshow(patch/255)\n",
    "#     axs[i].axis('off')\n",
    "#     axs[i].set_title(f'Patch {i + 1}')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T06:57:25.744355Z",
     "iopub.status.busy": "2024-02-16T06:57:25.743991Z",
     "iopub.status.idle": "2024-02-16T06:57:25.750685Z",
     "shell.execute_reply": "2024-02-16T06:57:25.74948Z",
     "shell.execute_reply.started": "2024-02-16T06:57:25.744325Z"
    }
   },
   "outputs": [],
   "source": [
    "#load the .npz file\n",
    "def load_images(path, name, labels):\n",
    "    npzfile=np.load(path+\"{}.npz\".format(name))\n",
    "    images=npzfile['arr_0']\n",
    "\n",
    "\n",
    "    npzfile=np.load(path+\"{}.npz\".format(labels))\n",
    "    labels=npzfile['arr_0']\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T06:57:26.109201Z",
     "iopub.status.busy": "2024-02-16T06:57:26.10864Z",
     "iopub.status.idle": "2024-02-16T06:59:41.337515Z",
     "shell.execute_reply": "2024-02-16T06:59:41.334438Z",
     "shell.execute_reply.started": "2024-02-16T06:57:26.109155Z"
    }
   },
   "outputs": [],
   "source": [
    "path='/kaggle/input/building-dataset/'\n",
    "\n",
    "\n",
    "\n",
    "x_train,y_train = load_images(path,'train','train_labels')\n",
    "\n",
    "\n",
    "x_val,y_val = load_images(path,'val','val_labels')\n",
    "\n",
    "\n",
    "x_test,y_test = load_images(path,'test','test_labels')\n",
    "\n",
    "\n",
    "x_train.sort()\n",
    "y_train.sort()\n",
    "\n",
    "x_val.sort()\n",
    "y_val.sort()\n",
    "\n",
    "x_test.sort()\n",
    "y_test.sort()\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test,shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T06:59:41.338795Z",
     "iopub.status.idle": "2024-02-16T06:59:41.339302Z",
     "shell.execute_reply": "2024-02-16T06:59:41.339073Z",
     "shell.execute_reply.started": "2024-02-16T06:59:41.339049Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np \n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "train_gen = DataGenerator(x_train, y_train, 4)\n",
    "val_gen = DataGenerator(x_val, y_val, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T06:59:41.347425Z",
     "iopub.status.idle": "2024-02-16T06:59:41.347725Z",
     "shell.execute_reply": "2024-02-16T06:59:41.347602Z",
     "shell.execute_reply.started": "2024-02-16T06:59:41.347588Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "fig.figsize = (30,30)\n",
    "\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.imshow(np.reshape(y_train[2]/255,(512,512)),cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title(\"Ground-truth\")\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.imshow(x_train[2]/255)\n",
    "plt.axis('off')\n",
    "plt.title(\"Actual image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T06:59:41.341033Z",
     "iopub.status.idle": "2024-02-16T06:59:41.341384Z",
     "shell.execute_reply": "2024-02-16T06:59:41.341211Z",
     "shell.execute_reply.started": "2024-02-16T06:59:41.341195Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + 0.5 * dice_loss(tf.cast(y_true, tf.float32), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T06:59:41.342247Z",
     "iopub.status.idle": "2024-02-16T06:59:41.342592Z",
     "shell.execute_reply": "2024-02-16T06:59:41.342458Z",
     "shell.execute_reply.started": "2024-02-16T06:59:41.342443Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_callbacks():\n",
    "    # Reduce learning rate on plateau\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        cooldown=1,\n",
    "        min_delta=0.0001\n",
    "    )\n",
    "\n",
    "    # Early stopping\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.0001,\n",
    "        patience=30,\n",
    "        verbose=1,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Model checkpoint\n",
    "    # Define the path using os.path.join for cross-platform compatibility\n",
    "    check_path = os.path.join('.', 'dpp_building.h5')\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        check_path,\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    return [reduce_lr, early_stop, checkpoint]\n",
    "\n",
    "# Usage example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T06:59:41.344498Z",
     "iopub.status.idle": "2024-02-16T06:59:41.34503Z",
     "shell.execute_reply": "2024-02-16T06:59:41.344888Z",
     "shell.execute_reply.started": "2024-02-16T06:59:41.344872Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    # Accuracy plot\n",
    "    plt.plot(history.history['accuracy'], label='train_acc')\n",
    "    plt.plot(history.history['val_accuracy'], '--', label='val_acc')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"No. of epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "    # Loss plot\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], '--', label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"No. of epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T06:59:41.345966Z",
     "iopub.status.idle": "2024-02-16T06:59:41.346259Z",
     "shell.execute_reply": "2024-02-16T06:59:41.346132Z",
     "shell.execute_reply.started": "2024-02-16T06:59:41.346119Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score, precision_score, recall_score\n",
    "\n",
    "def get_dice(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred, axis=(0, 1, 2))\n",
    "    union = np.sum(y_true**2, axis=(0, 1, 2)) + np.sum(y_pred**2, axis=(0, 1, 2))\n",
    "    dc = 2 * intersection / union\n",
    "    return dc\n",
    "\n",
    "\n",
    "def evaluate_segmentation(y_test, y_pred):\n",
    "    # Mean Intersection over Union\n",
    "    mean_iou = MeanIoU(2)\n",
    "    mean_iou.update_state(y_test, y_pred)\n",
    "    class_iou = mean_iou.result().numpy()\n",
    "    mean_iou.reset_states()\n",
    "    \n",
    "    # Accuracy\n",
    "    acc = Accuracy()\n",
    "    acc.update_state(y_test, y_pred)\n",
    "    accuracy = acc.result().numpy()\n",
    "    acc.reset_states()\n",
    "    \n",
    "    # Precision\n",
    "    precision = precision_score(y_test.ravel(), y_pred.ravel(), average='binary')\n",
    "    \n",
    "    # Recall\n",
    "    recall = recall_score(y_test.ravel(), y_pred.ravel(), average='binary')\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test.ravel(), y_pred.ravel())\n",
    "    \n",
    "    # Classification Report\n",
    "    cr = classification_report(y_test.ravel(), y_pred.ravel())\n",
    "    \n",
    "    # Cohen's Kappa Score\n",
    "    kappa = cohen_kappa_score(y_test.ravel(), y_pred.ravel())\n",
    "    \n",
    "    # Dice Coefficient\n",
    "    dice_coeff = get_dice(y_test, y_pred)\n",
    "    mean_dice_coeff = np.mean(dice_coeff)\n",
    "    \n",
    "    return {\n",
    "        \"mean_iou\": mean_iou,\n",
    "        \"class_iou\": class_iou,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"classification_report\": cr,\n",
    "        \"cohen_kappa_score\": kappa,\n",
    "        \"dice_coefficient\": dice_coeff,\n",
    "        \"mean_dice_coefficient\": mean_dice_coeff\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T07:03:11.317195Z",
     "iopub.status.busy": "2024-02-16T07:03:11.316672Z",
     "iopub.status.idle": "2024-02-16T07:03:11.327892Z",
     "shell.execute_reply": "2024-02-16T07:03:11.326703Z",
     "shell.execute_reply.started": "2024-02-16T07:03:11.317144Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_predictions(x_test, y_test, y_pred, num_samples=10):\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Plot input image\n",
    "        ax = fig.add_subplot(num_samples, 3, 3*i+1)\n",
    "        ax.imshow(np.reshape(x_test[i], (512, 512)), cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Input image\")\n",
    "\n",
    "        # Plot ground truth\n",
    "        ax = fig.add_subplot(num_samples, 3, 3*i+2)\n",
    "        ax.imshow(np.reshape(y_test[i], (512, 512)), cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Ground-truth\")\n",
    "\n",
    "        # Plot predicted image\n",
    "        ax = fig.add_subplot(num_samples, 3, 3*i+3)\n",
    "        ax.imshow(np.reshape(y_pred[i], (512, 512)), cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Predicted image\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CTMU_Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class LipPooling(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters=1):\n",
    "        super(LipPooling, self).__init__()\n",
    "        self.conv1=tf.keras.layers.Conv2D(filters, 3, padding='valid')\n",
    "        self.batch_norm=tf.keras.layers.BatchNormalization()\n",
    "        self.window_size=(3,3)\n",
    "    def call(inputs):\n",
    "        x=self.conv1(inputs)\n",
    "        x=self.batch_norm(x)\n",
    "        x=tf.keras.activations.sigmoid(x)\n",
    "        e_x=tf.keras.activations.exponential(x)\n",
    "        m_x= inputs*e_x\n",
    "        e_x=tf.nn.pool(e_x, self.window_size, pooling_type='SUM', padding='VALID')\n",
    "        m_x=tf.nn.pool(m_x, self.window_size, pooling_type='SUM', padding='VALID')\n",
    "        x=tf.divide(m_x, e_x+1e-8)\n",
    "\n",
    "        return x      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_attention(input_feature, ratio=8):\n",
    "\t\n",
    "\tchannel_axis = -1\n",
    "\tchannel = input_feature._keras_shape[channel_axis]\n",
    "\t\n",
    "\tshared_layer_one = Dense(channel//ratio,\n",
    "\t\t\t\t\t\t\t activation='relu',\n",
    "\t\t\t\t\t\t\t kernel_initializer='he_normal',\n",
    "\t\t\t\t\t\t\t use_bias=True,\n",
    "\t\t\t\t\t\t\t bias_initializer='zeros')\n",
    "\tshared_layer_two = Dense(channel,\n",
    "\t\t\t\t\t\t\t kernel_initializer='he_normal',\n",
    "\t\t\t\t\t\t\t use_bias=True,\n",
    "\t\t\t\t\t\t\t bias_initializer='zeros')\n",
    "\t\n",
    "\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n",
    "\tavg_pool = Reshape((1,1,channel))(avg_pool)\n",
    "\tassert avg_pool._keras_shape[1:] == (1,1,channel)\n",
    "\tavg_pool = shared_layer_one(avg_pool)\n",
    "\tassert avg_pool._keras_shape[1:] == (1,1,channel//ratio)\n",
    "\tavg_pool = shared_layer_two(avg_pool)\n",
    "\tassert avg_pool._keras_shape[1:] == (1,1,channel)\n",
    "\t\n",
    "\tmax_pool = GlobalMaxPooling2D()(input_feature)\n",
    "\tmax_pool = Reshape((1,1,channel))(max_pool)\n",
    "\tassert max_pool._keras_shape[1:] == (1,1,channel)\n",
    "\tmax_pool = shared_layer_one(max_pool)\n",
    "\tassert max_pool._keras_shape[1:] == (1,1,channel//ratio)\n",
    "\tmax_pool = shared_layer_two(max_pool)\n",
    "\tassert max_pool._keras_shape[1:] == (1,1,channel)\n",
    "\t\n",
    "\tcbam_feature = Add()([avg_pool,max_pool])\n",
    "\tcbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\t\n",
    "\t# if K.image_data_format() == \"channels_first\":\n",
    "\t# \tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\t\n",
    "\treturn multiply([input_feature, cbam_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CTM module\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_row_attention(q, k, f):\n",
    "  \"\"\"\n",
    "  Calculates row attention based on Q, K, and F feature maps.\n",
    "\n",
    "  Args:\n",
    "    q: A tensor of shape (batch_size, height, width, reduced_channels).\n",
    "    k: A tensor of the same shape as q.\n",
    "    f: A tensor of shape (batch_size, height, width, channels).\n",
    "\n",
    "  Returns:\n",
    "    A tensor of shape (batch_size, height, width, channels).\n",
    "  \"\"\"\n",
    "  \n",
    "  # Get dimensions\n",
    "  batch_size, height, width, reduced_channels = q.shape\n",
    "  channels = f.shape[-1]\n",
    "\n",
    "  # Calculate correlations\n",
    "  correlations = tf.matmul(q, tf.transpose(k))  # (batch_size, H, W, H)\n",
    "  correlations = tf.nn.softmax(correlations, axis=-1)  # (batch_size, H, W, H)\n",
    "\n",
    "  # Generate V feature map\n",
    "  v = tf.keras.layers.Conv2D(channels, kernel_size=1, activation=None, padding='same')(f)\n",
    "\n",
    "  # Calculate row attention scores\n",
    "  row_attention = []\n",
    "  for i in range(height):\n",
    "    # Extract relevant feature vectors for row i\n",
    "    qi = q[:, i, :, :]  # (batch_size, 1, W, reduced_channels)\n",
    "    ki = k[:, i, :, :]  # (batch_size, W, reduced_channels)\n",
    "    vi = v[:, i, :, :]  # (batch_size, 1, W, channels)\n",
    "    phi_i = k[:, :, i, :]  # (batch_size, W, channels)\n",
    "\n",
    "    # Calculate attention for row i\n",
    "    row_i_attention = tf.reduce_sum(correlations[:, i, :, :] * phi_i, axis=1) + vi\n",
    "    row_attention.append(row_i_attention)\n",
    "  row_attention = tf.stack(row_attention, axis=1)  # (batch_size, H, W, channels)\n",
    "\n",
    "  return row_attention\n",
    "\n",
    "# # Example usage (assuming Q, K, and F are defined elsewhere)\n",
    "# row_attention = get_row_attention(q, k, f)\n",
    "# print(f\"Row attention shape: {row_attention.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_column_attention(yrow, q, k, f):\n",
    "  \"\"\"\n",
    "  Calculates column attention based on Yrow, Q, K, and F feature maps.\n",
    "\n",
    "  Args:\n",
    "    yrow: A tensor of shape (batch_size, height, width, channels).\n",
    "    q: A tensor of the same shape as yrow.\n",
    "    k: A tensor of the same shape as q.\n",
    "    f: A tensor of shape (batch_size, height, width, channels).\n",
    "\n",
    "  Returns:\n",
    "    A tensor of shape (batch_size, height, width, channels).\n",
    "  \"\"\"\n",
    "  \n",
    "  # Get dimensions\n",
    "  batch_size, height, width, channels = yrow.shape\n",
    "\n",
    "  # Calculate correlations\n",
    "  correlations = tf.matmul(yrow, tf.transpose(k, perm=[0, 2, 1, 3]))  # (batch_size, H, W, C)\n",
    "  correlations = tf.nn.softmax(correlations, axis=-1)  # (batch_size, H, W, C)\n",
    "\n",
    "  # Calculate column attention scores\n",
    "  column_attention = []\n",
    "  for i in range(width):\n",
    "    # Extract relevant feature vectors for column i\n",
    "    yrow_i = yrow[:, :, i, :]  # (batch_size, H, 1, channels)\n",
    "    ki = k[:, :, i, :]  # (batch_size, H, channels)\n",
    "    fi = f[:, :, i, :]  # (batch_size, H, 1, channels)\n",
    "    phi_col_i = k[:, :, :, i]  # (batch_size, H, channels)\n",
    "\n",
    "    # Calculate attention for column i\n",
    "    col_i_attention = tf.reduce_sum(correlations[:, :, i, :] * phi_col_i, axis=-1) + fi\n",
    "    column_attention.append(col_i_attention)\n",
    "  column_attention = tf.stack(column_attention, axis=2)  # (batch_size, H, W, channels)\n",
    "\n",
    "  return column_attention\n",
    "\n",
    "# # Example usage (assuming Yrow, Q, K, and F are defined elsewhere)\n",
    "# column_attention = get_column_attention(yrow, q, k, f)\n",
    "# print(f\"Column attention shape: {column_attention.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"tf.linalg.matmul_9\" (type TFOpLambda).\n\nDimensions must be equal, but are 16 and 512 for '{{node tf.linalg.matmul_9/MatMul}} = BatchMatMulV2[T=DT_FLOAT, adj_x=false, adj_y=false](Placeholder, Placeholder_1)' with input shapes: [?,512,512,16], [16,512,512,?].\n\nCall arguments received:\n  • a=tf.Tensor(shape=(None, 512, 512, 16), dtype=float32)\n  • b=tf.Tensor(shape=(16, 512, 512, None), dtype=float32)\n  • transpose_a=False\n  • transpose_b=False\n  • adjoint_a=False\n  • adjoint_b=False\n  • a_is_sparse=False\n  • b_is_sparse=False\n  • output_type=None\n  • name=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m k\u001b[38;5;241m=\u001b[39mq\n\u001b[0;32m      8\u001b[0m f\u001b[38;5;241m=\u001b[39mx\n\u001b[1;32m----> 9\u001b[0m yrow\u001b[38;5;241m=\u001b[39m \u001b[43mget_row_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# column attention\u001b[39;00m\n\u001b[0;32m     11\u001b[0m q\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(yrow)\n",
      "Cell \u001b[1;32mIn[38], line 23\u001b[0m, in \u001b[0;36mget_row_attention\u001b[1;34m(q, k, f)\u001b[0m\n\u001b[0;32m     20\u001b[0m channels \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate correlations\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m correlations \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, H, W, H)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m correlations \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(correlations, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (batch_size, H, W, H)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Generate V feature map\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pavithra\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pavithra\\lib\\site-packages\\keras\\layers\\core\\tf_op_layer.py:107\u001b[0m, in \u001b[0;36mKerasOpDispatcher.handle\u001b[1;34m(self, op, args, kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Handle the specified operation with the specified arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(x, keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor)\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten([args, kwargs])):\n\u001b[1;32m--> 107\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m TFOpLambda(op)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNOT_SUPPORTED\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pavithra\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"tf.linalg.matmul_9\" (type TFOpLambda).\n\nDimensions must be equal, but are 16 and 512 for '{{node tf.linalg.matmul_9/MatMul}} = BatchMatMulV2[T=DT_FLOAT, adj_x=false, adj_y=false](Placeholder, Placeholder_1)' with input shapes: [?,512,512,16], [16,512,512,?].\n\nCall arguments received:\n  • a=tf.Tensor(shape=(None, 512, 512, 16), dtype=float32)\n  • b=tf.Tensor(shape=(16, 512, 512, None), dtype=float32)\n  • transpose_a=False\n  • transpose_b=False\n  • adjoint_a=False\n  • adjoint_b=False\n  • a_is_sparse=False\n  • b_is_sparse=False\n  • output_type=None\n  • name=None"
     ]
    }
   ],
   "source": [
    "input_shape = (4, 512, 512, 3)\n",
    "inputs= tf.keras.Input(shape=(512, 512, 3))\n",
    "# row attention\n",
    "x=tf.keras.layers.Conv2D(16,1, activation='relu', padding='same',input_shape=input_shape[1:])(inputs)\n",
    "\n",
    "q=tf.keras.layers.Conv2D(16,1, activation='relu', padding='same')(x)\n",
    "k=q\n",
    "f=x\n",
    "yrow= get_row_attention(q,k,f)\n",
    "# column attention\n",
    "q=tf.keras.layers.Conv2D(512,1, activation='relu', padding='same')(yrow)\n",
    "k=q\n",
    "f=yrow\n",
    "output= get_column_attention(yrow,q,k,f)\n",
    "\n",
    "model=tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdilation_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muse_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'glorot_uniform'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbias_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'zeros'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbias_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbias_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "2D convolution layer (e.g. spatial convolution over images).\n",
       "\n",
       "This layer creates a convolution kernel that is convolved\n",
       "with the layer input to produce a tensor of\n",
       "outputs. If `use_bias` is True,\n",
       "a bias vector is created and added to the outputs. Finally, if\n",
       "`activation` is not `None`, it is applied to the outputs as well.\n",
       "\n",
       "When using this layer as the first layer in a model,\n",
       "provide the keyword argument `input_shape`\n",
       "(tuple of integers or `None`, does not include the sample axis),\n",
       "e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
       "in `data_format=\"channels_last\"`. You can use `None` when\n",
       "a dimension has variable size.\n",
       "\n",
       "Examples:\n",
       "\n",
       ">>> # The inputs are 28x28 RGB images with `channels_last` and the batch\n",
       ">>> # size is 4.\n",
       ">>> input_shape = (4, 28, 28, 3)\n",
       ">>> x = tf.random.normal(input_shape)\n",
       ">>> y = tf.keras.layers.Conv2D(\n",
       "... 2, 3, activation='relu', input_shape=input_shape[1:])(x)\n",
       ">>> print(y.shape)\n",
       "(4, 26, 26, 2)\n",
       "\n",
       ">>> # With `dilation_rate` as 2.\n",
       ">>> input_shape = (4, 28, 28, 3)\n",
       ">>> x = tf.random.normal(input_shape)\n",
       ">>> y = tf.keras.layers.Conv2D(\n",
       "... 2, 3, activation='relu', dilation_rate=2, input_shape=input_shape[1:])(x)\n",
       ">>> print(y.shape)\n",
       "(4, 24, 24, 2)\n",
       "\n",
       ">>> # With `padding` as \"same\".\n",
       ">>> input_shape = (4, 28, 28, 3)\n",
       ">>> x = tf.random.normal(input_shape)\n",
       ">>> y = tf.keras.layers.Conv2D(\n",
       "... 2, 3, activation='relu', padding=\"same\", input_shape=input_shape[1:])(x)\n",
       ">>> print(y.shape)\n",
       "(4, 28, 28, 2)\n",
       "\n",
       ">>> # With extended batch shape [4, 7]:\n",
       ">>> input_shape = (4, 7, 28, 28, 3)\n",
       ">>> x = tf.random.normal(input_shape)\n",
       ">>> y = tf.keras.layers.Conv2D(\n",
       "... 2, 3, activation='relu', input_shape=input_shape[2:])(x)\n",
       ">>> print(y.shape)\n",
       "(4, 7, 26, 26, 2)\n",
       "\n",
       "\n",
       "Args:\n",
       "  filters: Integer, the dimensionality of the output space (i.e. the number of\n",
       "    output filters in the convolution).\n",
       "  kernel_size: An integer or tuple/list of 2 integers, specifying the height\n",
       "    and width of the 2D convolution window. Can be a single integer to specify\n",
       "    the same value for all spatial dimensions.\n",
       "  strides: An integer or tuple/list of 2 integers, specifying the strides of\n",
       "    the convolution along the height and width. Can be a single integer to\n",
       "    specify the same value for all spatial dimensions. Specifying any stride\n",
       "    value != 1 is incompatible with specifying any `dilation_rate` value != 1.\n",
       "  padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
       "    `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n",
       "    to the left/right or up/down of the input. When `padding=\"same\"` and\n",
       "    `strides=1`, the output has the same size as the input.\n",
       "  data_format: A string, one of `channels_last` (default) or `channels_first`.\n",
       "    The ordering of the dimensions in the inputs. `channels_last` corresponds\n",
       "    to inputs with shape `(batch_size, height, width, channels)` while\n",
       "    `channels_first` corresponds to inputs with shape `(batch_size, channels,\n",
       "    height, width)`. It defaults to the `image_data_format` value found in\n",
       "    your Keras config file at `~/.keras/keras.json`. If you never set it, then\n",
       "    it will be `channels_last`.\n",
       "  dilation_rate: an integer or tuple/list of 2 integers, specifying the\n",
       "    dilation rate to use for dilated convolution. Can be a single integer to\n",
       "    specify the same value for all spatial dimensions. Currently, specifying\n",
       "    any `dilation_rate` value != 1 is incompatible with specifying any stride\n",
       "    value != 1.\n",
       "  groups: A positive integer specifying the number of groups in which the\n",
       "    input is split along the channel axis. Each group is convolved separately\n",
       "    with `filters / groups` filters. The output is the concatenation of all\n",
       "    the `groups` results along the channel axis. Input channels and `filters`\n",
       "    must both be divisible by `groups`.\n",
       "  activation: Activation function to use. If you don't specify anything, no\n",
       "    activation is applied (see `keras.activations`).\n",
       "  use_bias: Boolean, whether the layer uses a bias vector.\n",
       "  kernel_initializer: Initializer for the `kernel` weights matrix (see\n",
       "    `keras.initializers`). Defaults to 'glorot_uniform'.\n",
       "  bias_initializer: Initializer for the bias vector (see\n",
       "    `keras.initializers`). Defaults to 'zeros'.\n",
       "  kernel_regularizer: Regularizer function applied to the `kernel` weights\n",
       "    matrix (see `keras.regularizers`).\n",
       "  bias_regularizer: Regularizer function applied to the bias vector (see\n",
       "    `keras.regularizers`).\n",
       "  activity_regularizer: Regularizer function applied to the output of the\n",
       "    layer (its \"activation\") (see `keras.regularizers`).\n",
       "  kernel_constraint: Constraint function applied to the kernel matrix (see\n",
       "    `keras.constraints`).\n",
       "  bias_constraint: Constraint function applied to the bias vector (see\n",
       "    `keras.constraints`).\n",
       "\n",
       "Input shape:\n",
       "  4+D tensor with shape: `batch_shape + (channels, rows, cols)` if\n",
       "    `data_format='channels_first'`\n",
       "  or 4+D tensor with shape: `batch_shape + (rows, cols, channels)` if\n",
       "    `data_format='channels_last'`.\n",
       "\n",
       "Output shape:\n",
       "  4+D tensor with shape: `batch_shape + (filters, new_rows, new_cols)` if\n",
       "  `data_format='channels_first'` or 4+D tensor with shape: `batch_shape +\n",
       "    (new_rows, new_cols, filters)` if `data_format='channels_last'`.  `rows`\n",
       "    and `cols` values might have changed due to padding.\n",
       "\n",
       "Returns:\n",
       "  A tensor of rank 4+ representing\n",
       "  `activation(conv2d(inputs, kernel) + bias)`.\n",
       "\n",
       "Raises:\n",
       "  ValueError: if `padding` is `\"causal\"`.\n",
       "  ValueError: when both `strides > 1` and `dilation_rate > 1`.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\shyamlal\\anaconda3\\envs\\pavithra\\lib\\site-packages\\keras\\layers\\convolutional.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     Conv2DTranspose, Conv2D"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?tf.keras.layers.Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(feature_map, patch_size=4):\n",
    "    patches=tf.image.extract_patches(images=feature_map, \n",
    "                                     sizes=[1, patch_size, patch_size,1],\n",
    "                                     strides=[1, patch_size, patch_size,1],\n",
    "                                    padding='VALID')\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-A Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T10:27:09.788283Z",
     "iopub.status.busy": "2024-02-22T10:27:09.787110Z",
     "iopub.status.idle": "2024-02-22T10:27:09.797215Z",
     "shell.execute_reply": "2024-02-22T10:27:09.795827Z",
     "shell.execute_reply.started": "2024-02-22T10:27:09.788207Z"
    }
   },
   "outputs": [],
   "source": [
    "class resConv(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(resConv, self).__init__()\n",
    "        self.conv1=tf.keras.layers.Conv2D(filters, 3, padding='valid')\n",
    "    \n",
    "    def call(inputs):\n",
    "        x=self.conv1(inputs)\n",
    "        x=tf.nn.activation.relu(x)\n",
    "        x=self.conv1(x)\n",
    "        x=tf.nn.activation.relu(x)\n",
    "        x=self.conv1(inputs)\n",
    "        x+=inputs\n",
    "        x=tf.nn.activation.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T10:38:30.980310Z",
     "iopub.status.busy": "2024-02-22T10:38:30.978826Z",
     "iopub.status.idle": "2024-02-22T10:38:31.183145Z",
     "shell.execute_reply": "2024-02-22T10:38:31.181597Z",
     "shell.execute_reply.started": "2024-02-22T10:38:30.980232Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__call() takes 1 positional argument but 2 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m x\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(inputs)\n\u001b[1;32m      5\u001b[0m resConvLayer\u001b[38;5;241m=\u001b[39mresConv(\u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[43mresConvLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m resConvLayer\u001b[38;5;241m=\u001b[39mresConv(\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      8\u001b[0m resConvLayer(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__call() takes 1 positional argument but 2 were given\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "inputs=tf.keras.layers.Input(shape=(512,512,3))\n",
    "\n",
    "x=tf.keras.layers.Conv2D(64,3, padding='same')(inputs)\n",
    "resConvLayer=resConv(64)\n",
    "x=resConvLayer(x)\n",
    "resConvLayer=resConv(128)\n",
    "resConvLayer(x)\n",
    "resConvLayer=resConv(256)\n",
    "resConvLayer(x)\n",
    "resConvLayer=resConv(512)\n",
    "resConvLayer(x)\n",
    "\n",
    "\n",
    "model=Model(inputs=inputs, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T06:40:40.803847Z",
     "iopub.status.busy": "2024-02-16T06:40:40.803474Z",
     "iopub.status.idle": "2024-02-16T06:40:47.99836Z",
     "shell.execute_reply": "2024-02-16T06:40:47.997355Z",
     "shell.execute_reply.started": "2024-02-16T06:40:40.803816Z"
    }
   },
   "outputs": [],
   "source": [
    "model=DPM_UNet((512,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T06:40:48.000589Z",
     "iopub.status.busy": "2024-02-16T06:40:48.000103Z",
     "iopub.status.idle": "2024-02-16T06:40:49.416092Z",
     "shell.execute_reply": "2024-02-16T06:40:49.414818Z",
     "shell.execute_reply.started": "2024-02-16T06:40:48.000561Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-16T06:59:41.348659Z",
     "iopub.status.idle": "2024-02-16T06:59:41.348948Z",
     "shell.execute_reply": "2024-02-16T06:59:41.348826Z",
     "shell.execute_reply.started": "2024-02-16T06:59:41.348813Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', iou_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = create_callbacks()\n",
    "history = model.fit(train_gen, validation_data=val_gen, batch_size=4,shuffle=True, verbose=1\n",
    "                                  ,epochs = 100, callbacks = callbacks )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dppnetmodel.predict(x_test)\n",
    "y_pred = y_pred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(x_test, y_test, y_pred, num_samples=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('C:\\\\Users\\\\Admin\\\\Documents\\\\road_segmentation\\\\dpp_ROAD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=[]\n",
    "for i in range(len(x_test)):\n",
    "    image= np.expand_dims(x_test[i], axis=0)\n",
    "\n",
    "    y_pred = dppnetmodel.predict(image)\n",
    "    y_pred=y_pred>0.5\n",
    "    y_predicted.append(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "gt=(y_test.ravel()).astype('int')\n",
    "pd=(np.array(y_predicted).ravel()).astype('int')\n",
    "f1 = f1_score(gt,pd,average='macro')\n",
    "kappa = cohen_kappa_score(gt,pd)\n",
    "accuracy = accuracy_score(gt,pd)\n",
    "jaccard = jaccard_score(gt,pd,average='macro')\n",
    "precision = precision_score(gt,pd,average='macro')\n",
    "recall = recall_score(gt,pd,average='macro')\n",
    "print(np.unique(gt),np.unique(pd))\n",
    "print(\"F1 SCORE:\", f1)\n",
    "print(\"Kappa:\",kappa)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Jaccard Score:\",jaccard)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UNet_Tutorial.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4285814,
     "sourceId": 7375702,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
