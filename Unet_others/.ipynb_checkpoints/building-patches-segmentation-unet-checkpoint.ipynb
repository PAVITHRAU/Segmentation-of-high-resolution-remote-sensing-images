{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"UNet_Tutorial.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7432584,"sourceType":"datasetVersion","datasetId":4325289}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Building Segmentation","metadata":{"_uuid":"6641cf25-1ae4-417f-b1c2-960226555991","_cell_guid":"5b9e8293-e254-4bc2-b214-463d69f02ab3","trusted":true}},{"cell_type":"code","source":"import glob\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tifffile as tiff\nimport cv2\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\nfrom tensorflow.keras.metrics import MeanIoU, Accuracy","metadata":{"_uuid":"25702d4b-8e6a-42a2-9d04-95f43e846573","_cell_guid":"48cd9a02-d3bc-47c5-8fcc-22159a42319d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:22:39.140553Z","iopub.execute_input":"2024-02-09T05:22:39.140942Z","iopub.status.idle":"2024-02-09T05:22:42.701192Z","shell.execute_reply.started":"2024-02-09T05:22:39.140911Z","shell.execute_reply":"2024-02-09T05:22:42.699806Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n    except RuntimeError as e:\n        print(e)","metadata":{"_uuid":"1272aa4f-7cbc-41d9-a14c-c38f0b20c459","_cell_guid":"04c61375-889b-4e75-8a86-918cb5642491","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:22:42.704156Z","iopub.execute_input":"2024-02-09T05:22:42.705484Z","iopub.status.idle":"2024-02-09T05:22:42.812187Z","shell.execute_reply.started":"2024-02-09T05:22:42.705434Z","shell.execute_reply":"2024-02-09T05:22:42.811118Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"gpus","metadata":{"_uuid":"1ce9e576-15de-4176-be50-308fafaf2b7d","_cell_guid":"8b7795ab-de61-4874-9843-907b48d7b0d3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:22:42.813588Z","iopub.execute_input":"2024-02-09T05:22:42.813990Z","iopub.status.idle":"2024-02-09T05:22:42.828458Z","shell.execute_reply.started":"2024-02-09T05:22:42.813956Z","shell.execute_reply":"2024-02-09T05:22:42.827515Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef extract_padded_patches(image, patch_size=(512, 512)):\n    height, width = image.shape[:2]\n    patch_height, patch_width = patch_size\n\n    num_patches_y = (height + patch_height - 1) // patch_height\n    num_patches_x = (width + patch_width - 1) // patch_width\n\n    # Calculate padding\n    pad_y = num_patches_y * patch_height - height\n    pad_x = num_patches_x * patch_width - width\n\n    # Pad the image\n    padded_image = np.pad(image, ((0, pad_y), (0, pad_x), (0, 0)), mode='constant')\n    #print(padded_image.shape)\n    \n    # Extract patches\n    patches = []\n\n    for y in range(0, num_patches_y * patch_height, patch_height):\n        for x in range(0, num_patches_x * patch_width, patch_width):\n            patch = padded_image[y:y+patch_height, x:x+patch_width]\n            #plt.imshow(patch/255)\n            patches.append(patch)\n\n    return np.array(patches)","metadata":{"_uuid":"72544685-2fd3-45d1-8f44-acc5fc8e66b8","_cell_guid":"5e58f076-2e92-42bc-ae14-010adcf60894","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:22:42.831565Z","iopub.execute_input":"2024-02-09T05:22:42.831907Z","iopub.status.idle":"2024-02-09T05:22:42.839774Z","shell.execute_reply.started":"2024-02-09T05:22:42.831877Z","shell.execute_reply":"2024-02-09T05:22:42.838871Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#load the .npz file\ndef load_images(path,name, labels):\n    npzfile=np.load(path+\"{}.npz\".format(name))\n    images=npzfile['arr_0']\n    del npzfile\n    \n\n\n    npzfile=np.load(path+\"{}.npz\".format(labels))\n    labels=npzfile['arr_0']\n    del npzfile\n    \n    return np.array(images),  np.reshape(np.array(labels), (-1, 512, 512, 1))","metadata":{"_uuid":"bbb49e0c-ca1f-4f90-826e-5be21156b191","_cell_guid":"04aa5f10-e33d-4e39-bef0-f26a3b371faa","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:22:42.840719Z","iopub.execute_input":"2024-02-09T05:22:42.841071Z","iopub.status.idle":"2024-02-09T05:22:42.847509Z","shell.execute_reply.started":"2024-02-09T05:22:42.841038Z","shell.execute_reply":"2024-02-09T05:22:42.846639Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n\n# # Assume 'patches' is a list of images obtained from extract_padded_patches function\n\n# # Create a figure with subplots\n# fig, axs = plt.subplots(1, len(patches), figsize=(15, 5))\n\n# # Iterate through patches and display them\n# for i, patch in enumerate(patches):\n#     axs[i].imshow(patch/255)\n#     axs[i].axis('off')\n#     axs[i].set_title(f'Patch {i + 1}')\n\n# # Show the plot\n# plt.show()","metadata":{"_uuid":"4c38dbc9-feba-4cea-9cc7-13bd252e93a2","_cell_guid":"08c1d702-50e8-465b-a7b0-4a8a27e1c1d7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:22:42.848624Z","iopub.execute_input":"2024-02-09T05:22:42.848890Z","iopub.status.idle":"2024-02-09T05:22:42.860421Z","shell.execute_reply.started":"2024-02-09T05:22:42.848867Z","shell.execute_reply":"2024-02-09T05:22:42.859472Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"path='/kaggle/input/building-patches-512/'\n\nx_train,y_train = load_images(path,'x_train_patches','y_train_patches')\n\n\nx_val,y_val = load_images(path,'x_val_patches','y_val_patches')\n\n\nx_test,y_test = load_images(path,'x_test_patches','y_test_patches')\n\n\nx_train.sort()\ny_train.sort()\n\nx_val.sort()\ny_val.sort()\n\nx_test.sort()\ny_test.sort()\n\nprint(x_train.shape, y_train.shape, x_test.shape, y_test.shape)","metadata":{"_uuid":"b8269bae-eeb0-47f6-ada7-b526e80f7197","_cell_guid":"5b927d5b-380d-49fb-8377-76f8d9374bf9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:22:42.864055Z","iopub.execute_input":"2024-02-09T05:22:42.864696Z","iopub.status.idle":"2024-02-09T05:23:11.015437Z","shell.execute_reply.started":"2024-02-09T05:22:42.864670Z","shell.execute_reply":"2024-02-09T05:23:11.014429Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(1233, 512, 512, 3) (1233, 512, 512, 1) (90, 512, 512, 3) (90, 512, 512, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"#x_train[0][1]","metadata":{"_uuid":"1448410a-5799-429e-b969-e451151f798c","_cell_guid":"a7ba2620-aeb7-459d-af72-e67ca8e066fa","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:11.016528Z","iopub.execute_input":"2024-02-09T05:23:11.016826Z","iopub.status.idle":"2024-02-09T05:23:11.021194Z","shell.execute_reply.started":"2024-02-09T05:23:11.016803Z","shell.execute_reply":"2024-02-09T05:23:11.020162Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# from keras.preprocessing.image import ImageDataGenerator\n# train_datagen = ImageDataGenerator(\n#     rescale=1./255,\n#     shear_range=0.2,\n#     zoom_range=0.2,\n#     horizontal_flip=True)\n\n# val_datagen = ImageDataGenerator(\n#     rescale=1./255)\n\n# test_datagen = ImageDataGenerator(\n#     rescale=1./255)\n\n# train_generator = train_datagen.flow(x_train, y_train, batch_size=4)\n# validation_generator = val_datagen.flow(x_val, y_val, batch_size=4)\n# test_generator = test_datagen.flow(x_test, y_test, batch_size=4)","metadata":{"_uuid":"67cdc844-0317-43ff-9b8d-cfc0344629a9","_cell_guid":"fd4098f8-8ab5-4a6a-96e7-506259c96a93","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:11.022514Z","iopub.execute_input":"2024-02-09T05:23:11.022900Z","iopub.status.idle":"2024-02-09T05:23:11.031200Z","shell.execute_reply.started":"2024-02-09T05:23:11.022856Z","shell.execute_reply":"2024-02-09T05:23:11.030335Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)","metadata":{"_uuid":"89f358a2-b18b-49c5-a066-365607741a53","_cell_guid":"d07c5915-6c9f-4d71-a9d3-77cf33d32622","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:11.035461Z","iopub.execute_input":"2024-02-09T05:23:11.035826Z","iopub.status.idle":"2024-02-09T05:23:11.041577Z","shell.execute_reply.started":"2024-02-09T05:23:11.035801Z","shell.execute_reply":"2024-02-09T05:23:11.040746Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(1233, 512, 512, 3) (1233, 512, 512, 1) (36, 512, 512, 3) (36, 512, 512, 1) (90, 512, 512, 3) (90, 512, 512, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# x_train = tf.constant(x_train, dtype=tf.float32)\n# y_train = tf.constant(y_train, dtype=tf.float32)\n# x_val = tf.constant(x_val, dtype=tf.float32)\n# y_val = tf.constant(y_val, dtype=tf.float32)\n# x_test = tf.constant(x_test, dtype=tf.float32)\n# y_test = tf.constant(y_test, dtype=tf.float32)","metadata":{"_uuid":"e9b2531b-7a15-4cb5-b22b-3c6794b86fd4","_cell_guid":"c5f54775-c5df-4705-b90a-8007d1255c34","collapsed":false,"_kg_hide-output":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:11.042557Z","iopub.execute_input":"2024-02-09T05:23:11.042836Z","iopub.status.idle":"2024-02-09T05:23:11.049423Z","shell.execute_reply.started":"2024-02-09T05:23:11.042814Z","shell.execute_reply":"2024-02-09T05:23:11.048644Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#del train_dataset\nwith tf.device('/device:GPU:1'):\n    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(2)","metadata":{"_uuid":"abd5685c-1948-44ad-a5f4-f158d3657127","_cell_guid":"0d41ed1b-58e4-4df5-908a-d791e364409f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:11.050545Z","iopub.execute_input":"2024-02-09T05:23:11.050876Z","iopub.status.idle":"2024-02-09T05:23:22.704105Z","shell.execute_reply.started":"2024-02-09T05:23:11.050846Z","shell.execute_reply":"2024-02-09T05:23:22.703110Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"del x_train\ndel y_train","metadata":{"_uuid":"0abecf41-96b3-4d72-99fc-990da15cbc65","_cell_guid":"77479dfd-da04-4fcb-82b0-7d492dd15ed2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:22.705329Z","iopub.execute_input":"2024-02-09T05:23:22.705714Z","iopub.status.idle":"2024-02-09T05:23:22.719937Z","shell.execute_reply.started":"2024-02-09T05:23:22.705680Z","shell.execute_reply":"2024-02-09T05:23:22.718941Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\n\nlocal_device_protos = device_lib.list_local_devices()\ngpu_devices = [x for x in local_device_protos if x.device_type == 'GPU']\n\nfor gpu_device in gpu_devices:\n    print(\"Name:\", gpu_device.name)\n    print(\"Memory:\", gpu_device.memory_limit)","metadata":{"_uuid":"490b8314-7ec6-437a-a760-80ba3a4a3d31","_cell_guid":"38ca130e-45e3-4817-be22-5dd2b519c0c7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:22.721089Z","iopub.execute_input":"2024-02-09T05:23:22.721400Z","iopub.status.idle":"2024-02-09T05:23:22.733994Z","shell.execute_reply.started":"2024-02-09T05:23:22.721374Z","shell.execute_reply":"2024-02-09T05:23:22.733018Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Name: /device:GPU:0\nMemory: 4294967296\nName: /device:GPU:1\nMemory: 14626652160\n","output_type":"stream"}]},{"cell_type":"code","source":"# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# # Set a seed for reproducibility\n# seed = 42\n\n# # Image data generator\n# image_datagen = ImageDataGenerator(\n#     # Your image augmentation parameters\n#     rescale=1./255,  # Example: normalization\n#     rotation_range=20,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     shear_range=0.2,\n#     zoom_range=0.2,\n#     horizontal_flip=True,\n#     fill_mode='nearest',\n#     seed=seed\n# )\n# # Set seed for image data generator\n# image_datagen.set_seed(seed)\n\n# # Mask data generator\n# mask_datagen = ImageDataGenerator(\n#     # Your mask augmentation parameters\n#     rescale=1./255,  # Example: normalization\n#     rotation_range=20,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     shear_range=0.2,\n#     zoom_range=0.2,\n#     horizontal_flip=True,\n#     fill_mode='nearest',\n#     seed=seed\n# )\n# # Set seed for mask data generator\n# #mask_datagen.set_seed(seed)\n\n# # Example usage:\n# # Load images and masks using the generators\n# image_generator = image_datagen.flow(\n#     x_train,\n#     class_mode=None\n# )\n\n# mask_generator = mask_datagen.flow(\n#     y_train,\n#     class_mode=None\n# )\n\n# # Combine generators into one which yields images and masks\n# train_generator = zip(image_generator, mask_generator)\n\n# # Example: Train your model using the train_generator\n# #model.fit(train_generator, epochs=10)","metadata":{"_uuid":"6793a16e-bcaf-4fba-aa2d-597e44ba8441","_cell_guid":"10cc0390-628b-4dc1-a29b-8338ab8f8a28","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:22.735088Z","iopub.execute_input":"2024-02-09T05:23:22.735450Z","iopub.status.idle":"2024-02-09T05:23:22.744531Z","shell.execute_reply.started":"2024-02-09T05:23:22.735414Z","shell.execute_reply":"2024-02-09T05:23:22.743638Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{"_uuid":"d9a131fe-23e2-45e1-80b7-de1fc2a92674","_cell_guid":"16172312-305f-413f-b96d-091c9ff5eb9e","trusted":true}},{"cell_type":"code","source":"from keras import backend as K\nfrom keras.losses import binary_crossentropy\nimport tensorflow as tf\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef iou_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n    return iou\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + 0.5 * dice_loss(tf.cast(y_true, tf.float32), y_pred)","metadata":{"_uuid":"ef9b40fa-55f2-4d27-9dde-4e78c5d5424f","_cell_guid":"770ba02c-a84e-4760-9634-95f4478f8073","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:22.745748Z","iopub.execute_input":"2024-02-09T05:23:22.746061Z","iopub.status.idle":"2024-02-09T05:23:22.757366Z","shell.execute_reply.started":"2024-02-09T05:23:22.746031Z","shell.execute_reply":"2024-02-09T05:23:22.756450Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Calculate Number of Flops and Parameters","metadata":{"_uuid":"0e6235fe-8185-4736-868b-e607e84a021e","_cell_guid":"3d833cec-f5da-4f3b-a9d6-f186284b4da7","trusted":true}},{"cell_type":"code","source":"def calculate_flops_and_params(model):\n    flops = tf.profiler.experimental.profile(model, options=tf.profiler.experimental.ProfilerOptions(host_tracer_level=2)).total_float_ops\n    params = sum([tf.keras.backend.count_params(p) for p in model.trainable_variables])\n    return flops, params","metadata":{"_uuid":"08382893-6a20-4f11-8a00-2ee47bc04a13","_cell_guid":"feed2c00-6f18-4647-8e2d-b08e8ebe3182","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:22.758484Z","iopub.execute_input":"2024-02-09T05:23:22.758819Z","iopub.status.idle":"2024-02-09T05:23:22.771352Z","shell.execute_reply.started":"2024-02-09T05:23:22.758788Z","shell.execute_reply":"2024-02-09T05:23:22.770577Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# **UTILS**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ndef create_callbacks():\n    # Reduce learning rate on plateau\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        mode='min',\n        factor=0.5,\n        patience=10,\n        verbose=1,\n        cooldown=1,\n        min_delta=0.0001\n    )\n\n    # Early stopping\n    early_stop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        min_delta=0.0001,\n        patience=30,\n        verbose=1,\n        mode='min',\n        restore_best_weights=True\n    )\n\n    # Model checkpoint\n    check_path = './dpp_building.h5'\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        check_path,\n        monitor='val_loss',\n        verbose=1,\n        save_best_only=True,\n        save_weights_only=True,\n        mode='min'\n    )\n\n    return [reduce_lr, early_stop, checkpoint]\n\n# Usage example:\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T05:23:22.772425Z","iopub.execute_input":"2024-02-09T05:23:22.772715Z","iopub.status.idle":"2024-02-09T05:23:22.782094Z","shell.execute_reply.started":"2024-02-09T05:23:22.772691Z","shell.execute_reply":"2024-02-09T05:23:22.781206Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_history(history):\n    # Accuracy plot\n    plt.plot(history.history['accuracy'], label='train_acc')\n    plt.plot(history.history['val_accuracy'], '--', label='val_acc')\n    plt.legend()\n    plt.xlabel(\"No. of epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(\"Training and Validation Accuracy\")\n    plt.show()\n\n    # Loss plot\n    plt.plot(history.history['loss'], label='train_loss')\n    plt.plot(history.history['val_loss'], '--', label='val_loss')\n    plt.legend()\n    plt.xlabel(\"No. of epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Training and Validation Loss\")\n    plt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T05:23:22.783224Z","iopub.execute_input":"2024-02-09T05:23:22.783518Z","iopub.status.idle":"2024-02-09T05:23:22.794063Z","shell.execute_reply.started":"2024-02-09T05:23:22.783490Z","shell.execute_reply":"2024-02-09T05:23:22.793205Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate Model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score, precision_score, recall_score\n\ndef get_dice(y_true, y_pred):\n    intersection = np.sum(y_true * y_pred, axis=(0, 1, 2))\n    union = np.sum(y_true**2, axis=(0, 1, 2)) + np.sum(y_pred**2, axis=(0, 1, 2))\n    dc = 2 * intersection / union\n    return dc\n\n\ndef evaluate_segmentation(y_test, y_pred):\n    # Mean Intersection over Union\n    mean_iou = MeanIoU(2)\n    mean_iou.update_state(y_test, y_pred)\n    class_iou = mean_iou.result().numpy()\n    mean_iou.reset_states()\n    \n    # Accuracy\n    acc = Accuracy()\n    acc.update_state(y_test, y_pred)\n    accuracy = acc.result().numpy()\n    acc.reset_states()\n    \n    # Precision\n    precision = precision_score(y_test.ravel(), y_pred.ravel(), average='binary')\n    \n    # Recall\n    recall = recall_score(y_test.ravel(), y_pred.ravel(), average='binary')\n    \n    # Confusion Matrix\n    cm = confusion_matrix(y_test.ravel(), y_pred.ravel())\n    \n    # Classification Report\n    cr = classification_report(y_test.ravel(), y_pred.ravel())\n    \n    # Cohen's Kappa Score\n    kappa = cohen_kappa_score(y_test.ravel(), y_pred.ravel())\n    \n    # Dice Coefficient\n    dice_coeff = get_dice(y_test, y_pred)\n    mean_dice_coeff = np.mean(dice_coeff)\n    \n    return {\n        \"mean_iou\": mean_iou,\n        \"class_iou\": class_iou,\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"confusion_matrix\": cm,\n        \"classification_report\": cr,\n        \"cohen_kappa_score\": kappa,\n        \"dice_coefficient\": dice_coeff,\n        \"mean_dice_coefficient\": mean_dice_coeff\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T05:23:22.795008Z","iopub.execute_input":"2024-02-09T05:23:22.795260Z","iopub.status.idle":"2024-02-09T05:23:23.074781Z","shell.execute_reply.started":"2024-02-09T05:23:22.795238Z","shell.execute_reply":"2024-02-09T05:23:23.073951Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Visualize","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef visualize_predictions(x_test, y_test, y_pred, num_samples=10):\n    fig = plt.figure(figsize=(20, 15))\n\n    for i in range(num_samples):\n        # Plot input image\n        ax = fig.add_subplot(num_samples, 3, 3*i+1)\n        ax.imshow(np.reshape(x_test[i], (512, 512)), cmap=\"gray\")\n        plt.axis('off')\n        plt.title(\"Input image\")\n\n        # Plot ground truth\n        ax = fig.add_subplot(num_samples, 3, 3*i+2)\n        ax.imshow(np.reshape(y_test[i], (512, 512)), cmap=\"gray\")\n        plt.axis('off')\n        plt.title(\"Ground-truth\")\n\n        # Plot predicted image\n        ax = fig.add_subplot(num_samples, 3, 3*i+3)\n        ax.imshow(np.reshape(y_pred[i], (512, 512)), cmap=\"gray\")\n        plt.axis('off')\n        plt.title(\"Predicted image\")\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T05:23:23.075982Z","iopub.execute_input":"2024-02-09T05:23:23.076282Z","iopub.status.idle":"2024-02-09T05:23:23.084900Z","shell.execute_reply.started":"2024-02-09T05:23:23.076256Z","shell.execute_reply":"2024-02-09T05:23:23.083873Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# DPPNet","metadata":{"_uuid":"91b5a05d-0d0c-4731-b28d-29a112c9e6be","_cell_guid":"6830c483-9e50-4894-aaa6-928492b3c202","trusted":true}},{"cell_type":"code","source":"# In[5]:\n\n\nimport numpy as np\nfrom keras.backend import int_shape\nfrom keras.models import Model\nfrom keras.layers import Conv2D,Conv2DTranspose, Conv3D, MaxPooling2D, MaxPooling3D, UpSampling2D, Add, BatchNormalization, Input, Activation, Lambda, Concatenate\nfrom tensorflow.keras import regularizers\n\n\ndef residual_separable(inp, n_filters, dropout=0.3, dilation=1, l2=None, name=\"down\"):\n    x = tf.keras.layers.SeparableConv2D(n_filters, (3, 3), strides=1, padding='same', activation=None,\n                        dilation_rate=dilation, use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform',\n                        pointwise_regularizer=regularizers.l2(0.00004))(inp)\n    x = BatchNormalization()(x)\n    x = Dropout(rate=dropout)(x)\n    if inp.shape[3] == x.shape[3]:\n        x = Add()([x, inp])\n    x = Activation('relu')(x)\n    return x\n\ndef residual_separable_multi(inp, n_filters, dropout=0.3, dilation=1, l2=None, name=\"down\"):\n    x = tf.keras.layers.DepthwiseConv2D(3, strides=(1, 1), depth_multiplier=1, padding='same', use_bias=False)(inp)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x2 = tf.keras.layers.DepthwiseConv2D(3, strides=(1, 1), depth_multiplier=1, dilation_rate= (dilation, dilation), padding='same', use_bias=False)(inp)\n    x2 = BatchNormalization()(x2)\n    x2 = Activation('relu')(x2)\n\n    x +=x2\n\n    x = Conv2D(n_filters, 1, strides=1, padding='same', activation=None, \n                         dilation_rate=1, use_bias=False, kernel_regularizer=regularizers.l2(0.00004))(x)\n    x = BatchNormalization()(x)\n\n    x = Dropout(rate=dropout)(x)\n\n    if inp.shape[3] == x.shape[3]:\n        x = Add()([x, inp])\n\n    x = Activation('relu')(x)\n    return x\n\n\ndef encoder_module(inp, n_filters, dropout=0.3, dilation=[1,1], l2=None, name=\"down\"):\n    x = residual_separable(inp, n_filters, dropout=dropout, dilation=dilation[0], l2=l2, name=name)\n    x = residual_separable(x, n_filters, dropout=dropout, dilation=dilation[1], l2=l2, name=name)\n    return x\n\ndef encoder_module_multi(inp, n_filters, dropout=0.3, dilation=[1,1], l2=None, name=\"down\"):\n    x = residual_separable_multi(inp, n_filters, dropout=dropout, dilation=dilation[0], l2=l2, name=name)\n    x = residual_separable_multi(x, n_filters, dropout=dropout, dilation=dilation[1], l2=l2, name=name)\n    return x\n\ndef upsample(x, n_filters, last=False, l2=None, name=\"down\"):\n    x = Conv2DTranspose(n_filters, 3, strides=2, padding='same',use_bias=True,\n                                   activation=None,\n                                   kernel_regularizer=regularizers.l2(0.00004))(x)\n    if not last:\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n\n    return x\n\ndef downsample(inp, n_filters_in, n_filters_out, bn=False, use_relu=False, l2=None, name=\"down\"):\n    \n    if n_filters_in < n_filters_out:\n        filters_conv = n_filters_out - n_filters_in\n    else:\n        filters_conv = n_filters_out\n\n    x = Conv2D(filters_conv, 3, strides=2, padding='same', activation=None,\n                         dilation_rate=1, use_bias=False, kernel_regularizer=regularizers.l2(0.00004))(inp)\n    \n    if n_filters_in < n_filters_out:\n        y =  MaxPooling2D(pool_size=(2, 2), strides=(2,2))(inp)\n        x =  concatenate([x,y], axis = -1)\n    \n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    return x\n\ndef dpp(x,f):\n  x1 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same', activation='relu', \n                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x) \n  x2 = tf.keras.layers.SeparableConv2D(f, (3, 3), strides = 2, padding='same', activation='relu', \n                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x) \n  x3 = tf.keras.layers.SeparableConv2D(f, (3, 3), strides = 4, padding='same', activation='relu', \n                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x) \n  x1 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same', activation='relu', \n                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x1) \n  x2 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same', activation='relu', \n                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x2) \n  x3 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same', activation='relu', \n                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x3) \n  x1 = Conv2D(f,(1,1))(x1)\n  x2 = Conv2DTranspose(f, 3, strides=2, padding='same',use_bias=True, activation='relu')(x2)\n  x3 = Conv2DTranspose(f, 3, strides=4, padding='same',use_bias=True, activation='relu')(x3)  \n  x = concatenate([x3,x2,x1], axis=3)\n  x1 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same',dilation_rate = (1,1), activation='relu', \n                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x) \n  x2 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same',dilation_rate = (2,2), activation='relu', \n                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x) \n  x3 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same',dilation_rate = (4,4), activation='relu', \n                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x) \n  x4 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same',dilation_rate = (8,8), activation='relu', \n                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x) \n  x = concatenate([x1,x2,x3,x4], axis=3)\n  x = Conv2D(f,(1,1))(x)\n  return x\n     \n\n\n# In[6]:\n\n\nimport numpy as np\nfrom keras.backend import int_shape\nfrom keras.models import Model\nfrom keras.layers import *\nfrom tensorflow.keras import regularizers\nimport tensorflow as tf\n\ndef feature_extractor(x,f,dropout=0.25, dilation=[1,1,1,1], l2=None, name=\"down\"):\n  x1_1 = residual_separable_multi(x, f, dropout=dropout, dilation=1, l2=l2, name=name)\n  x1_2 = residual_separable_multi(x, f//4, dropout=dropout, dilation=dilation[0], l2=l2, name=name)\n  x2 = concatenate([x,x1_2])\n  x2_1 = residual_separable_multi(x2, f, dropout=dropout, dilation=1, l2=l2, name=name)\n  x2_2 = residual_separable_multi(x2_1, f//4, dropout=dropout, dilation=dilation[1], l2=l2, name=name)\n  x3 = concatenate([x,x1_2,x2_2])\n  x3_1 = residual_separable_multi(x3, f, dropout=dropout, dilation=1, l2=l2, name=name)\n  x3_2 = residual_separable_multi(x3_1, f//4, dropout=dropout, dilation=dilation[2], l2=l2, name=name)\n  x4 = concatenate([x,x1_2,x2_2,x3_2])\n  x4_1 = residual_separable_multi(x4, f, dropout=dropout, dilation=1, l2=l2, name=name)\n  x4_2 = residual_separable_multi(x4_1, f//4, dropout=dropout, dilation=dilation[3], l2=l2, name=name)\n  xout = concatenate([x,x1_2,x2_2,x3_2,x4_2])\n  return xout\n\n\n# In[7]:\n\n\nfrom tensorflow.keras.layers import BatchNormalization, Activation, AveragePooling2D, DepthwiseConv2D, Conv2DTranspose\nimport tensorflow.keras.backend as K \nfrom keras import backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras.layers import Activation,Reshape, Add, Multiply, DepthwiseConv2D, BatchNormalization, Concatenate, Conv2D, Dense,Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, Input, Lambda,LeakyReLU, MaxPooling2D, Multiply, Permute, Reshape, UpSampling2D \nimport collections\nimport tensorflow as tf\n    \n\ndef dppnet(input_size,  n_classes, l2=None, upsampling=2):\n    inputs = Input(input_size)\n    d1 = downsample(inputs, 3, 16, l2=l2, name=\"d1\")\n    d2 = downsample(d1, n_filters_in=16, n_filters_out=64, l2=l2, name=\"d2\")\n    m1 = encoder_module(d2, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres3\", dropout=0.0)\n    m2 = encoder_module(m1, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres4\", dropout=0.0)\n    m3 = encoder_module(m2, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres5\", dropout=0.0)\n    m4 = encoder_module(m3, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres6\", dropout=0.0)\n    m5 = encoder_module(m4, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres7\", dropout=0.0)\n\n    d3 = downsample(m5,  n_filters_in=64, n_filters_out=128, l2=l2, name=\"d8\")\n    m6 = feature_extractor(d3,128,dropout=0.25, dilation=[2,4,8,16], l2=l2, name=\"fres9\")\n    m7 = feature_extractor(m6,128,dropout=0.25, dilation=[1,2,8,16], l2=l2, name=\"fres10\")\n    up1 = upsample(m7, n_filters=64, l2=l2, name=\"up11\")\n    x = up1+d2\n    up2 = upsample(x, n_filters=16, l2=l2, name=\"up16\", last = True)\n    x = concatenate([up2, d1], axis=3)\n    x = dpp(x,32)\n    x = Conv2D(1, (1, 1), activation='sigmoid')(x)\n    if upsampling > 1:\n      x = tf.keras.layers.experimental.preprocessing.Resizing(x.shape[1] * upsampling, x.shape[2] * upsampling)(x)\n\n\n    model = Model(inputs, x)\n\n#     opt = Adam(learning_rate=0.001)\n    #model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    return model","metadata":{"_uuid":"9afb77c7-89e2-4079-bf8b-8b804d0246c1","_cell_guid":"bec5f892-c6ba-4209-abda-2e84ce89785f","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:23.086374Z","iopub.execute_input":"2024-02-09T05:23:23.086964Z","iopub.status.idle":"2024-02-09T05:23:23.135760Z","shell.execute_reply.started":"2024-02-09T05:23:23.086931Z","shell.execute_reply":"2024-02-09T05:23:23.134899Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\n\ndef self_attention(x, filters, name='self_attention'):\n    # Compute the dimensionality of the input tensor\n    num_channels = int(x.shape[-1])\n\n    # Apply 1x1 convolution to reduce the dimensionality to 'filters'\n    f = Conv2D(filters, (1, 1), strides=(1, 1), padding='same')(x)\n    g = Conv2D(filters, (1, 1), strides=(1, 1), padding='same')(x)\n    h = Conv2D(filters, (1, 1), strides=(1, 1), padding='same')(x)\n\n    # Reshape the tensors for compatibility with the dot product operation\n    f = Reshape((-1, filters))(f)\n    g = Reshape((-1, filters))(g)\n    h = Reshape((-1, filters))(h)\n\n    # Compute the dot product between 'g' and 'f' to calculate the attention map\n    attention_map = Lambda(lambda x: K.batch_dot(x[0], K.permute_dimensions(x[1], (0, 2, 1))))([g, f])\n\n    # Apply softmax activation to normalize the attention scores\n    attention_map = Activation('softmax')(attention_map)\n\n    # Apply the attention map to the 'h' tensor to get the self-attended features\n    self_attended_features = Lambda(lambda x: K.batch_dot(x[0], x[1]))([attention_map, h])\n\n    # Reshape the self-attended features tensor to match the input shape\n    self_attended_features = Reshape((x.shape[1], x.shape[2], filters))(self_attended_features)\n\n    # Apply a 1x1 convolution to restore the original number of channels\n    self_attended_features = Conv2D(num_channels, (1, 1), strides=(1, 1), padding='same')(self_attended_features)\n\n    # Combine the self-attended features with the original features using element-wise addition\n    x = Add()([x, self_attended_features])\n\n    return x\n\n# Modify the DPPNet model to incorporate self-attention\ndef dppnet_with_attention(input_size, n_classes, l2=None, upsampling=2):\n    inputs = Input(input_size)\n    d1 = downsample(inputs, 3, 16, l2=l2, name=\"d1\")\n    d2 = downsample(d1, n_filters_in=16, n_filters_out=64, l2=l2, name=\"d2\")\n    m1 = encoder_module(d2, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres3\", dropout=0.0)\n    m2 = encoder_module(m1, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres4\", dropout=0.0)\n    m3 = encoder_module(m2, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres5\", dropout=0.0)\n    m4 = encoder_module(m3, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres6\", dropout=0.0)\n    m5 = encoder_module(m4, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres7\", dropout=0.0)\n\n    d3 = downsample(m5, n_filters_in=64, n_filters_out=128, l2=l2, name=\"d8\")\n    m6 = feature_extractor(d3, 128, dropout=0.25, dilation=[2, 4, 8, 16], l2=l2, name=\"fres9\")\n    m7 = feature_extractor(m6, 128, dropout=0.25, dilation=[1, 2, 8, 16], l2=l2, name=\"fres10\")\n    up1 = upsample(m7, n_filters=64, l2=l2, name=\"up11\")\n    x = up1 + d2\n\n    # Apply self-attention\n    x = self_attention(x, filters=64)\n\n    up2 = upsample(x, n_filters=16, l2=l2, name=\"up16\", last=True)\n    x = concatenate([up2, d1], axis=3)\n    x = dpp(x, 32)\n    x = Conv2D(1, (1, 1), activation='sigmoid')(x)\n\n    if upsampling > 1:\n        x = tf.keras.layers.experimental.preprocessing.Resizing(x.shape[1] * upsampling, x.shape[2] * upsampling)(x)\n\n    model = Model(inputs, x)\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T05:23:23.137004Z","iopub.execute_input":"2024-02-09T05:23:23.137298Z","iopub.status.idle":"2024-02-09T05:23:23.155486Z","shell.execute_reply.started":"2024-02-09T05:23:23.137272Z","shell.execute_reply":"2024-02-09T05:23:23.154515Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#dppnetmodel = dppnet_with_attention((512,512,3),1)\ndppnetmodel = dppnet((512,512,3),1)\n\ndppnetmodel.summary()","metadata":{"_uuid":"7623d15a-02a1-40c9-8cf7-365dd363745c","_cell_guid":"bb326bb8-e5ff-4868-abb1-e5f03fe12924","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:23.156691Z","iopub.execute_input":"2024-02-09T05:23:23.156958Z","iopub.status.idle":"2024-02-09T05:23:26.128143Z","shell.execute_reply.started":"2024-02-09T05:23:23.156935Z","shell.execute_reply":"2024-02-09T05:23:26.124896Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 512, 512, 3)]        0         []                            \n                                                                                                  \n conv2d (Conv2D)             (None, 256, 256, 13)         351       ['input_1[0][0]']             \n                                                                                                  \n max_pooling2d (MaxPooling2  (None, 256, 256, 3)          0         ['input_1[0][0]']             \n D)                                                                                               \n                                                                                                  \n concatenate (Concatenate)   (None, 256, 256, 16)         0         ['conv2d[0][0]',              \n                                                                     'max_pooling2d[0][0]']       \n                                                                                                  \n batch_normalization (Batch  (None, 256, 256, 16)         64        ['concatenate[0][0]']         \n Normalization)                                                                                   \n                                                                                                  \n activation (Activation)     (None, 256, 256, 16)         0         ['batch_normalization[0][0]'] \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 128, 128, 48)         6912      ['activation[0][0]']          \n                                                                                                  \n max_pooling2d_1 (MaxPoolin  (None, 128, 128, 16)         0         ['activation[0][0]']          \n g2D)                                                                                             \n                                                                                                  \n concatenate_1 (Concatenate  (None, 128, 128, 64)         0         ['conv2d_1[0][0]',            \n )                                                                   'max_pooling2d_1[0][0]']     \n                                                                                                  \n batch_normalization_1 (Bat  (None, 128, 128, 64)         256       ['concatenate_1[0][0]']       \n chNormalization)                                                                                 \n                                                                                                  \n activation_1 (Activation)   (None, 128, 128, 64)         0         ['batch_normalization_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n separable_conv2d (Separabl  (None, 128, 128, 64)         4672      ['activation_1[0][0]']        \n eConv2D)                                                                                         \n                                                                                                  \n batch_normalization_2 (Bat  (None, 128, 128, 64)         256       ['separable_conv2d[0][0]']    \n chNormalization)                                                                                 \n                                                                                                  \n dropout (Dropout)           (None, 128, 128, 64)         0         ['batch_normalization_2[0][0]'\n                                                                    ]                             \n                                                                                                  \n add (Add)                   (None, 128, 128, 64)         0         ['dropout[0][0]',             \n                                                                     'activation_1[0][0]']        \n                                                                                                  \n activation_2 (Activation)   (None, 128, 128, 64)         0         ['add[0][0]']                 \n                                                                                                  \n separable_conv2d_1 (Separa  (None, 128, 128, 64)         4672      ['activation_2[0][0]']        \n bleConv2D)                                                                                       \n                                                                                                  \n batch_normalization_3 (Bat  (None, 128, 128, 64)         256       ['separable_conv2d_1[0][0]']  \n chNormalization)                                                                                 \n                                                                                                  \n dropout_1 (Dropout)         (None, 128, 128, 64)         0         ['batch_normalization_3[0][0]'\n                                                                    ]                             \n                                                                                                  \n add_1 (Add)                 (None, 128, 128, 64)         0         ['dropout_1[0][0]',           \n                                                                     'activation_2[0][0]']        \n                                                                                                  \n activation_3 (Activation)   (None, 128, 128, 64)         0         ['add_1[0][0]']               \n                                                                                                  \n separable_conv2d_2 (Separa  (None, 128, 128, 64)         4672      ['activation_3[0][0]']        \n bleConv2D)                                                                                       \n                                                                                                  \n batch_normalization_4 (Bat  (None, 128, 128, 64)         256       ['separable_conv2d_2[0][0]']  \n chNormalization)                                                                                 \n                                                                                                  \n dropout_2 (Dropout)         (None, 128, 128, 64)         0         ['batch_normalization_4[0][0]'\n                                                                    ]                             \n                                                                                                  \n add_2 (Add)                 (None, 128, 128, 64)         0         ['dropout_2[0][0]',           \n                                                                     'activation_3[0][0]']        \n                                                                                                  \n activation_4 (Activation)   (None, 128, 128, 64)         0         ['add_2[0][0]']               \n                                                                                                  \n separable_conv2d_3 (Separa  (None, 128, 128, 64)         4672      ['activation_4[0][0]']        \n bleConv2D)                                                                                       \n                                                                                                  \n batch_normalization_5 (Bat  (None, 128, 128, 64)         256       ['separable_conv2d_3[0][0]']  \n chNormalization)                                                                                 \n                                                                                                  \n dropout_3 (Dropout)         (None, 128, 128, 64)         0         ['batch_normalization_5[0][0]'\n                                                                    ]                             \n                                                                                                  \n add_3 (Add)                 (None, 128, 128, 64)         0         ['dropout_3[0][0]',           \n                                                                     'activation_4[0][0]']        \n                                                                                                  \n activation_5 (Activation)   (None, 128, 128, 64)         0         ['add_3[0][0]']               \n                                                                                                  \n separable_conv2d_4 (Separa  (None, 128, 128, 64)         4672      ['activation_5[0][0]']        \n bleConv2D)                                                                                       \n                                                                                                  \n batch_normalization_6 (Bat  (None, 128, 128, 64)         256       ['separable_conv2d_4[0][0]']  \n chNormalization)                                                                                 \n                                                                                                  \n dropout_4 (Dropout)         (None, 128, 128, 64)         0         ['batch_normalization_6[0][0]'\n                                                                    ]                             \n                                                                                                  \n add_4 (Add)                 (None, 128, 128, 64)         0         ['dropout_4[0][0]',           \n                                                                     'activation_5[0][0]']        \n                                                                                                  \n activation_6 (Activation)   (None, 128, 128, 64)         0         ['add_4[0][0]']               \n                                                                                                  \n separable_conv2d_5 (Separa  (None, 128, 128, 64)         4672      ['activation_6[0][0]']        \n bleConv2D)                                                                                       \n                                                                                                  \n batch_normalization_7 (Bat  (None, 128, 128, 64)         256       ['separable_conv2d_5[0][0]']  \n chNormalization)                                                                                 \n                                                                                                  \n dropout_5 (Dropout)         (None, 128, 128, 64)         0         ['batch_normalization_7[0][0]'\n                                                                    ]                             \n                                                                                                  \n add_5 (Add)                 (None, 128, 128, 64)         0         ['dropout_5[0][0]',           \n                                                                     'activation_6[0][0]']        \n                                                                                                  \n activation_7 (Activation)   (None, 128, 128, 64)         0         ['add_5[0][0]']               \n                                                                                                  \n separable_conv2d_6 (Separa  (None, 128, 128, 64)         4672      ['activation_7[0][0]']        \n bleConv2D)                                                                                       \n                                                                                                  \n batch_normalization_8 (Bat  (None, 128, 128, 64)         256       ['separable_conv2d_6[0][0]']  \n chNormalization)                                                                                 \n                                                                                                  \n dropout_6 (Dropout)         (None, 128, 128, 64)         0         ['batch_normalization_8[0][0]'\n                                                                    ]                             \n                                                                                                  \n add_6 (Add)                 (None, 128, 128, 64)         0         ['dropout_6[0][0]',           \n                                                                     'activation_7[0][0]']        \n                                                                                                  \n activation_8 (Activation)   (None, 128, 128, 64)         0         ['add_6[0][0]']               \n                                                                                                  \n separable_conv2d_7 (Separa  (None, 128, 128, 64)         4672      ['activation_8[0][0]']        \n bleConv2D)                                                                                       \n                                                                                                  \n batch_normalization_9 (Bat  (None, 128, 128, 64)         256       ['separable_conv2d_7[0][0]']  \n chNormalization)                                                                                 \n                                                                                                  \n dropout_7 (Dropout)         (None, 128, 128, 64)         0         ['batch_normalization_9[0][0]'\n                                                                    ]                             \n                                                                                                  \n add_7 (Add)                 (None, 128, 128, 64)         0         ['dropout_7[0][0]',           \n                                                                     'activation_8[0][0]']        \n                                                                                                  \n activation_9 (Activation)   (None, 128, 128, 64)         0         ['add_7[0][0]']               \n                                                                                                  \n separable_conv2d_8 (Separa  (None, 128, 128, 64)         4672      ['activation_9[0][0]']        \n bleConv2D)                                                                                       \n                                                                                                  \n batch_normalization_10 (Ba  (None, 128, 128, 64)         256       ['separable_conv2d_8[0][0]']  \n tchNormalization)                                                                                \n                                                                                                  \n dropout_8 (Dropout)         (None, 128, 128, 64)         0         ['batch_normalization_10[0][0]\n                                                                    ']                            \n                                                                                                  \n add_8 (Add)                 (None, 128, 128, 64)         0         ['dropout_8[0][0]',           \n                                                                     'activation_9[0][0]']        \n                                                                                                  \n activation_10 (Activation)  (None, 128, 128, 64)         0         ['add_8[0][0]']               \n                                                                                                  \n separable_conv2d_9 (Separa  (None, 128, 128, 64)         4672      ['activation_10[0][0]']       \n bleConv2D)                                                                                       \n                                                                                                  \n batch_normalization_11 (Ba  (None, 128, 128, 64)         256       ['separable_conv2d_9[0][0]']  \n tchNormalization)                                                                                \n                                                                                                  \n dropout_9 (Dropout)         (None, 128, 128, 64)         0         ['batch_normalization_11[0][0]\n                                                                    ']                            \n                                                                                                  \n add_9 (Add)                 (None, 128, 128, 64)         0         ['dropout_9[0][0]',           \n                                                                     'activation_10[0][0]']       \n                                                                                                  \n activation_11 (Activation)  (None, 128, 128, 64)         0         ['add_9[0][0]']               \n                                                                                                  \n conv2d_2 (Conv2D)           (None, 64, 64, 64)           36864     ['activation_11[0][0]']       \n                                                                                                  \n max_pooling2d_2 (MaxPoolin  (None, 64, 64, 64)           0         ['activation_11[0][0]']       \n g2D)                                                                                             \n                                                                                                  \n concatenate_2 (Concatenate  (None, 64, 64, 128)          0         ['conv2d_2[0][0]',            \n )                                                                   'max_pooling2d_2[0][0]']     \n                                                                                                  \n batch_normalization_12 (Ba  (None, 64, 64, 128)          512       ['concatenate_2[0][0]']       \n tchNormalization)                                                                                \n                                                                                                  \n activation_12 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_12[0][0]\n                                                                    ']                            \n                                                                                                  \n depthwise_conv2d_2 (Depthw  (None, 64, 64, 128)          1152      ['activation_12[0][0]']       \n iseConv2D)                                                                                       \n                                                                                                  \n depthwise_conv2d_3 (Depthw  (None, 64, 64, 128)          1152      ['activation_12[0][0]']       \n iseConv2D)                                                                                       \n                                                                                                  \n batch_normalization_16 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_2[0][0]']  \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_17 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_3[0][0]']  \n tchNormalization)                                                                                \n                                                                                                  \n activation_16 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_16[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_17 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_17[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_1 (TF  (None, 64, 64, 128)          0         ['activation_16[0][0]',       \n OpLambda)                                                           'activation_17[0][0]']       \n                                                                                                  \n conv2d_4 (Conv2D)           (None, 64, 64, 32)           4096      ['tf.__operators__.add_1[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_18 (Ba  (None, 64, 64, 32)           128       ['conv2d_4[0][0]']            \n tchNormalization)                                                                                \n                                                                                                  \n dropout_11 (Dropout)        (None, 64, 64, 32)           0         ['batch_normalization_18[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_18 (Activation)  (None, 64, 64, 32)           0         ['dropout_11[0][0]']          \n                                                                                                  \n concatenate_3 (Concatenate  (None, 64, 64, 160)          0         ['activation_12[0][0]',       \n )                                                                   'activation_18[0][0]']       \n                                                                                                  \n depthwise_conv2d_4 (Depthw  (None, 64, 64, 160)          1440      ['concatenate_3[0][0]']       \n iseConv2D)                                                                                       \n                                                                                                  \n depthwise_conv2d_5 (Depthw  (None, 64, 64, 160)          1440      ['concatenate_3[0][0]']       \n iseConv2D)                                                                                       \n                                                                                                  \n batch_normalization_19 (Ba  (None, 64, 64, 160)          640       ['depthwise_conv2d_4[0][0]']  \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_20 (Ba  (None, 64, 64, 160)          640       ['depthwise_conv2d_5[0][0]']  \n tchNormalization)                                                                                \n                                                                                                  \n activation_19 (Activation)  (None, 64, 64, 160)          0         ['batch_normalization_19[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_20 (Activation)  (None, 64, 64, 160)          0         ['batch_normalization_20[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_2 (TF  (None, 64, 64, 160)          0         ['activation_19[0][0]',       \n OpLambda)                                                           'activation_20[0][0]']       \n                                                                                                  \n conv2d_5 (Conv2D)           (None, 64, 64, 128)          20480     ['tf.__operators__.add_2[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_21 (Ba  (None, 64, 64, 128)          512       ['conv2d_5[0][0]']            \n tchNormalization)                                                                                \n                                                                                                  \n dropout_12 (Dropout)        (None, 64, 64, 128)          0         ['batch_normalization_21[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_21 (Activation)  (None, 64, 64, 128)          0         ['dropout_12[0][0]']          \n                                                                                                  \n depthwise_conv2d_6 (Depthw  (None, 64, 64, 128)          1152      ['activation_21[0][0]']       \n iseConv2D)                                                                                       \n                                                                                                  \n depthwise_conv2d_7 (Depthw  (None, 64, 64, 128)          1152      ['activation_21[0][0]']       \n iseConv2D)                                                                                       \n                                                                                                  \n batch_normalization_22 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_6[0][0]']  \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_23 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_7[0][0]']  \n tchNormalization)                                                                                \n                                                                                                  \n activation_22 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_22[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_23 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_23[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_3 (TF  (None, 64, 64, 128)          0         ['activation_22[0][0]',       \n OpLambda)                                                           'activation_23[0][0]']       \n                                                                                                  \n conv2d_6 (Conv2D)           (None, 64, 64, 32)           4096      ['tf.__operators__.add_3[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_24 (Ba  (None, 64, 64, 32)           128       ['conv2d_6[0][0]']            \n tchNormalization)                                                                                \n                                                                                                  \n dropout_13 (Dropout)        (None, 64, 64, 32)           0         ['batch_normalization_24[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_24 (Activation)  (None, 64, 64, 32)           0         ['dropout_13[0][0]']          \n                                                                                                  \n concatenate_4 (Concatenate  (None, 64, 64, 192)          0         ['activation_12[0][0]',       \n )                                                                   'activation_18[0][0]',       \n                                                                     'activation_24[0][0]']       \n                                                                                                  \n depthwise_conv2d_8 (Depthw  (None, 64, 64, 192)          1728      ['concatenate_4[0][0]']       \n iseConv2D)                                                                                       \n                                                                                                  \n depthwise_conv2d_9 (Depthw  (None, 64, 64, 192)          1728      ['concatenate_4[0][0]']       \n iseConv2D)                                                                                       \n                                                                                                  \n batch_normalization_25 (Ba  (None, 64, 64, 192)          768       ['depthwise_conv2d_8[0][0]']  \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_26 (Ba  (None, 64, 64, 192)          768       ['depthwise_conv2d_9[0][0]']  \n tchNormalization)                                                                                \n                                                                                                  \n activation_25 (Activation)  (None, 64, 64, 192)          0         ['batch_normalization_25[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_26 (Activation)  (None, 64, 64, 192)          0         ['batch_normalization_26[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_4 (TF  (None, 64, 64, 192)          0         ['activation_25[0][0]',       \n OpLambda)                                                           'activation_26[0][0]']       \n                                                                                                  \n conv2d_7 (Conv2D)           (None, 64, 64, 128)          24576     ['tf.__operators__.add_4[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_27 (Ba  (None, 64, 64, 128)          512       ['conv2d_7[0][0]']            \n tchNormalization)                                                                                \n                                                                                                  \n dropout_14 (Dropout)        (None, 64, 64, 128)          0         ['batch_normalization_27[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_27 (Activation)  (None, 64, 64, 128)          0         ['dropout_14[0][0]']          \n                                                                                                  \n depthwise_conv2d_10 (Depth  (None, 64, 64, 128)          1152      ['activation_27[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n depthwise_conv2d_11 (Depth  (None, 64, 64, 128)          1152      ['activation_27[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n batch_normalization_28 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_10[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_29 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_11[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n activation_28 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_28[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_29 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_29[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_5 (TF  (None, 64, 64, 128)          0         ['activation_28[0][0]',       \n OpLambda)                                                           'activation_29[0][0]']       \n                                                                                                  \n conv2d_8 (Conv2D)           (None, 64, 64, 32)           4096      ['tf.__operators__.add_5[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_30 (Ba  (None, 64, 64, 32)           128       ['conv2d_8[0][0]']            \n tchNormalization)                                                                                \n                                                                                                  \n dropout_15 (Dropout)        (None, 64, 64, 32)           0         ['batch_normalization_30[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_30 (Activation)  (None, 64, 64, 32)           0         ['dropout_15[0][0]']          \n                                                                                                  \n concatenate_5 (Concatenate  (None, 64, 64, 224)          0         ['activation_12[0][0]',       \n )                                                                   'activation_18[0][0]',       \n                                                                     'activation_24[0][0]',       \n                                                                     'activation_30[0][0]']       \n                                                                                                  \n depthwise_conv2d_12 (Depth  (None, 64, 64, 224)          2016      ['concatenate_5[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n depthwise_conv2d_13 (Depth  (None, 64, 64, 224)          2016      ['concatenate_5[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n batch_normalization_31 (Ba  (None, 64, 64, 224)          896       ['depthwise_conv2d_12[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_32 (Ba  (None, 64, 64, 224)          896       ['depthwise_conv2d_13[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n activation_31 (Activation)  (None, 64, 64, 224)          0         ['batch_normalization_31[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_32 (Activation)  (None, 64, 64, 224)          0         ['batch_normalization_32[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_6 (TF  (None, 64, 64, 224)          0         ['activation_31[0][0]',       \n OpLambda)                                                           'activation_32[0][0]']       \n                                                                                                  \n conv2d_9 (Conv2D)           (None, 64, 64, 128)          28672     ['tf.__operators__.add_6[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_33 (Ba  (None, 64, 64, 128)          512       ['conv2d_9[0][0]']            \n tchNormalization)                                                                                \n                                                                                                  \n dropout_16 (Dropout)        (None, 64, 64, 128)          0         ['batch_normalization_33[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_33 (Activation)  (None, 64, 64, 128)          0         ['dropout_16[0][0]']          \n                                                                                                  \n depthwise_conv2d_14 (Depth  (None, 64, 64, 128)          1152      ['activation_33[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n depthwise_conv2d_15 (Depth  (None, 64, 64, 128)          1152      ['activation_33[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n batch_normalization_34 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_14[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_35 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_15[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n activation_34 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_34[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_35 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_35[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_7 (TF  (None, 64, 64, 128)          0         ['activation_34[0][0]',       \n OpLambda)                                                           'activation_35[0][0]']       \n                                                                                                  \n conv2d_10 (Conv2D)          (None, 64, 64, 32)           4096      ['tf.__operators__.add_7[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_36 (Ba  (None, 64, 64, 32)           128       ['conv2d_10[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n dropout_17 (Dropout)        (None, 64, 64, 32)           0         ['batch_normalization_36[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_36 (Activation)  (None, 64, 64, 32)           0         ['dropout_17[0][0]']          \n                                                                                                  \n concatenate_6 (Concatenate  (None, 64, 64, 256)          0         ['activation_12[0][0]',       \n )                                                                   'activation_18[0][0]',       \n                                                                     'activation_24[0][0]',       \n                                                                     'activation_30[0][0]',       \n                                                                     'activation_36[0][0]']       \n                                                                                                  \n depthwise_conv2d_18 (Depth  (None, 64, 64, 256)          2304      ['concatenate_6[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n depthwise_conv2d_19 (Depth  (None, 64, 64, 256)          2304      ['concatenate_6[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n batch_normalization_40 (Ba  (None, 64, 64, 256)          1024      ['depthwise_conv2d_18[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_41 (Ba  (None, 64, 64, 256)          1024      ['depthwise_conv2d_19[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n activation_40 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_40[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_41 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_41[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_9 (TF  (None, 64, 64, 256)          0         ['activation_40[0][0]',       \n OpLambda)                                                           'activation_41[0][0]']       \n                                                                                                  \n conv2d_12 (Conv2D)          (None, 64, 64, 32)           8192      ['tf.__operators__.add_9[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_42 (Ba  (None, 64, 64, 32)           128       ['conv2d_12[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n dropout_19 (Dropout)        (None, 64, 64, 32)           0         ['batch_normalization_42[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_42 (Activation)  (None, 64, 64, 32)           0         ['dropout_19[0][0]']          \n                                                                                                  \n concatenate_7 (Concatenate  (None, 64, 64, 288)          0         ['concatenate_6[0][0]',       \n )                                                                   'activation_42[0][0]']       \n                                                                                                  \n depthwise_conv2d_20 (Depth  (None, 64, 64, 288)          2592      ['concatenate_7[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n depthwise_conv2d_21 (Depth  (None, 64, 64, 288)          2592      ['concatenate_7[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n batch_normalization_43 (Ba  (None, 64, 64, 288)          1152      ['depthwise_conv2d_20[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_44 (Ba  (None, 64, 64, 288)          1152      ['depthwise_conv2d_21[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n activation_43 (Activation)  (None, 64, 64, 288)          0         ['batch_normalization_43[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_44 (Activation)  (None, 64, 64, 288)          0         ['batch_normalization_44[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_10 (T  (None, 64, 64, 288)          0         ['activation_43[0][0]',       \n FOpLambda)                                                          'activation_44[0][0]']       \n                                                                                                  \n conv2d_13 (Conv2D)          (None, 64, 64, 128)          36864     ['tf.__operators__.add_10[0][0\n                                                                    ]']                           \n                                                                                                  \n batch_normalization_45 (Ba  (None, 64, 64, 128)          512       ['conv2d_13[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n dropout_20 (Dropout)        (None, 64, 64, 128)          0         ['batch_normalization_45[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_45 (Activation)  (None, 64, 64, 128)          0         ['dropout_20[0][0]']          \n                                                                                                  \n depthwise_conv2d_22 (Depth  (None, 64, 64, 128)          1152      ['activation_45[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n depthwise_conv2d_23 (Depth  (None, 64, 64, 128)          1152      ['activation_45[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n batch_normalization_46 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_22[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_47 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_23[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n activation_46 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_46[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_47 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_47[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_11 (T  (None, 64, 64, 128)          0         ['activation_46[0][0]',       \n FOpLambda)                                                          'activation_47[0][0]']       \n                                                                                                  \n conv2d_14 (Conv2D)          (None, 64, 64, 32)           4096      ['tf.__operators__.add_11[0][0\n                                                                    ]']                           \n                                                                                                  \n batch_normalization_48 (Ba  (None, 64, 64, 32)           128       ['conv2d_14[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n dropout_21 (Dropout)        (None, 64, 64, 32)           0         ['batch_normalization_48[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_48 (Activation)  (None, 64, 64, 32)           0         ['dropout_21[0][0]']          \n                                                                                                  \n concatenate_8 (Concatenate  (None, 64, 64, 320)          0         ['concatenate_6[0][0]',       \n )                                                                   'activation_42[0][0]',       \n                                                                     'activation_48[0][0]']       \n                                                                                                  \n depthwise_conv2d_24 (Depth  (None, 64, 64, 320)          2880      ['concatenate_8[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n depthwise_conv2d_25 (Depth  (None, 64, 64, 320)          2880      ['concatenate_8[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n batch_normalization_49 (Ba  (None, 64, 64, 320)          1280      ['depthwise_conv2d_24[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_50 (Ba  (None, 64, 64, 320)          1280      ['depthwise_conv2d_25[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n activation_49 (Activation)  (None, 64, 64, 320)          0         ['batch_normalization_49[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_50 (Activation)  (None, 64, 64, 320)          0         ['batch_normalization_50[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_12 (T  (None, 64, 64, 320)          0         ['activation_49[0][0]',       \n FOpLambda)                                                          'activation_50[0][0]']       \n                                                                                                  \n conv2d_15 (Conv2D)          (None, 64, 64, 128)          40960     ['tf.__operators__.add_12[0][0\n                                                                    ]']                           \n                                                                                                  \n batch_normalization_51 (Ba  (None, 64, 64, 128)          512       ['conv2d_15[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n dropout_22 (Dropout)        (None, 64, 64, 128)          0         ['batch_normalization_51[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_51 (Activation)  (None, 64, 64, 128)          0         ['dropout_22[0][0]']          \n                                                                                                  \n depthwise_conv2d_26 (Depth  (None, 64, 64, 128)          1152      ['activation_51[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n depthwise_conv2d_27 (Depth  (None, 64, 64, 128)          1152      ['activation_51[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n batch_normalization_52 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_26[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_53 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_27[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n activation_52 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_52[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_53 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_53[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_13 (T  (None, 64, 64, 128)          0         ['activation_52[0][0]',       \n FOpLambda)                                                          'activation_53[0][0]']       \n                                                                                                  \n conv2d_16 (Conv2D)          (None, 64, 64, 32)           4096      ['tf.__operators__.add_13[0][0\n                                                                    ]']                           \n                                                                                                  \n batch_normalization_54 (Ba  (None, 64, 64, 32)           128       ['conv2d_16[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n dropout_23 (Dropout)        (None, 64, 64, 32)           0         ['batch_normalization_54[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_54 (Activation)  (None, 64, 64, 32)           0         ['dropout_23[0][0]']          \n                                                                                                  \n concatenate_9 (Concatenate  (None, 64, 64, 352)          0         ['concatenate_6[0][0]',       \n )                                                                   'activation_42[0][0]',       \n                                                                     'activation_48[0][0]',       \n                                                                     'activation_54[0][0]']       \n                                                                                                  \n depthwise_conv2d_28 (Depth  (None, 64, 64, 352)          3168      ['concatenate_9[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n depthwise_conv2d_29 (Depth  (None, 64, 64, 352)          3168      ['concatenate_9[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n batch_normalization_55 (Ba  (None, 64, 64, 352)          1408      ['depthwise_conv2d_28[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_56 (Ba  (None, 64, 64, 352)          1408      ['depthwise_conv2d_29[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n activation_55 (Activation)  (None, 64, 64, 352)          0         ['batch_normalization_55[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_56 (Activation)  (None, 64, 64, 352)          0         ['batch_normalization_56[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_14 (T  (None, 64, 64, 352)          0         ['activation_55[0][0]',       \n FOpLambda)                                                          'activation_56[0][0]']       \n                                                                                                  \n conv2d_17 (Conv2D)          (None, 64, 64, 128)          45056     ['tf.__operators__.add_14[0][0\n                                                                    ]']                           \n                                                                                                  \n batch_normalization_57 (Ba  (None, 64, 64, 128)          512       ['conv2d_17[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n dropout_24 (Dropout)        (None, 64, 64, 128)          0         ['batch_normalization_57[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_57 (Activation)  (None, 64, 64, 128)          0         ['dropout_24[0][0]']          \n                                                                                                  \n depthwise_conv2d_30 (Depth  (None, 64, 64, 128)          1152      ['activation_57[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n depthwise_conv2d_31 (Depth  (None, 64, 64, 128)          1152      ['activation_57[0][0]']       \n wiseConv2D)                                                                                      \n                                                                                                  \n batch_normalization_58 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_30[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_59 (Ba  (None, 64, 64, 128)          512       ['depthwise_conv2d_31[0][0]'] \n tchNormalization)                                                                                \n                                                                                                  \n activation_58 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_58[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_59 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_59[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_15 (T  (None, 64, 64, 128)          0         ['activation_58[0][0]',       \n FOpLambda)                                                          'activation_59[0][0]']       \n                                                                                                  \n conv2d_18 (Conv2D)          (None, 64, 64, 32)           4096      ['tf.__operators__.add_15[0][0\n                                                                    ]']                           \n                                                                                                  \n batch_normalization_60 (Ba  (None, 64, 64, 32)           128       ['conv2d_18[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n dropout_25 (Dropout)        (None, 64, 64, 32)           0         ['batch_normalization_60[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_60 (Activation)  (None, 64, 64, 32)           0         ['dropout_25[0][0]']          \n                                                                                                  \n concatenate_10 (Concatenat  (None, 64, 64, 384)          0         ['concatenate_6[0][0]',       \n e)                                                                  'activation_42[0][0]',       \n                                                                     'activation_48[0][0]',       \n                                                                     'activation_54[0][0]',       \n                                                                     'activation_60[0][0]']       \n                                                                                                  \n conv2d_transpose (Conv2DTr  (None, 128, 128, 64)         221248    ['concatenate_10[0][0]']      \n anspose)                                                                                         \n                                                                                                  \n batch_normalization_61 (Ba  (None, 128, 128, 64)         256       ['conv2d_transpose[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n activation_61 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_61[0][0]\n                                                                    ']                            \n                                                                                                  \n tf.__operators__.add_16 (T  (None, 128, 128, 64)         0         ['activation_61[0][0]',       \n FOpLambda)                                                          'activation_1[0][0]']        \n                                                                                                  \n conv2d_transpose_1 (Conv2D  (None, 256, 256, 16)         9232      ['tf.__operators__.add_16[0][0\n Transpose)                                                         ]']                           \n                                                                                                  \n concatenate_11 (Concatenat  (None, 256, 256, 32)         0         ['conv2d_transpose_1[0][0]',  \n e)                                                                  'activation[0][0]']          \n                                                                                                  \n separable_conv2d_12 (Separ  (None, 64, 64, 32)           1312      ['concatenate_11[0][0]']      \n ableConv2D)                                                                                      \n                                                                                                  \n separable_conv2d_11 (Separ  (None, 128, 128, 32)         1312      ['concatenate_11[0][0]']      \n ableConv2D)                                                                                      \n                                                                                                  \n separable_conv2d_10 (Separ  (None, 256, 256, 32)         1312      ['concatenate_11[0][0]']      \n ableConv2D)                                                                                      \n                                                                                                  \n separable_conv2d_15 (Separ  (None, 64, 64, 32)           1312      ['separable_conv2d_12[0][0]'] \n ableConv2D)                                                                                      \n                                                                                                  \n separable_conv2d_14 (Separ  (None, 128, 128, 32)         1312      ['separable_conv2d_11[0][0]'] \n ableConv2D)                                                                                      \n                                                                                                  \n separable_conv2d_13 (Separ  (None, 256, 256, 32)         1312      ['separable_conv2d_10[0][0]'] \n ableConv2D)                                                                                      \n                                                                                                  \n conv2d_transpose_3 (Conv2D  (None, 256, 256, 32)         9248      ['separable_conv2d_15[0][0]'] \n Transpose)                                                                                       \n                                                                                                  \n conv2d_transpose_2 (Conv2D  (None, 256, 256, 32)         9248      ['separable_conv2d_14[0][0]'] \n Transpose)                                                                                       \n                                                                                                  \n conv2d_19 (Conv2D)          (None, 256, 256, 32)         1056      ['separable_conv2d_13[0][0]'] \n                                                                                                  \n concatenate_12 (Concatenat  (None, 256, 256, 96)         0         ['conv2d_transpose_3[0][0]',  \n e)                                                                  'conv2d_transpose_2[0][0]',  \n                                                                     'conv2d_19[0][0]']           \n                                                                                                  \n separable_conv2d_16 (Separ  (None, 256, 256, 32)         3936      ['concatenate_12[0][0]']      \n ableConv2D)                                                                                      \n                                                                                                  \n separable_conv2d_17 (Separ  (None, 256, 256, 32)         3936      ['concatenate_12[0][0]']      \n ableConv2D)                                                                                      \n                                                                                                  \n separable_conv2d_18 (Separ  (None, 256, 256, 32)         3936      ['concatenate_12[0][0]']      \n ableConv2D)                                                                                      \n                                                                                                  \n separable_conv2d_19 (Separ  (None, 256, 256, 32)         3936      ['concatenate_12[0][0]']      \n ableConv2D)                                                                                      \n                                                                                                  \n concatenate_13 (Concatenat  (None, 256, 256, 128)        0         ['separable_conv2d_16[0][0]', \n e)                                                                  'separable_conv2d_17[0][0]', \n                                                                     'separable_conv2d_18[0][0]', \n                                                                     'separable_conv2d_19[0][0]'] \n                                                                                                  \n conv2d_20 (Conv2D)          (None, 256, 256, 32)         4128      ['concatenate_13[0][0]']      \n                                                                                                  \n conv2d_21 (Conv2D)          (None, 256, 256, 1)          33        ['conv2d_20[0][0]']           \n                                                                                                  \n resizing (Resizing)         (None, 512, 512, 1)          0         ['conv2d_21[0][0]']           \n                                                                                                  \n==================================================================================================\nTotal params: 679760 (2.59 MB)\nTrainable params: 665136 (2.54 MB)\nNon-trainable params: 14624 (57.12 KB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#calculate_flops_and_params(dppnetmodel)","metadata":{"_uuid":"603137da-59e7-4c78-a29c-0b4cd27ae755","_cell_guid":"bc5f08cd-20eb-46ee-894a-b6c0fab191b4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:26.131355Z","iopub.execute_input":"2024-02-09T05:23:26.131649Z","iopub.status.idle":"2024-02-09T05:23:26.137301Z","shell.execute_reply.started":"2024-02-09T05:23:26.131623Z","shell.execute_reply":"2024-02-09T05:23:26.136299Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"opt = Adam(learning_rate=0.001)\ndppnetmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', iou_coef])","metadata":{"_uuid":"a18cc173-439f-4e3c-b019-67db9f901361","_cell_guid":"42c9c4f9-b6b2-4f92-8198-7cdc313c9a72","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:26.138875Z","iopub.execute_input":"2024-02-09T05:23:26.139165Z","iopub.status.idle":"2024-02-09T05:23:26.169270Z","shell.execute_reply.started":"2024-02-09T05:23:26.139142Z","shell.execute_reply":"2024-02-09T05:23:26.168441Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# model_checkpoint = ModelCheckpoint('./building_dppnet.h5', monitor='val_loss', save_best_only=True) \n# callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=3, restore_best_weights=True)\n# history = dppnetmodel.fit(train_dataset, validation_data=(x_val,y_val), epochs=50, verbose=1, callbacks=[model_checkpoint,callback])","metadata":{"_uuid":"1d8d9d4b-bd3a-461b-acf8-28b2e3f867b9","_cell_guid":"77d0deec-8cbb-4937-b275-1b1c83546310","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:26.181815Z","iopub.execute_input":"2024-02-09T05:23:26.182416Z","iopub.status.idle":"2024-02-09T05:23:26.186506Z","shell.execute_reply.started":"2024-02-09T05:23:26.182383Z","shell.execute_reply":"2024-02-09T05:23:26.185472Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"callbacks = create_callbacks()\nhistory = dppnetmodel.fit(train_dataset, validation_data=(x_val,y_val), batch_size=2,shuffle=True, verbose=1\n                                  ,epochs = 100, callbacks = callbacks )\n","metadata":{"_uuid":"82fee656-1148-4ffd-9178-f13d522b396b","_cell_guid":"355fcc80-c2af-445d-9733-85845b9d48e5","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T05:23:26.187933Z","iopub.execute_input":"2024-02-09T05:23:26.188608Z","iopub.status.idle":"2024-02-09T06:59:34.623468Z","shell.execute_reply.started":"2024-02-09T05:23:26.188556Z","shell.execute_reply":"2024-02-09T06:59:34.622422Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2024-02-09 05:23:44.014635: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout_11/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"617/617 [==============================] - ETA: 0s - loss: 0.3420 - accuracy: 0.8817 - iou_coef: 0.1509\nEpoch 1: val_loss improved from inf to 0.30959, saving model to ./dpp_building.h5\n617/617 [==============================] - 140s 166ms/step - loss: 0.3420 - accuracy: 0.8817 - iou_coef: 0.1509 - val_loss: 0.3096 - val_accuracy: 0.9058 - val_iou_coef: 0.1409 - lr: 0.0010\nEpoch 2/100\n617/617 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.8994 - iou_coef: 0.2290\nEpoch 2: val_loss improved from 0.30959 to 0.24520, saving model to ./dpp_building.h5\n617/617 [==============================] - 101s 164ms/step - loss: 0.2760 - accuracy: 0.8994 - iou_coef: 0.2290 - val_loss: 0.2452 - val_accuracy: 0.9138 - val_iou_coef: 0.2103 - lr: 0.0010\nEpoch 3/100\n617/617 [==============================] - ETA: 0s - loss: 0.2541 - accuracy: 0.9068 - iou_coef: 0.2590\nEpoch 3: val_loss improved from 0.24520 to 0.22884, saving model to ./dpp_building.h5\n617/617 [==============================] - 101s 164ms/step - loss: 0.2541 - accuracy: 0.9068 - iou_coef: 0.2590 - val_loss: 0.2288 - val_accuracy: 0.9165 - val_iou_coef: 0.2332 - lr: 0.0010\nEpoch 4/100\n617/617 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.9124 - iou_coef: 0.2836\nEpoch 4: val_loss did not improve from 0.22884\n617/617 [==============================] - 101s 164ms/step - loss: 0.2383 - accuracy: 0.9124 - iou_coef: 0.2836 - val_loss: 0.2363 - val_accuracy: 0.9191 - val_iou_coef: 0.2514 - lr: 0.0010\nEpoch 5/100\n617/617 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9157 - iou_coef: 0.2984\nEpoch 5: val_loss did not improve from 0.22884\n617/617 [==============================] - 101s 164ms/step - loss: 0.2295 - accuracy: 0.9157 - iou_coef: 0.2984 - val_loss: 0.2682 - val_accuracy: 0.9176 - val_iou_coef: 0.2373 - lr: 0.0010\nEpoch 6/100\n617/617 [==============================] - ETA: 0s - loss: 0.2243 - accuracy: 0.9181 - iou_coef: 0.3081\nEpoch 6: val_loss improved from 0.22884 to 0.22116, saving model to ./dpp_building.h5\n617/617 [==============================] - 101s 164ms/step - loss: 0.2243 - accuracy: 0.9181 - iou_coef: 0.3081 - val_loss: 0.2212 - val_accuracy: 0.9269 - val_iou_coef: 0.3129 - lr: 0.0010\nEpoch 7/100\n617/617 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.9210 - iou_coef: 0.3234\nEpoch 7: val_loss did not improve from 0.22116\n617/617 [==============================] - 101s 164ms/step - loss: 0.2156 - accuracy: 0.9210 - iou_coef: 0.3234 - val_loss: 0.3185 - val_accuracy: 0.9152 - val_iou_coef: 0.2215 - lr: 0.0010\nEpoch 8/100\n617/617 [==============================] - ETA: 0s - loss: 0.2083 - accuracy: 0.9237 - iou_coef: 0.3363\nEpoch 8: val_loss did not improve from 0.22116\n617/617 [==============================] - 101s 163ms/step - loss: 0.2083 - accuracy: 0.9237 - iou_coef: 0.3363 - val_loss: 0.2711 - val_accuracy: 0.9244 - val_iou_coef: 0.2833 - lr: 0.0010\nEpoch 9/100\n617/617 [==============================] - ETA: 0s - loss: 0.2037 - accuracy: 0.9254 - iou_coef: 0.3452\nEpoch 9: val_loss did not improve from 0.22116\n617/617 [==============================] - 101s 163ms/step - loss: 0.2037 - accuracy: 0.9254 - iou_coef: 0.3452 - val_loss: 0.2977 - val_accuracy: 0.9168 - val_iou_coef: 0.2371 - lr: 0.0010\nEpoch 10/100\n617/617 [==============================] - ETA: 0s - loss: 0.1828 - accuracy: 0.9340 - iou_coef: 0.3918\nEpoch 18: val_loss did not improve from 0.19210\n617/617 [==============================] - 100s 163ms/step - loss: 0.1828 - accuracy: 0.9340 - iou_coef: 0.3918 - val_loss: 0.2090 - val_accuracy: 0.9332 - val_iou_coef: 0.3563 - lr: 0.0010\nEpoch 19/100\n617/617 [==============================] - ETA: 0s - loss: 0.1799 - accuracy: 0.9351 - iou_coef: 0.3985\nEpoch 19: val_loss improved from 0.19210 to 0.18832, saving model to ./dpp_building.h5\n617/617 [==============================] - 101s 163ms/step - loss: 0.1799 - accuracy: 0.9351 - iou_coef: 0.3985 - val_loss: 0.1883 - val_accuracy: 0.9374 - val_iou_coef: 0.4076 - lr: 0.0010\nEpoch 20/100\n617/617 [==============================] - ETA: 0s - loss: 0.1801 - accuracy: 0.9351 - iou_coef: 0.3980\nEpoch 20: val_loss did not improve from 0.18832\n617/617 [==============================] - 100s 163ms/step - loss: 0.1801 - accuracy: 0.9351 - iou_coef: 0.3980 - val_loss: 0.2096 - val_accuracy: 0.9312 - val_iou_coef: 0.3658 - lr: 0.0010\nEpoch 21/100\n617/617 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.9355 - iou_coef: 0.4006\nEpoch 21: val_loss did not improve from 0.18832\n617/617 [==============================] - 101s 163ms/step - loss: 0.1794 - accuracy: 0.9355 - iou_coef: 0.4006 - val_loss: 0.2229 - val_accuracy: 0.9307 - val_iou_coef: 0.3511 - lr: 0.0010\nEpoch 22/100\n617/617 [==============================] - ETA: 0s - loss: 0.1774 - accuracy: 0.9363 - iou_coef: 0.4050\nEpoch 22: val_loss improved from 0.18832 to 0.18368, saving model to ./dpp_building.h5\n617/617 [==============================] - 101s 163ms/step - loss: 0.1774 - accuracy: 0.9363 - iou_coef: 0.4050 - val_loss: 0.1837 - val_accuracy: 0.9360 - val_iou_coef: 0.4134 - lr: 0.0010\nEpoch 23/100\n617/617 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.9369 - iou_coef: 0.4099\nEpoch 23: val_loss did not improve from 0.18368\n617/617 [==============================] - 100s 162ms/step - loss: 0.1753 - accuracy: 0.9369 - iou_coef: 0.4099 - val_loss: 0.1891 - val_accuracy: 0.9297 - val_iou_coef: 0.3880 - lr: 0.0010\nEpoch 24/100\n617/617 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.9370 - iou_coef: 0.4093\nEpoch 24: val_loss did not improve from 0.18368\n617/617 [==============================] - 100s 163ms/step - loss: 0.1756 - accuracy: 0.9370 - iou_coef: 0.4093 - val_loss: 0.2156 - val_accuracy: 0.9338 - val_iou_coef: 0.3671 - lr: 0.0010\nEpoch 25/100\n617/617 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.9373 - iou_coef: 0.4115\nEpoch 25: val_loss did not improve from 0.18368\n617/617 [==============================] - 100s 162ms/step - loss: 0.1754 - accuracy: 0.9373 - iou_coef: 0.4115 - val_loss: 0.2115 - val_accuracy: 0.9332 - val_iou_coef: 0.3774 - lr: 0.0010\nEpoch 26/100\n617/617 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.9367 - iou_coef: 0.4093\nEpoch 26: val_loss did not improve from 0.18368\n617/617 [==============================] - 100s 162ms/step - loss: 0.1762 - accuracy: 0.9367 - iou_coef: 0.4093 - val_loss: 0.2206 - val_accuracy: 0.9207 - val_iou_coef: 0.3811 - lr: 0.0010\nEpoch 27/100\n617/617 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.9372 - iou_coef: 0.4104\nEpoch 27: val_loss improved from 0.18368 to 0.18052, saving model to ./dpp_building.h5\n617/617 [==============================] - 100s 163ms/step - loss: 0.1754 - accuracy: 0.9372 - iou_coef: 0.4104 - val_loss: 0.1805 - val_accuracy: 0.9381 - val_iou_coef: 0.3930 - lr: 0.0010\nEpoch 28/100\n617/617 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.9380 - iou_coef: 0.4161\nEpoch 28: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1731 - accuracy: 0.9380 - iou_coef: 0.4161 - val_loss: 0.1871 - val_accuracy: 0.9381 - val_iou_coef: 0.4350 - lr: 0.0010\nEpoch 29/100\n617/617 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.9389 - iou_coef: 0.4206\nEpoch 29: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1707 - accuracy: 0.9389 - iou_coef: 0.4206 - val_loss: 0.2295 - val_accuracy: 0.9310 - val_iou_coef: 0.3456 - lr: 0.0010\nEpoch 30/100\n617/617 [==============================] - ETA: 0s - loss: 0.1713 - accuracy: 0.9386 - iou_coef: 0.4190\nEpoch 30: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1713 - accuracy: 0.9386 - iou_coef: 0.4190 - val_loss: 0.1985 - val_accuracy: 0.9366 - val_iou_coef: 0.3834 - lr: 0.0010\nEpoch 31/100\n617/617 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9384 - iou_coef: 0.4183\nEpoch 31: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 163ms/step - loss: 0.1723 - accuracy: 0.9384 - iou_coef: 0.4183 - val_loss: 0.1816 - val_accuracy: 0.9412 - val_iou_coef: 0.4486 - lr: 0.0010\nEpoch 32/100\n617/617 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9388 - iou_coef: 0.4213\nEpoch 32: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 163ms/step - loss: 0.1711 - accuracy: 0.9388 - iou_coef: 0.4213 - val_loss: 0.2253 - val_accuracy: 0.9307 - val_iou_coef: 0.3553 - lr: 0.0010\nEpoch 33/100\n617/617 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9385 - iou_coef: 0.4187\nEpoch 33: val_loss did not improve from 0.18052\n617/617 [==============================] - 101s 163ms/step - loss: 0.1723 - accuracy: 0.9385 - iou_coef: 0.4187 - val_loss: 0.1858 - val_accuracy: 0.9385 - val_iou_coef: 0.4032 - lr: 0.0010\nEpoch 34/100\n617/617 [==============================] - ETA: 0s - loss: 0.1698 - accuracy: 0.9396 - iou_coef: 0.4250\nEpoch 34: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 163ms/step - loss: 0.1698 - accuracy: 0.9396 - iou_coef: 0.4250 - val_loss: 0.1944 - val_accuracy: 0.9388 - val_iou_coef: 0.4194 - lr: 0.0010\nEpoch 35/100\n617/617 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.9402 - iou_coef: 0.4293\nEpoch 35: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1675 - accuracy: 0.9402 - iou_coef: 0.4293 - val_loss: 0.1851 - val_accuracy: 0.9387 - val_iou_coef: 0.4152 - lr: 0.0010\nEpoch 36/100\n617/617 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9393 - iou_coef: 0.4250\nEpoch 36: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1694 - accuracy: 0.9393 - iou_coef: 0.4250 - val_loss: 0.1870 - val_accuracy: 0.9402 - val_iou_coef: 0.4321 - lr: 0.0010\nEpoch 37/100\n617/617 [==============================] - ETA: 0s - loss: 0.1684 - accuracy: 0.9400 - iou_coef: 0.4276\nEpoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 37: val_loss did not improve from 0.18052\n617/617 [==============================] - 101s 163ms/step - loss: 0.1684 - accuracy: 0.9400 - iou_coef: 0.4276 - val_loss: 0.2146 - val_accuracy: 0.9356 - val_iou_coef: 0.3800 - lr: 0.0010\nEpoch 38/100\n617/617 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.9413 - iou_coef: 0.4375\nEpoch 38: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1644 - accuracy: 0.9413 - iou_coef: 0.4375 - val_loss: 0.2038 - val_accuracy: 0.9377 - val_iou_coef: 0.3945 - lr: 5.0000e-04\nEpoch 39/100\n617/617 [==============================] - ETA: 0s - loss: 0.1590 - accuracy: 0.9430 - iou_coef: 0.4484\nEpoch 39: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 163ms/step - loss: 0.1590 - accuracy: 0.9430 - iou_coef: 0.4484 - val_loss: 0.2232 - val_accuracy: 0.9358 - val_iou_coef: 0.3878 - lr: 5.0000e-04\nEpoch 40/100\n617/617 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 0.9437 - iou_coef: 0.4534\nEpoch 40: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1566 - accuracy: 0.9437 - iou_coef: 0.4534 - val_loss: 0.2333 - val_accuracy: 0.9342 - val_iou_coef: 0.3715 - lr: 5.0000e-04\nEpoch 41/100\n617/617 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.9442 - iou_coef: 0.4572\nEpoch 41: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1546 - accuracy: 0.9442 - iou_coef: 0.4572 - val_loss: 0.2048 - val_accuracy: 0.9378 - val_iou_coef: 0.3949 - lr: 5.0000e-04\nEpoch 42/100\n617/617 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.9441 - iou_coef: 0.4562\nEpoch 42: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1546 - accuracy: 0.9441 - iou_coef: 0.4562 - val_loss: 0.2128 - val_accuracy: 0.9378 - val_iou_coef: 0.3908 - lr: 5.0000e-04\nEpoch 43/100\n617/617 [==============================] - ETA: 0s - loss: 0.1545 - accuracy: 0.9440 - iou_coef: 0.4560\nEpoch 43: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1545 - accuracy: 0.9440 - iou_coef: 0.4560 - val_loss: 0.2092 - val_accuracy: 0.9380 - val_iou_coef: 0.3915 - lr: 5.0000e-04\nEpoch 44/100\n617/617 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 0.9446 - iou_coef: 0.4596\nEpoch 44: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 163ms/step - loss: 0.1530 - accuracy: 0.9446 - iou_coef: 0.4596 - val_loss: 0.2033 - val_accuracy: 0.9390 - val_iou_coef: 0.4114 - lr: 5.0000e-04\nEpoch 45/100\n617/617 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.9447 - iou_coef: 0.4617\nEpoch 45: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1524 - accuracy: 0.9447 - iou_coef: 0.4617 - val_loss: 0.2298 - val_accuracy: 0.9345 - val_iou_coef: 0.3691 - lr: 5.0000e-04\nEpoch 46/100\n617/617 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.9453 - iou_coef: 0.4644\nEpoch 46: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1508 - accuracy: 0.9453 - iou_coef: 0.4644 - val_loss: 0.2049 - val_accuracy: 0.9385 - val_iou_coef: 0.3982 - lr: 5.0000e-04\nEpoch 47/100\n617/617 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.9454 - iou_coef: 0.4665\nEpoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 47: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1501 - accuracy: 0.9454 - iou_coef: 0.4665 - val_loss: 0.2044 - val_accuracy: 0.9383 - val_iou_coef: 0.3972 - lr: 5.0000e-04\nEpoch 48/100\n617/617 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.9454 - iou_coef: 0.4667\nEpoch 48: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1495 - accuracy: 0.9454 - iou_coef: 0.4667 - val_loss: 0.2114 - val_accuracy: 0.9388 - val_iou_coef: 0.4013 - lr: 2.5000e-04\nEpoch 49/100\n617/617 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.9466 - iou_coef: 0.4747\nEpoch 49: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1463 - accuracy: 0.9466 - iou_coef: 0.4747 - val_loss: 0.2075 - val_accuracy: 0.9399 - val_iou_coef: 0.4114 - lr: 2.5000e-04\nEpoch 50/100\n617/617 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.9471 - iou_coef: 0.4799\nEpoch 50: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1443 - accuracy: 0.9471 - iou_coef: 0.4799 - val_loss: 0.2303 - val_accuracy: 0.9377 - val_iou_coef: 0.3934 - lr: 2.5000e-04\nEpoch 51/100\n617/617 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.9475 - iou_coef: 0.4822\nEpoch 51: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1433 - accuracy: 0.9475 - iou_coef: 0.4822 - val_loss: 0.2173 - val_accuracy: 0.9386 - val_iou_coef: 0.4035 - lr: 2.5000e-04\nEpoch 52/100\n617/617 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.9475 - iou_coef: 0.4825\nEpoch 52: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 163ms/step - loss: 0.1429 - accuracy: 0.9475 - iou_coef: 0.4825 - val_loss: 0.2201 - val_accuracy: 0.9383 - val_iou_coef: 0.4044 - lr: 2.5000e-04\nEpoch 53/100\n617/617 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.9478 - iou_coef: 0.4853\nEpoch 53: val_loss did not improve from 0.18052\n617/617 [==============================] - 101s 163ms/step - loss: 0.1418 - accuracy: 0.9478 - iou_coef: 0.4853 - val_loss: 0.2229 - val_accuracy: 0.9381 - val_iou_coef: 0.4007 - lr: 2.5000e-04\nEpoch 54/100\n617/617 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.9479 - iou_coef: 0.4864\nEpoch 54: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1414 - accuracy: 0.9479 - iou_coef: 0.4864 - val_loss: 0.2209 - val_accuracy: 0.9384 - val_iou_coef: 0.3982 - lr: 2.5000e-04\nEpoch 55/100\n617/617 [==============================] - ETA: 0s - loss: 0.1406 - accuracy: 0.9482 - iou_coef: 0.4876\nEpoch 55: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1406 - accuracy: 0.9482 - iou_coef: 0.4876 - val_loss: 0.2101 - val_accuracy: 0.9400 - val_iou_coef: 0.4164 - lr: 2.5000e-04\nEpoch 56/100\n617/617 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9482 - iou_coef: 0.4879\nEpoch 56: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 162ms/step - loss: 0.1403 - accuracy: 0.9482 - iou_coef: 0.4879 - val_loss: 0.2085 - val_accuracy: 0.9399 - val_iou_coef: 0.4112 - lr: 2.5000e-04\nEpoch 57/100\n617/617 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.9484 - iou_coef: 0.4896\nEpoch 57: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\nRestoring model weights from the end of the best epoch: 27.\n\nEpoch 57: val_loss did not improve from 0.18052\n617/617 [==============================] - 100s 163ms/step - loss: 0.1397 - accuracy: 0.9484 - iou_coef: 0.4896 - val_loss: 0.2122 - val_accuracy: 0.9393 - val_iou_coef: 0.4106 - lr: 2.5000e-04\nEpoch 57: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"plot_history(history)","metadata":{"_uuid":"1b31d836-ec1f-4f12-afab-686c88db761e","_cell_guid":"2473146c-531a-4435-9574-680792be789c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T06:59:34.624794Z","iopub.execute_input":"2024-02-09T06:59:34.625090Z","iopub.status.idle":"2024-02-09T06:59:35.292705Z","shell.execute_reply.started":"2024-02-09T06:59:34.625065Z","shell.execute_reply":"2024-02-09T06:59:35.287938Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dppnetmodel.load_weights('/kaggle/input/dpp-building/dppnet_building.h5')\n# dppnetmodel.save('/kaggle/input/dpp-building/dppnet_building.h5')","metadata":{"_uuid":"1c561dc8-4afa-40d2-8227-7530da358705","_cell_guid":"0856765f-6acc-4287-84be-a7840e17e9a1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T06:59:35.294007Z","iopub.execute_input":"2024-02-09T06:59:35.294686Z","iopub.status.idle":"2024-02-09T06:59:35.298912Z","shell.execute_reply.started":"2024-02-09T06:59:35.294645Z","shell.execute_reply":"2024-02-09T06:59:35.297966Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n\n# try:\n#     dppnetmodel = tf.keras.models.load_model('/kaggle/input/dpp-building/dppnet_building.h5')\n#     y_pred = dppnetmodel.predict(x_test)\n#     y_pred = y_pred > 0.5\n# except Exception as e:\n#     print(\"Error loading the model:\", e)","metadata":{"_uuid":"52849bd9-3a77-4b7e-a9f8-789515c39f2f","_cell_guid":"55bdd267-7a2f-4064-9d58-ffa38d0d92e2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T06:59:35.300094Z","iopub.execute_input":"2024-02-09T06:59:35.300368Z","iopub.status.idle":"2024-02-09T06:59:35.308356Z","shell.execute_reply.started":"2024-02-09T06:59:35.300343Z","shell.execute_reply":"2024-02-09T06:59:35.307635Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"del train_dataset\ndel x_val\ndel y_val","metadata":{"execution":{"iopub.status.busy":"2024-02-09T07:01:55.230759Z","iopub.execute_input":"2024-02-09T07:01:55.231793Z","iopub.status.idle":"2024-02-09T07:01:55.528079Z","shell.execute_reply.started":"2024-02-09T07:01:55.231758Z","shell.execute_reply":"2024-02-09T07:01:55.527059Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"#dppnetmodel = tf.keras.models.load_model('/kaggle/working/dppnet_building.h5')\n\ny_pred = dppnetmodel.predict(x_test)\ny_pred = y_pred>0.5\n#y_pred","metadata":{"_uuid":"b5cd2137-c223-4b67-9d92-2b4681b12fc4","_cell_guid":"0158e4b1-fdb8-4ae6-8da6-659f3b6704a0","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T07:01:58.735195Z","iopub.execute_input":"2024-02-09T07:01:58.736053Z","iopub.status.idle":"2024-02-09T07:02:09.588053Z","shell.execute_reply.started":"2024-02-09T07:01:58.736021Z","shell.execute_reply":"2024-02-09T07:02:09.586733Z"},"trusted":true},"execution_count":35,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#dppnetmodel = tf.keras.models.load_model('/kaggle/working/dppnet_building.h5')\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mdppnetmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#y_pred\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nOOM when allocating tensor with shape[32,256,256,96] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/concatenate_12/concat-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_227987]"],"ename":"ResourceExhaustedError","evalue":"Graph execution error:\n\nOOM when allocating tensor with shape[32,256,256,96] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/concatenate_12/concat-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_227987]","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"_uuid":"7c4d56e0-30f8-41bb-af0e-1cfc1f42a413","_cell_guid":"4c48fd48-ecdd-4f41-9d15-7bce09b6ced2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T07:00:10.939361Z","iopub.status.idle":"2024-02-09T07:00:10.939706Z","shell.execute_reply.started":"2024-02-09T07:00:10.939528Z","shell.execute_reply":"2024-02-09T07:00:10.939543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_predictions(x_test, y_test, y_pred, num_samples=9)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T07:00:10.940980Z","iopub.status.idle":"2024-02-09T07:00:10.941295Z","shell.execute_reply.started":"2024-02-09T07:00:10.941138Z","shell.execute_reply":"2024-02-09T07:00:10.941153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig=plt.figure()\n# fig.figsize=(50,50)\n\n# ax=fig.add_subplot(1,2,1)\n# ax.imshow(np.reshape(y_test[4],(512,512)),cmap=\"gray\")\n# plt.axis('off')\n# plt.title(\"Ground-truth\")\n\n# ax=fig.add_subplot(1,2,2)\n# ax.imshow(np.reshape(y_pred[4],(512,512)),cmap=\"gray\")\n# plt.axis('off')\n# plt.title(\"Predicted image\")","metadata":{"_uuid":"3056e0b9-ed4d-4146-8901-ada9e63b8438","_cell_guid":"8a2e1b71-7232-457f-982d-23f7a92457f2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T07:00:10.942529Z","iopub.status.idle":"2024-02-09T07:00:10.942910Z","shell.execute_reply.started":"2024-02-09T07:00:10.942741Z","shell.execute_reply":"2024-02-09T07:00:10.942758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluation_results_dpp = evaluate_segmentation(y_test, y_pred)\nprint(evaluation_results_dpp)","metadata":{"_uuid":"8152a7ce-5038-45a2-8221-0fd052ab265c","_cell_guid":"2a3e2ebb-603b-4f50-83e2-64022735b865","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-09T07:00:10.947069Z","iopub.status.idle":"2024-02-09T07:00:10.947416Z","shell.execute_reply.started":"2024-02-09T07:00:10.947248Z","shell.execute_reply":"2024-02-09T07:00:10.947266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dual Path Morph Unet","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Layer\nfrom tensorflow.keras import initializers, constraints\nfrom tensorflow.python.keras.utils import conv_utils\nfrom tensorflow.keras import backend as K\n\nclass Erosion2D(Layer):\n    def __init__(\n        self,\n        num_filters,\n        kernel_size,\n        strides=(1, 1),\n        padding=\"valid\",\n        kernel_initializer=\"glorot_uniform\",\n        kernel_constraint=None,\n        **kwargs\n    ):\n        super(Erosion2D, self).__init__(**kwargs)\n        self.num_filters = num_filters\n        self.kernel_size = kernel_size\n        self.strides = strides\n        self.padding = padding\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.channel_axis = -1\n\n    def build(self, input_shape):\n        if input_shape[self.channel_axis] is None:\n            raise ValueError(\n                \"The channel dimension of the inputs \"\n                \"should be defined. Found `None`.\"\n            )\n\n        input_dim = input_shape[self.channel_axis]\n        kernel_shape = self.kernel_size + (input_dim, self.num_filters)\n\n        self.kernel = self.add_weight(\n            shape=kernel_shape,\n            initializer=self.kernel_initializer,\n            name=\"kernel\",\n            constraint=self.kernel_constraint,\n        )\n\n        super(Erosion2D, self).build(input_shape)\n\n    def call(self, x):\n        outputs = K.placeholder()\n        for i in range(self.num_filters):\n            out = K.min(\n                self.__erosion2d(x, self.kernel[..., i], self.strides, self.padding),\n                axis=self.channel_axis,\n                keepdims=True,\n            )\n\n            if i == 0:\n                outputs = out\n            else:\n                outputs = K.concatenate([outputs, out])\n\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        space = input_shape[1:-1]\n        new_space = []\n        for i in range(len(space)):\n            new_dim = conv_utils.conv_output_length(\n                space[i],\n                self.kernel_size[i],\n                padding=self.padding,\n                stride=self.strides[i],\n                dilation=1,\n            )\n            new_space.append(new_dim)\n\n        return (input_shape[0],) + tuple(new_space) + (self.num_filters,)\n\n    def __erosion2d(self, x, st_element, strides, padding, rates=(1, 1, 1, 1)):\n        x = tf.nn.erosion2d(\n            x, st_element, (1,) + strides + (1,), rates, padding.upper()\n        )\n        return x\n\nclass Dilation2D(Layer):\n    def __init__(\n        self,\n        num_filters,\n        kernel_size,\n        strides=(1, 1),\n        padding=\"valid\",\n        kernel_initializer=\"glorot_uniform\",\n        kernel_constraint=None,\n        **kwargs\n    ):\n        super(Dilation2D, self).__init__(**kwargs)\n        self.num_filters = num_filters\n        self.kernel_size = kernel_size\n        self.strides = strides\n        self.padding = padding\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.channel_axis = -1\n\n    def build(self, input_shape):\n        if input_shape[self.channel_axis] is None:\n            raise ValueError(\n                \"The channel dimension of the inputs \"\n                \"should be defined. Found `None`.\"\n            )\n\n        input_dim = input_shape[self.channel_axis]\n        kernel_shape = self.kernel_size + (input_dim, self.num_filters)\n\n        self.kernel = self.add_weight(\n            shape=kernel_shape,\n            initializer=self.kernel_initializer,\n            name=\"kernel\",\n            constraint=self.kernel_constraint,\n        )\n\n        super(Dilation2D, self).build(input_shape)\n\n    def call(self, x):\n        for i in range(self.num_filters):\n            out = K.max(\n                self.__dilation2d(x, self.kernel[..., i], self.strides, self.padding),\n                axis=self.channel_axis,\n                keepdims=True,\n            )\n\n            if i == 0:\n                outputs = out\n            else:\n                outputs = K.concatenate([outputs, out])\n\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        space = input_shape[1:-1]\n        new_space = []\n        for i in range(len(space)):\n            new_dim = conv_utils.conv_output_length(\n                space[i],\n                self.kernel_size[i],\n                padding=self.padding,\n                stride=self.strides[i],\n                dilation=1,\n            )\n            new_space.append(new_dim)\n\n        return (input_shape[0],) + tuple(new_space) + (self.num_filters,)\n\n    def __dilation2d(self, x, st_element, strides, padding, rates=(1, 1, 1, 1)):\n        x = tf.nn.dilation2d(\n            x, st_element, (1,) + strides + (1,), rates, padding.upper()\n        )\n        return x\n\nclass CombDense_new(Layer):\n    def __init__(\n        self,\n        units=1,\n        strides=(1, 1),\n        kernel_initializer=\"glorot_uniform\",\n        kernel_constraint=None,\n        use_bias=True,\n        **kwargs\n    ):\n        super(CombDense_new, self).__init__(**kwargs)\n        self.num_node = units\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.channel_axis = -1\n\n    def build(self, input_shape):\n        input_dim = input_shape[-1]\n        super(CombDense_new, self).build(input_shape)\n\n    def call(self, x):\n        d = self.num_node\n        Z = []\n        W = []\n        for i in range(d):\n            Z.append(x[i])\n            W.append(x[d + i])\n            WS = W[0]\n        for i in range(1, len(W)):\n            WS = WS + W[i]\n        Z3_temp = W[0] * Z[0]\n        for i in range(1, len(W)):\n            Z3_temp = Z3_temp + W[i] * Z[i]\n            Z3 = Z3_temp / WS\n        return Z3\n\n    def compute_output_shape(self, input_shape):\n        return (\n            input_shape[0][0],\n            input_shape[0][1],\n            input_shape[0][2],\n            input_shape[0][3],\n        )\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T10:26:34.763985Z","iopub.execute_input":"2024-02-08T10:26:34.764391Z","iopub.status.idle":"2024-02-08T10:26:34.796727Z","shell.execute_reply.started":"2024-02-08T10:26:34.764362Z","shell.execute_reply":"2024-02-08T10:26:34.795526Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nimport keras\nfrom keras.models import Model\nfrom keras.layers import Input, Lambda, BatchNormalization, Conv2D, Activation\nfrom keras.layers import add, dot, concatenate\n\n\ndef _morph_unit(inputs, filters=4, kernel=(3, 3)):\n    erosion = Erosion2D(\n        filters, kernel, padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\"\n    )(inputs)\n    dilation = Dilation2D(\n        filters, kernel, padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\"\n    )(inputs)\n    xc = Concatenate()([erosion, dilation])\n    xc = Conv2D(\n        2 * filters,\n        kernel,\n        padding=\"same\",\n        activation=\"linear\",\n        kernel_initializer=\"he_normal\",\n    )(xc)\n    return xc\n\n\ndef _bn_relu_conv_block(inputs, filters, kernel=(3, 3), stride=(1, 1)):\n    x = Conv2D(\n        filters,\n        kernel,\n        padding=\"same\",\n        use_bias=False,\n        kernel_initializer=\"he_normal\",\n        strides=stride,\n    )(inputs)\n    x = BatchNormalization(axis=-1)(x)\n    x = Activation(\"relu\")(x)\n    return x\n\n\ndef _grouped_morph_block(input, grouped_channels, cardinality):\n    group_morph_list = []\n    for c in range(cardinality):\n        x = Lambda(\n            lambda z: z[:, :, :, c * grouped_channels : (c + 1) * grouped_channels]\n        )(input)\n        x = _morph_unit(x, grouped_channels)\n        group_morph_list.append(x)\n    merged_output = concatenate(group_morph_list, axis=-1)\n    merged_output = BatchNormalization(axis=-1)(merged_output)\n    return merged_output\n\n\ndef _dual_path_block(\n    input,\n    pointwise_filters_a,\n    grouped_conv_filters_b,\n    pointwise_filters_c,\n    filter_increment,\n    cardinality,\n    block_type=\"normal\",\n):\n    grouped_channels = int(grouped_conv_filters_b / cardinality)\n    inputs = concatenate(input, axis=-1) if isinstance(input, list) else input\n    stride = (1, 1)\n\n    if block_type == \"projection\":\n        projection = True\n    elif block_type == \"normal\":\n        projection = False\n    else:\n        raise ValueError('\"block_type\" must be either \"projection\" or \"normal\"')\n\n    if projection:\n        projection_path = _bn_relu_conv_block(\n            inputs,\n            filters=pointwise_filters_c + 2 * filter_increment,\n            kernel=(1, 1),\n            stride=stride,\n        )\n        input_residual_path = Lambda(lambda z: z[:, :, :, :pointwise_filters_c])(\n            projection_path\n        )\n        input_dense_path = Lambda(lambda z: z[:, :, :, pointwise_filters_c:])(\n            projection_path\n        )\n    else:\n        input_residual_path = input[0]\n        input_dense_path = input[1]\n\n    x = _bn_relu_conv_block(inputs, filters=pointwise_filters_a, kernel=(1, 1))\n    x = _grouped_morph_block(\n        x, grouped_channels=grouped_channels, cardinality=cardinality\n    )\n    x = _bn_relu_conv_block(\n        x, filters=pointwise_filters_c + filter_increment, kernel=(1, 1)\n    )\n\n    output_residual_path = Lambda(lambda z: z[:, :, :, :pointwise_filters_c])(x)\n    output_dense_path = Lambda(lambda z: z[:, :, :, pointwise_filters_c:])(x)\n\n    residual_path = add([input_residual_path, output_residual_path])\n    dense_path = concatenate([input_dense_path, output_dense_path], axis=-1)\n    return [residual_path, dense_path]\n\n\ndef _decoder_block(inputs, skip_connection, filters):\n    upsampled_input = Conv2DTranspose(\n        filters=int(ip.shape[-1]), kernel_size=(3, 3), strides=(2, 2), padding=\"same\"\n    )(inputs)\n    concatenated_output = Concatenate()([upsampled_input, skip_connection])\n    concatenated_output = _morph_block(concatenated_output, filters)\n    return concatenated_output\n\n\ndef _morph_block(inputs, num_filters, filter_increment=12, cardinality=6):\n    x = inputs\n    x = _dual_path_block(\n        x,\n        num_filters,\n        num_filters,\n        num_filters,\n        filter_increment,\n        cardinality,\n        \"projection\",\n    )\n    x = _dual_path_block(\n        x,\n        num_filters,\n        num_filters,\n        num_filters,\n        filter_increment,\n        cardinality,\n        \"normal\",\n    )\n    x = concatenate(x, axis=-1)\n    return x\n\n\ndef DPM_UNet(input_shape=(256, 256, 3)):\n    inputs = Input(shape=input_shape)\n    morph_ip = _morph_unit(ip, 6)\n\n    E1 = _morph_block(morph_ip, 12)\n    pool1 = AveragePooling2D(pool_size=(2, 2))(E1)\n\n    E2 = _morph_block(pool1, 12 * 2)\n    pool2 = AveragePooling2D(pool_size=(2, 2))(E2)\n\n    E3 = _morph_block(pool2, 12 * 3)\n    pool3 = AveragePooling2D(pool_size=(2, 2))(E3)\n\n    C = _morph_block(pool3, 12 * 4)\n\n    D3 = _decoder_block(C, E3, 12 * 3)\n    D2 = _decoder_block(D3, E2, 12 * 2)\n    D1 = _decoder_block(D2, E1, 12)\n\n    outputs = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(D1)\n    return Model(inputs, outputs)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T10:26:51.247497Z","iopub.execute_input":"2024-02-08T10:26:51.247889Z","iopub.status.idle":"2024-02-08T10:26:51.273459Z","shell.execute_reply.started":"2024-02-08T10:26:51.247857Z","shell.execute_reply":"2024-02-08T10:26:51.272442Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"dpm_unet_model=DPM_UNet((512, 512, 3))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T10:27:43.345084Z","iopub.execute_input":"2024-02-08T10:27:43.345475Z","iopub.status.idle":"2024-02-08T10:27:43.448017Z","shell.execute_reply.started":"2024-02-08T10:27:43.345444Z","shell.execute_reply":"2024-02-08T10:27:43.446827Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dpm_unet_model\u001b[38;5;241m=\u001b[39m\u001b[43mDPM_UNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[20], line 141\u001b[0m, in \u001b[0;36mDPM_UNet\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mDPM_UNet\u001b[39m(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m3\u001b[39m)):\n\u001b[1;32m    140\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[0;32m--> 141\u001b[0m     morph_ip \u001b[38;5;241m=\u001b[39m _morph_unit(\u001b[43mip\u001b[49m, \u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m    143\u001b[0m     E1 \u001b[38;5;241m=\u001b[39m _morph_block(morph_ip, \u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m    144\u001b[0m     pool1 \u001b[38;5;241m=\u001b[39m AveragePooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))(E1)\n","\u001b[0;31mNameError\u001b[0m: name 'ip' is not defined"],"ename":"NameError","evalue":"name 'ip' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"_uuid":"5e934a64-62a4-4a98-91b5-6d8843f171ce","_cell_guid":"a6fea83c-e7ff-4934-956f-6d79df324d35","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"02e4fc8f-7e34-4112-88b0-b7bf61d2f6eb","_cell_guid":"0c0ae15d-18b4-4888-bf46-4ea2aaa08e20","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UNET","metadata":{"_uuid":"40aa9c70-02d6-4a7b-b7cf-beae3a132744","_cell_guid":"4ec86afa-41fe-4e0b-ac8b-89cfa5b08877","trusted":true}},{"cell_type":"code","source":"IMG_WIDTH = 512\nIMG_HEIGHT = 512\nIMG_CHANNELS = 3\n\ninputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n\n# Encode module\nc1 = Conv2D(16, (3, 3), kernel_initializer='he_normal', padding='same') (inputs)\nc1 = Activation('relu')(c1)\nc1 = Conv2D(16, (3, 3), kernel_initializer='he_normal', padding='same') (c1)\nc1 = Activation('relu')(c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p1)\nc2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p2)\nc3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4)\nc5 = Dropout(0.4) (c5)\nc5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c5)\n\n# Decoder module\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c9)\noutputs = Conv2D(1, (1, 1)) (c9)\nout = Activation('sigmoid')(outputs)\n\nmodel = Model(inputs=[inputs], outputs=[out])","metadata":{"_uuid":"036e5ef6-ff5f-4af6-bcb9-903b687dae6a","_cell_guid":"913d8ffa-742c-4f05-a9bc-844b8ef9e70a","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T10:00:33.622117Z","iopub.execute_input":"2024-01-19T10:00:33.622870Z","iopub.status.idle":"2024-01-19T10:00:33.931962Z","shell.execute_reply.started":"2024-01-19T10:00:33.622832Z","shell.execute_reply":"2024-01-19T10:00:33.931088Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define loss function\nopt = Adam(learning_rate=0.00002)\nmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', iou_coef])\n\nprint(model.summary())","metadata":{"_uuid":"2704d919-1c5d-4271-b21b-8083f2e0662f","_cell_guid":"0dbdb3b2-a443-41d8-bc99-05e9d85afd39","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T10:01:27.082177Z","iopub.execute_input":"2024-01-19T10:01:27.082564Z","iopub.status.idle":"2024-01-19T10:01:27.174297Z","shell.execute_reply.started":"2024-01-19T10:01:27.082534Z","shell.execute_reply":"2024-01-19T10:01:27.173016Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import LearningRateScheduler\n# Learning Rate Scheduler\ndef Lr_scheduler(epoch, lr):\n    decay_rate = 0.1\n    decay_step = 30\n    if epoch % decay_step == 0 and epoch:\n        return lr * decay_rate\n    return lr","metadata":{"_uuid":"444a54a4-7b5b-4ebd-bf00-17877266ed6e","_cell_guid":"2f4f8a84-94db-4e1a-ab38-f0803f65f26d","collapsed":false,"execution":{"iopub.status.busy":"2024-01-18T11:53:21.140783Z","iopub.execute_input":"2024-01-18T11:53:21.141449Z","iopub.status.idle":"2024-01-18T11:53:21.146617Z","shell.execute_reply.started":"2024-01-18T11:53:21.141411Z","shell.execute_reply":"2024-01-18T11:53:21.145624Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_checkpoint = ModelCheckpoint('./building_unet.h5', monitor='val_loss', save_best_only=True)\n# callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=10, restore_best_weights=True)\n\n# #lr_scheduler = LearningRateScheduler(Lr_scheduler, verbose=1)\n# #history = seg_net_model.fit(x=x_train, y=y_train, validation_data=(x_val,y_val), epochs=1, verbose=1, callbacks=[model_checkpoint,callback], workers=8, use_multiprocessing=True )\n# history = model.fit(x=x_train, y=y_train, validation_data=(x_val,y_val), epochs=50, verbose=1, callbacks=[model_checkpoint,callback])#, workers=8, use_multiprocessing=True )","metadata":{"_uuid":"b5b0a029-de71-4827-beec-4ea3b1d581e3","_cell_guid":"aabec5eb-ccc5-4396-9c1f-0e9658902d44","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T10:01:33.163318Z","iopub.execute_input":"2024-01-19T10:01:33.163982Z","iopub.status.idle":"2024-01-19T10:01:33.169036Z","shell.execute_reply.started":"2024-01-19T10:01:33.163945Z","shell.execute_reply":"2024-01-19T10:01:33.167916Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = ModelCheckpoint('./building_unet1.h5', monitor='val_loss', save_best_only=True) \ncallback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=3, restore_best_weights=True)\nhistory = model.fit(train_dataset, validation_data=(x_val,y_val), epochs=50, verbose=1, callbacks=[model_checkpoint,callback])","metadata":{"_uuid":"0c84e4e7-c34a-4c32-bcf7-838b99d2ff99","_cell_guid":"481971bc-e8a9-435f-ad1d-1085cfd589e9","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T10:01:55.257765Z","iopub.execute_input":"2024-01-19T10:01:55.258558Z","iopub.status.idle":"2024-01-19T10:47:09.009312Z","shell.execute_reply.started":"2024-01-19T10:01:55.258524Z","shell.execute_reply":"2024-01-19T10:47:09.008415Z"},"scrolled":true,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(x_train)","metadata":{"_uuid":"3368696a-bec3-4f43-aa18-c1d8640f35cf","_cell_guid":"7cc18ef3-9519-4bf1-a9f0-823909217bd6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'] , label = 'train_acc')\nplt.plot(history.history['val_accuracy'] ,'--', label = 'val_acc')\nplt.legend()\nplt.xlabel(\"No. of epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training and Validation Accuracy\")\nplt.show()\n\nplt.plot(history.history['loss'] , label = 'train_loss')\nplt.plot(history.history['val_loss'] ,'--', label = 'val_loss')\nplt.legend()\nplt.xlabel(\"No. of epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss\")\nplt.show()","metadata":{"_uuid":"febfff14-cccf-4b96-bbc8-631e1bb1a42b","_cell_guid":"02ac8a02-330b-4e9d-b546-88d741a7f30b","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T10:47:09.011505Z","iopub.execute_input":"2024-01-19T10:47:09.012204Z","iopub.status.idle":"2024-01-19T10:47:09.477630Z","shell.execute_reply.started":"2024-01-19T10:47:09.012163Z","shell.execute_reply":"2024-01-19T10:47:09.476677Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_test)\ny_pred = y_pred>0.5\n#y_pred","metadata":{"_uuid":"28ca2d1d-6167-4979-948f-adba981ae186","_cell_guid":"1976451f-7d70-4fdf-bc3b-8b1527bd6bf4","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T10:47:09.478696Z","iopub.execute_input":"2024-01-19T10:47:09.478967Z","iopub.status.idle":"2024-01-19T10:47:11.323127Z","shell.execute_reply.started":"2024-01-19T10:47:09.478944Z","shell.execute_reply":"2024-01-19T10:47:11.322069Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure()\nfig.figsize=(50,50)\n\nax=fig.add_subplot(1,2,1)\nax.imshow(np.reshape(y_test[4],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Ground-truth\")\n\nax=fig.add_subplot(1,2,2)\nax.imshow(np.reshape(y_pred[4],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Predicted image\")","metadata":{"_uuid":"433ac9aa-9f64-436b-9636-2116aedc17be","_cell_guid":"c6a7b471-427f-49fc-a9fa-6e511cc53d35","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T10:47:11.325911Z","iopub.execute_input":"2024-01-19T10:47:11.326215Z","iopub.status.idle":"2024-01-19T10:47:11.652490Z","shell.execute_reply.started":"2024-01-19T10:47:11.326188Z","shell.execute_reply":"2024-01-19T10:47:11.651530Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nfig.figsize = (30,30)\n\nax = fig.add_subplot(1,2,1)\nax.imshow(np.reshape(y_test[2],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Ground-truth\")\n\nax = fig.add_subplot(1,2,2)\nax.imshow(np.reshape(y_pred[2],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Predicted image\")","metadata":{"_uuid":"6d49ce16-19eb-469f-81ac-4d0bcf99ece1","_cell_guid":"99fa0f0e-8786-4ae2-970f-88c24c0c9b04","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T10:47:11.653868Z","iopub.execute_input":"2024-01-19T10:47:11.654524Z","iopub.status.idle":"2024-01-19T10:47:11.891315Z","shell.execute_reply.started":"2024-01-19T10:47:11.654492Z","shell.execute_reply":"2024-01-19T10:47:11.890357Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_test=y_test.numpy()\n#y_pred=y_pred.numpy()\n\nmeaniou = MeanIoU(2, name=None, dtype=None)\nmeaniou.update_state(y_test, y_pred)\nclass_iou = meaniou.result().numpy()\nprint(\"Class-wise IoU =\", class_iou)\n\nprint(\"mean IoU = \",meaniou.result().numpy())\nmeaniou.reset_states()\n\n\n\n\nacc = Accuracy()\nacc.update_state(y_test, y_pred)\nprint(\"acc = \",acc.result().numpy())\nacc.reset_states()\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test.ravel(), y_pred.ravel())\nprint(cm)\n\nfrom sklearn.metrics import classification_report\ncr = classification_report(y_test.ravel(), y_pred.ravel())\nprint(cr)\n\nfrom sklearn.metrics import cohen_kappa_score\nk = cohen_kappa_score(y_test.ravel(), y_pred.ravel())\nprint(\"k = \",k)\n\ndef get_dice(y_true, y_pred):\n\n    intersection = np.sum(y_true * y_pred, axis=(0, 1, 2))\n    union = np.sum(y_true**2, axis=(0, 1, 2)) + np.sum(y_pred**2, axis=(0, 1, 2))\n    dc = 2 * intersection / union\n    return dc\n\ndice_coeff = get_dice(y_test, y_pred)\nprint(\"dc = \",np.mean(dice_coeff))","metadata":{"_uuid":"fae1dc8a-24ff-43f5-913e-dede690e1f3f","_cell_guid":"cf518d0b-0876-47d9-8c8c-3590e4a625d1","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T10:47:11.892557Z","iopub.execute_input":"2024-01-19T10:47:11.892852Z","iopub.status.idle":"2024-01-19T10:49:27.369091Z","shell.execute_reply.started":"2024-01-19T10:47:11.892825Z","shell.execute_reply":"2024-01-19T10:49:27.367878Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SegNet","metadata":{"_uuid":"c0190cbe-6ce7-4a63-9375-3716d8dfc902","_cell_guid":"6c90db00-71f0-4157-b318-cad3e3fd47c7","trusted":true}},{"cell_type":"code","source":"def segnet():\n    with tf.device('/GPU:0'):\n        # Encoding layer\n        img_input = Input(shape= (512, 512, 3))\n        x = Conv2D(32, (3, 3), padding='same', name='conv1',strides= (1,1))(img_input)\n        x = BatchNormalization(name='bn1')(x)\n        x = Activation('relu')(x)\n        x = Conv2D(32, (3, 3), padding='same', name='conv2')(x)\n        x = BatchNormalization(name='bn2')(x)\n        x = Activation('relu')(x)\n        x = MaxPooling2D()(x)\n    \n        x = Conv2D(64, (3, 3), padding='same', name='conv3')(x)\n        x = BatchNormalization(name='bn3')(x)\n        x = Activation('relu')(x)\n        x = Conv2D(64, (3, 3), padding='same', name='conv4')(x)\n        x = BatchNormalization(name='bn4')(x)\n        x = Activation('relu')(x)\n        x = MaxPooling2D()(x)\n\n        x = Conv2D(128, (3, 3), padding='same', name='conv5')(x)\n        x = BatchNormalization(name='bn5')(x)\n        x = Activation('relu')(x)\n        x = Conv2D(128, (3, 3), padding='same', name='conv6')(x)\n        x = BatchNormalization(name='bn6')(x)\n        x = Activation('relu')(x)\n        x = Conv2D(128, (3, 3), padding='same', name='conv7')(x)\n        x = BatchNormalization(name='bn7')(x)\n        x = Activation('relu')(x)\n        x = MaxPooling2D()(x)\n\n        x = Conv2D(256, (3, 3), padding='same', name='conv8')(x)\n        x = BatchNormalization(name='bn8')(x)\n        x = Activation('relu')(x)\n        x = Conv2D(256, (3, 3), padding='same', name='conv9')(x)\n        x = BatchNormalization(name='bn9')(x)\n        x = Activation('relu')(x)\n        x = Conv2D(256, (3, 3), padding='same', name='conv10')(x)\n        x = BatchNormalization(name='bn10')(x)\n        x = Activation('relu')(x)\n        x = MaxPooling2D()(x)\n    \n        x = Conv2D(256, (3, 3), padding='same', name='conv11')(x)\n        x = BatchNormalization(name='bn11')(x)\n        x = Activation('relu')(x)\n        x = Conv2D(256, (3, 3), padding='same', name='conv12')(x)\n        x = BatchNormalization(name='bn12')(x)\n        x = Activation('relu')(x)\n        x = Conv2D(256, (3, 3), padding='same', name='conv13')(x)\n        x = BatchNormalization(name='bn13')(x)\n        x = Activation('relu')(x)\n        x = MaxPooling2D()(x)\n\n        x = Dense(512, activation = 'relu', name='fc1')(x)\n        x = Dense(512, activation = 'relu', name='fc2')(x)\n    # Decoding Layer \n        x = UpSampling2D()(x)\n        x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv1')(x)\n        x = BatchNormalization(name='bn14')(x)\n        x = Activation('relu')(x)\n        x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv2')(x)\n        x = BatchNormalization(name='bn15')(x)\n        x = Activation('relu')(x)\n        x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv3')(x)\n        x = BatchNormalization(name='bn16')(x)\n        x = Activation('relu')(x)\n    \n        x = UpSampling2D()(x)\n        x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv4')(x)\n        x = BatchNormalization(name='bn17')(x)\n        x = Activation('relu')(x)\n        x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv5')(x)\n        x = BatchNormalization(name='bn18')(x)\n        x = Activation('relu')(x)\n        x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv6')(x)\n        x = BatchNormalization(name='bn19')(x)\n        x = Activation('relu')(x)\n\n        x = UpSampling2D()(x)\n        x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv7')(x)\n        x = BatchNormalization(name='bn20')(x)\n        x = Activation('relu')(x)\n        x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv8')(x)\n        x = BatchNormalization(name='bn21')(x)\n        x = Activation('relu')(x)\n        x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv9')(x)\n        x = BatchNormalization(name='bn22')(x)\n        x = Activation('relu')(x)\n\n        x = UpSampling2D()(x)\n        x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv10')(x)\n        x = BatchNormalization(name='bn23')(x)\n        x = Activation('relu')(x)\n        x = Conv2DTranspose(32, (3, 3), padding='same', name='deconv11')(x)\n        x = BatchNormalization(name='bn24')(x)\n        x = Activation('relu')(x)\n    \n        x = UpSampling2D()(x)\n        x = Conv2DTranspose(32, (3, 3), padding='same', name='deconv12')(x)\n        x = BatchNormalization(name='bn25')(x)\n        x = Activation('relu')(x)\n        x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv13')(x)\n        x = BatchNormalization(name='bn26')(x)\n        pred = Activation('sigmoid')(x)\n        #pred = Reshape((512,512))(x)\n    \n    \n        model = Model(inputs=img_input, outputs=pred)\n    \n#     model.compile(optimizer= SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False), loss= [\"binary_crossentropy\"]\n#                   , metrics=[iou, dice_coef, precision, recall, accuracy])\n#     model.summary()\n#     hist = model.fit(x_train, y_train, epochs= epochs_num, batch_size= 18, validation_data= (x_val, y_val), verbose=1)\n    \n#     model.save(savename)\n    return model","metadata":{"_uuid":"7b3813bd-4ca1-4da0-9331-69cc00120edc","_cell_guid":"084a4370-60cf-4d82-ae19-05b9f6e4f231","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T10:49:27.370906Z","iopub.execute_input":"2024-01-19T10:49:27.371208Z","iopub.status.idle":"2024-01-19T10:49:27.401763Z","shell.execute_reply.started":"2024-01-19T10:49:27.371181Z","shell.execute_reply":"2024-01-19T10:49:27.400754Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, UpSampling2D, Conv2DTranspose, Dense\n\ndef lightweight_segnet():\n    # Encoding layer\n    img_input = Input(shape=(512, 512, 3))\n    x = Conv2D(32, (3, 3), padding='same', name='conv1', strides=(1, 1))(img_input)\n    x = BatchNormalization(name='bn1')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(32, (3, 3), padding='same', name='conv2')(x)\n    x = BatchNormalization(name='bn2')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n\n    x = Conv2D(64, (3, 3), padding='same', name='conv3')(x)\n    x = BatchNormalization(name='bn3')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(64, (3, 3), padding='same', name='conv4')(x)\n    x = BatchNormalization(name='bn4')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n\n    x = Conv2D(128, (3, 3), padding='same', name='conv5')(x)\n    x = BatchNormalization(name='bn5')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(128, (3, 3), padding='same', name='conv6')(x)\n    x = BatchNormalization(name='bn6')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n\n    # Decoding Layer\n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv1')(x)\n    x = BatchNormalization(name='bn7')(x)\n    x = Activation('relu')(x)\n\n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(32, (3, 3), padding='same', name='deconv2')(x)\n    x = BatchNormalization(name='bn8')(x)\n    x = Activation('relu')(x)\n\n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv3')(x)\n    x = BatchNormalization(name='bn9')(x)\n    #x = Activation('relu')(x)\n    \n#     x = UpSampling2D()(x)\n#     x = Conv2DTranspose(16, (3, 3), padding='same', name='deconv4')(x)\n#     x = BatchNormalization(name='bn94')(x)\n#     x = Activation('relu')(x)\n\n#     x = UpSampling2D()(x)\n#     x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv5')(x)\n#     x = BatchNormalization(name='bn10')(x)\n    pred = Activation('sigmoid')(x)\n    \n    with tf.device('/GPU:0'):\n        model = Model(inputs=img_input, outputs=pred)\n    \n    #model = Model(inputs=img_input, outputs=pred)\n    return model","metadata":{"_uuid":"0f60462e-4782-40e6-ba79-8dba45b98cac","_cell_guid":"02f99662-8e5f-4e5c-b688-c04796846bb2","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T11:29:09.297368Z","iopub.execute_input":"2024-01-19T11:29:09.298129Z","iopub.status.idle":"2024-01-19T11:29:09.313540Z","shell.execute_reply.started":"2024-01-19T11:29:09.298086Z","shell.execute_reply":"2024-01-19T11:29:09.312537Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seg_net_model=lightweight_segnet()\nseg_net_model.summary()","metadata":{"_uuid":"f78215ec-c7fc-4970-9944-07779554c563","_cell_guid":"d6884e7b-98fa-4c93-9252-43c5353545ed","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T11:29:10.471681Z","iopub.execute_input":"2024-01-19T11:29:10.472412Z","iopub.status.idle":"2024-01-19T11:29:10.798333Z","shell.execute_reply.started":"2024-01-19T11:29:10.472377Z","shell.execute_reply":"2024-01-19T11:29:10.797392Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define loss function\nopt = Adam(learning_rate=0.0002)\nseg_net_model.compile(optimizer=opt, loss='binary_crossentropy',metrics=[dice_coef,iou_coef, 'accuracy'])\n\n#print(model.summary())","metadata":{"_uuid":"33d5f576-4c64-43c4-87c5-e51d18fbc00f","_cell_guid":"b3a3f663-a59b-48ac-a463-42c66cd179cc","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T11:29:16.090002Z","iopub.execute_input":"2024-01-19T11:29:16.090915Z","iopub.status.idle":"2024-01-19T11:29:16.104511Z","shell.execute_reply.started":"2024-01-19T11:29:16.090881Z","shell.execute_reply":"2024-01-19T11:29:16.103528Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = ModelCheckpoint('./building_unet.h5', monitor='val_loss', save_best_only=True) \ncallback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=10, restore_best_weights=True)\n#lr_scheduler = LearningRateScheduler(Lr_scheduler, verbose=1)\n\n#history = seg_net_model.fit(x=x_train, y=y_train, validation_data=(x_val,y_val), epochs=1, verbose=1, callbacks=[model_checkpoint,callback], workers=8, use_multiprocessing=True )\nhistory = seg_net_model.fit(train_dataset, validation_data=(x_val,y_val), epochs=100, verbose=1, callbacks=[model_checkpoint,callback], workers=12, use_multiprocessing=True )","metadata":{"_uuid":"7d807450-043b-475b-998a-a4a949a1c563","_cell_guid":"6b69c067-fb56-4dcc-a076-51c2732a842d","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T11:29:16.722868Z","iopub.execute_input":"2024-01-19T11:29:16.723271Z","iopub.status.idle":"2024-01-19T11:59:54.104473Z","shell.execute_reply.started":"2024-01-19T11:29:16.723240Z","shell.execute_reply":"2024-01-19T11:59:54.103517Z"},"scrolled":true,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = model.fit(train_generator,\n#                     validation_data=validation_generator,\n#                     use_multiprocessing=True,\n#                     workers=6,\n#                     epochs=10, batch_size=8,\n#                     verbose=1,\n#                     callbacks=[model_checkpoint, callback])","metadata":{"_uuid":"9409b1b4-d563-409e-b1db-35ca8d8fc8de","_cell_guid":"6df7b76e-f693-4565-bfc5-23fbec0079eb","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T11:59:54.106375Z","iopub.execute_input":"2024-01-19T11:59:54.106700Z","iopub.status.idle":"2024-01-19T11:59:54.111317Z","shell.execute_reply.started":"2024-01-19T11:59:54.106671Z","shell.execute_reply":"2024-01-19T11:59:54.110361Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'] , label = 'train_acc')\nplt.plot(history.history['val_accuracy'] ,'--', label = 'val_acc')\nplt.legend()\nplt.xlabel(\"No. of epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training and Validation Accuracy\")\nplt.show()\n\nplt.plot(history.history['loss'] , label = 'train_loss')\nplt.plot(history.history['val_loss'] ,'--', label = 'val_loss')\nplt.legend()\nplt.xlabel(\"No. of epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss\")\nplt.show()","metadata":{"_uuid":"a39cd96a-505b-426f-93ba-8455faf1a784","_cell_guid":"c9b007b7-0799-4f40-9191-70e59fbbe25f","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T11:59:54.112397Z","iopub.execute_input":"2024-01-19T11:59:54.112708Z","iopub.status.idle":"2024-01-19T11:59:54.696230Z","shell.execute_reply.started":"2024-01-19T11:59:54.112680Z","shell.execute_reply":"2024-01-19T11:59:54.695281Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = seg_net_model.predict(x_test)\ny_pred = y_pred>0.5\n#y_pred","metadata":{"_uuid":"8750f8e3-afe4-4d40-9c65-d0e485bb27fa","_cell_guid":"bdef02fe-40c6-4361-8396-21ea9f857bf6","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T11:59:54.698995Z","iopub.execute_input":"2024-01-19T11:59:54.699383Z","iopub.status.idle":"2024-01-19T12:00:03.004658Z","shell.execute_reply.started":"2024-01-19T11:59:54.699348Z","shell.execute_reply":"2024-01-19T12:00:03.003738Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure()\nfig.figsize=(50,50)\n\nax=fig.add_subplot(1,2,1)\nax.imshow(np.reshape(y_test[4],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Ground-truth\")\n\nax=fig.add_subplot(1,2,2)\nax.imshow(np.reshape(y_pred[4],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Predicted image\")","metadata":{"_uuid":"9d56ab6a-0f2f-4a6d-802c-c1c860f93055","_cell_guid":"0630c746-88f6-44c0-b757-d12971a0ee98","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T12:00:03.005870Z","iopub.execute_input":"2024-01-19T12:00:03.006202Z","iopub.status.idle":"2024-01-19T12:00:03.330746Z","shell.execute_reply.started":"2024-01-19T12:00:03.006173Z","shell.execute_reply":"2024-01-19T12:00:03.329882Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nfig.figsize = (30,30)\n\nax = fig.add_subplot(1,2,1)\nax.imshow(np.reshape(y_test[2],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Ground-truth\")\n\nax = fig.add_subplot(1,2,2)\nax.imshow(np.reshape(y_pred[2],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Predicted image\")","metadata":{"_uuid":"6fc7753a-39fd-4cdf-a408-28d0fe1eefbe","_cell_guid":"28560e16-837d-4294-8e27-93f367fea7f0","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T12:00:03.331996Z","iopub.execute_input":"2024-01-19T12:00:03.332287Z","iopub.status.idle":"2024-01-19T12:00:03.576388Z","shell.execute_reply.started":"2024-01-19T12:00:03.332261Z","shell.execute_reply":"2024-01-19T12:00:03.575521Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(y_test)","metadata":{"_uuid":"3b909ad7-071b-4b6c-95dd-964c3a78960d","_cell_guid":"44819d6a-594a-47c9-88e2-4c1058367e3c","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T12:00:03.577715Z","iopub.execute_input":"2024-01-19T12:00:03.578091Z","iopub.status.idle":"2024-01-19T12:00:03.584591Z","shell.execute_reply.started":"2024-01-19T12:00:03.578056Z","shell.execute_reply":"2024-01-19T12:00:03.583603Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_test=y_test.numpy()\n#y_pred=y_pred.numpy()\n\nmeaniou = MeanIoU(2, name=None, dtype=None)\nmeaniou.update_state(y_test, y_pred)\nclass_iou = meaniou.result().numpy()\nprint(\"Class-wise IoU =\", class_iou)\n\nprint(\"mean IoU = \",meaniou.result().numpy())\nmeaniou.reset_states()\n\n\n\n\nacc = Accuracy()\nacc.update_state(y_test, y_pred)\nprint(\"acc = \",acc.result().numpy())\nacc.reset_states()\n \nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test.ravel(), y_pred.ravel())\nprint(cm)\n \nfrom sklearn.metrics import classification_report\ncr = classification_report(y_test.ravel(), y_pred.ravel())\nprint(cr)\n \nfrom sklearn.metrics import cohen_kappa_score\nk = cohen_kappa_score(y_test.ravel(), y_pred.ravel())\nprint(\"k = \",k)\n \ndef get_dice(y_true, y_pred):\n \n    intersection = np.sum(y_true * y_pred, axis=(0, 1, 2))\n    union = np.sum(y_true**2, axis=(0, 1, 2)) + np.sum(y_pred**2, axis=(0, 1, 2))\n    dc = 2 * intersection / union\n    return dc\n \ndice_coeff = get_dice(y_test, y_pred)\nprint(\"dc = \",np.mean(dice_coeff))","metadata":{"_uuid":"247fdb36-58c5-4163-bdc8-046cf23ac8a4","_cell_guid":"c300df8f-4f4f-4c84-bd33-936f4a5e14c5","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T12:00:03.585888Z","iopub.execute_input":"2024-01-19T12:00:03.586215Z","iopub.status.idle":"2024-01-19T12:02:16.895348Z","shell.execute_reply.started":"2024-01-19T12:00:03.586182Z","shell.execute_reply":"2024-01-19T12:02:16.894193Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UNET+Attention","metadata":{"_uuid":"c1f306ce-e6f2-4f9f-94dc-9dc61ea74489","_cell_guid":"9f750957-0d75-4d68-b9ad-e2c78893fbbb","trusted":true}},{"cell_type":"code","source":"def attention_gate(inp_1, inp_2, n_intermediate_channels):\n    inp_1_conv = Conv2D(n_intermediate_channels, (1, 1), padding='same')(inp_1)\n    inp_2_conv = Conv2D(n_intermediate_channels, (1, 1), padding='same')(inp_2)\n    f = add([inp_1_conv, inp_2_conv])\n    f = Activation('relu')(f)\n    g = Conv2D(1, (1, 1), padding='same')(f)\n    gate = Activation('sigmoid')(g)\n\n    return multiply([inp_2, gate])\n\ndef conv_block(input_tensor, num_filters):\n    encoder = Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n    encoder = Activation('relu')(encoder)\n    encoder = BatchNormalization()(encoder)\n    encoder = Conv2D(num_filters, (3, 3), padding='same')(encoder)\n    encoder = Activation('relu')(encoder)\n    encoder = BatchNormalization()(encoder)\n    return encoder\n\ndef encoder_block(input_tensor, num_filters):\n    encoder = conv_block(input_tensor, num_filters)\n    encoder_pool = MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n    return encoder_pool, encoder\n\ndef decoder_block(input_tensor, concat_tensor, num_filters):\n    decoder = Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n    decoder = concatenate([decoder, concat_tensor], axis=-1)\n    decoder = conv_block(decoder, num_filters)\n    return decoder\n\ndef get_attention_unet(input_shape, num_filters_start=16, num_classes=1):\n    inputs = Input(input_shape)\n\n    # Downsampling through the model\n    encoder_pool0, encoder0 = encoder_block(inputs, num_filters_start)\n    encoder_pool1, encoder1 = encoder_block(encoder_pool0, num_filters_start*2)\n    encoder_pool2, encoder2 = encoder_block(encoder_pool1, num_filters_start*4)\n    encoder_pool3, encoder3 = encoder_block(encoder_pool2, num_filters_start*8)\n\n    center = conv_block(encoder_pool3, num_filters_start*16)\n\n    # Upsampling and establishing the skip connections\n    decoder3 = decoder_block(center, encoder3, num_filters_start*8)\n    attn3 = attention_gate(encoder3, decoder3, num_filters_start*8)\n    decoder2 = decoder_block(attn3, encoder2, num_filters_start*4)\n    attn2 = attention_gate(encoder2, decoder2, num_filters_start*4)\n    decoder1 = decoder_block(attn2, encoder1, num_filters_start*2)\n    attn1 = attention_gate(encoder1, decoder1, num_filters_start*2)\n    decoder0 = decoder_block(attn1, encoder0, num_filters_start)\n\n    # Output\n    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(decoder0)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n\n    return model","metadata":{"_uuid":"45f6bddc-8781-4ca0-bd15-0ca7b44c2796","_cell_guid":"60aa2f62-d375-415d-94d9-1ae7c2d6f943","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T12:02:16.896593Z","iopub.execute_input":"2024-01-19T12:02:16.896890Z","iopub.status.idle":"2024-01-19T12:02:17.325515Z","shell.execute_reply.started":"2024-01-19T12:02:16.896863Z","shell.execute_reply":"2024-01-19T12:02:17.324542Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define model parameters\ninput_shape = (512, 512, 3)  # or your preferred dimensions\nnum_filters_start = 16  # number of filters in the first layer of U-Net\nnum_classes = 1  # binary segmentation\n\n# Create a new model instance\nattention_unet_model = get_attention_unet(input_shape, num_filters_start, num_classes)","metadata":{"_uuid":"7c6fbf85-133a-4bf2-a9bd-20a9eec27b67","_cell_guid":"8da630ae-736a-4ec6-bdc0-7efd5b8273e3","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T12:02:17.328716Z","iopub.execute_input":"2024-01-19T12:02:17.329023Z","iopub.status.idle":"2024-01-19T12:02:17.973965Z","shell.execute_reply.started":"2024-01-19T12:02:17.328997Z","shell.execute_reply":"2024-01-19T12:02:17.973146Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(attention_unet_model.summary())","metadata":{"_uuid":"8283a139-7d59-4268-bdce-c7ea12904c87","_cell_guid":"5b7e7235-8f3e-46ad-b506-5adacf1c5641","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T12:02:17.975036Z","iopub.execute_input":"2024-01-19T12:02:17.975331Z","iopub.status.idle":"2024-01-19T12:02:18.203189Z","shell.execute_reply.started":"2024-01-19T12:02:17.975304Z","shell.execute_reply":"2024-01-19T12:02:18.202188Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = Adam(learning_rate=0.0002)\n\nattention_unet_model.compile(optimizer=opt, loss='binary_crossentropy',metrics=[dice_coef,iou_coef, 'accuracy'])","metadata":{"_uuid":"ad159259-c68d-4569-9e0b-fee3ec484175","_cell_guid":"e0487e82-0206-422b-9ef9-d9020edf885a","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T12:02:18.204854Z","iopub.execute_input":"2024-01-19T12:02:18.205221Z","iopub.status.idle":"2024-01-19T12:02:18.221935Z","shell.execute_reply.started":"2024-01-19T12:02:18.205185Z","shell.execute_reply":"2024-01-19T12:02:18.220967Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = ModelCheckpoint('./building_unet.h5', monitor='val_loss', save_best_only=True) \ncallback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=10, restore_best_weights=True)\n#lr_scheduler = LearningRateScheduler(Lr_scheduler, verbose=1)","metadata":{"_uuid":"31e7b504-b34e-4026-aaaa-2d4261efdad0","_cell_guid":"e5fea18b-a821-4743-beba-02bae6406d41","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T12:02:18.223171Z","iopub.execute_input":"2024-01-19T12:02:18.223538Z","iopub.status.idle":"2024-01-19T12:02:18.230054Z","shell.execute_reply.started":"2024-01-19T12:02:18.223502Z","shell.execute_reply":"2024-01-19T12:02:18.229144Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = attention_unet_model.fit(train_dataset, validation_data=(x_val,y_val), epochs=100, verbose=1, callbacks=[model_checkpoint,callback], workers=8, use_multiprocessing=True)","metadata":{"_uuid":"77449b96-3cba-47a4-af40-089b6599fb1e","_cell_guid":"d6fa92df-ff01-447c-92d4-d4c8212baebd","collapsed":false,"execution":{"iopub.status.busy":"2024-01-19T12:02:18.231172Z","iopub.execute_input":"2024-01-19T12:02:18.231435Z"},"scrolled":true,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'] , label = 'train_acc')\nplt.plot(history.history['val_accuracy'] ,'--', label = 'val_acc')\nplt.legend()\nplt.xlabel(\"No. of epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training and Validation Accuracy\")\nplt.show()\n\nplt.plot(history.history['loss'] , label = 'train_loss')\nplt.plot(history.history['val_loss'] ,'--', label = 'val_loss')\nplt.legend()\nplt.xlabel(\"No. of epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss\")\nplt.show()","metadata":{"_uuid":"56310d1f-fa60-41bc-a215-70a8a1b9a324","_cell_guid":"bef8fb92-fb1d-4fb6-88e6-6a29f8e5a7c6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = attention_unet_model.predict(x_test)\ny_pred = y_pred>0.5","metadata":{"_uuid":"17ee2ed4-40fa-4f23-9ab1-a1af9710b7cf","_cell_guid":"11eacdcc-c246-4ae4-a4a5-8d747d9d7ffc","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred<0.5","metadata":{"_uuid":"500bba91-6a86-45c8-9abf-846f54d0d976","_cell_guid":"ced36051-e786-46e1-8d54-86c9951f0b21","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure()\nfig.figsize=(50,50)\n\nax=fig.add_subplot(1,2,1)\nax.imshow(np.reshape(y_test[4],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Ground-truth\")\n\nax=fig.add_subplot(1,2,2)\nax.imshow(np.reshape(y_pred[4],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Predicted image\")","metadata":{"_uuid":"2d998aa2-47f9-4aa6-9c4e-b1555a99e018","_cell_guid":"a9dc791e-0fc4-49e1-ab9e-1541078646ae","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nfig.figsize = (30,30)\n\nax = fig.add_subplot(1,2,1)\nax.imshow(np.reshape(y_test[2],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Ground-truth\")\n\nax = fig.add_subplot(1,2,2)\nax.imshow(np.reshape(y_pred[2],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Predicted image\")","metadata":{"_uuid":"b13e6272-8b21-4f43-b43c-96ae2a2757de","_cell_guid":"bfdc3e6e-2b7f-40b1-9834-b9421db9142a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meaniou = MeanIoU(2, name=None, dtype=None)\nmeaniou.update_state(y_test, y_pred)\nprint(\"mean IoU = \",meaniou.result().numpy())\nmeaniou.reset_states()\n \nacc = Accuracy()\nacc.update_state(y_test, y_pred)\nprint(\"acc = \",acc.result().numpy())\nacc.reset_states()\n \nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test.ravel(), y_pred.ravel())\nprint(cm)\n \nfrom sklearn.metrics import classification_report\ncr = classification_report(y_test.ravel(), y_pred.ravel())\nprint(cr)\n \nfrom sklearn.metrics import cohen_kappa_score\nk = cohen_kappa_score(y_test.ravel(), y_pred.ravel())\nprint(\"k = \",k)\n \ndef get_dice(y_true, y_pred):\n \n    intersection = np.sum(y_true * y_pred, axis=(0, 1, 2))\n    union = np.sum(y_true**2, axis=(0, 1, 2)) + np.sum(y_pred**2, axis=(0, 1, 2))\n    dc = 2 * intersection / union\n    return dc\n \ndice_coeff = get_dice(y_test, y_pred)\nprint(\"dc = \",np.mean(dice_coeff))","metadata":{"_uuid":"f6f63727-bef2-4e40-b86b-41eb7b4a676f","_cell_guid":"cdcfc63e-3a51-40c0-89cb-f57b3312e673","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"a82f6dc3-c0d3-441b-9fc0-914e3b6b3850","_cell_guid":"b386a175-f4b4-43cf-98d8-e6578837c5ee","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UNET++","metadata":{"_uuid":"08265624-b0d9-46fa-bfaf-606661035527","_cell_guid":"876bc6dc-77e8-41fa-8c18-e1722408e70e","trusted":true}},{"cell_type":"code","source":"# Defining the Convolutional Block\ndef conv_block(inputs, num_filters):\n    # Applying the sequence of Convolutional, Batch Normalization\n    # and Activation Layers to the input tensor\n    x = tf.keras.Sequential([\n        # Convolutional Layer\n        tf.keras.layers.Conv2D(num_filters, 3, padding='same'),\n        # Batch Normalization Layer\n        tf.keras.layers.BatchNormalization(),\n        # Activation Layer\n        tf.keras.layers.Activation('relu'),\n        # Convolutional Layer\n        tf.keras.layers.Conv2D(num_filters, 3, padding='same'),\n        # Batch Normalization Layer\n        tf.keras.layers.BatchNormalization(),\n        # Activation Layer\n        tf.keras.layers.Activation('relu')\n    ])(inputs)\n \n    # Returning the output of the Convolutional Block\n    return x","metadata":{"_uuid":"6e10ed02-a966-40f9-8d78-9e6bdccc8f88","_cell_guid":"7ecacd41-a309-4c9a-a934-d767d77da400","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the Unet++ Model\ndef unet_plus_plus_model(input_shape=(256, 256, 3), num_classes=1, deep_supervision=True):\n\tinputs = tf.keras.layers.Input(shape=input_shape)\n\n\t# Encoding Path\n\tx_00 = conv_block(inputs, 64)\n\tx_10 = conv_block(tf.keras.layers.MaxPooling2D()(x_00), 128)\n\tx_20 = conv_block(tf.keras.layers.MaxPooling2D()(x_10), 256)\n\tx_30 = conv_block(tf.keras.layers.MaxPooling2D()(x_20), 512)\n\tx_40 = conv_block(tf.keras.layers.MaxPooling2D()(x_30), 1024)\n\n\t# Nested Decoding Path\n\tx_01 = conv_block(tf.keras.layers.concatenate(\n\t\t[x_00, tf.keras.layers.UpSampling2D()(x_10)]), 64)\n\tx_11 = conv_block(tf.keras.layers.concatenate(\n\t\t[x_10, tf.keras.layers.UpSampling2D()(x_20)]), 128)\n\tx_21 = conv_block(tf.keras.layers.concatenate(\n\t\t[x_20, tf.keras.layers.UpSampling2D()(x_30)]), 256)\n\tx_31 = conv_block(tf.keras.layers.concatenate(\n\t\t[x_30, tf.keras.layers.UpSampling2D()(x_40)]), 512)\n\n\tx_02 = conv_block(tf.keras.layers.concatenate(\n\t\t[x_00, x_01, tf.keras.layers.UpSampling2D()(x_11)]), 64)\n\tx_12 = conv_block(tf.keras.layers.concatenate(\n\t\t[x_10, x_11, tf.keras.layers.UpSampling2D()(x_21)]), 128)\n\tx_22 = conv_block(tf.keras.layers.concatenate(\n\t\t[x_20, x_21, tf.keras.layers.UpSampling2D()(x_31)]), 256)\n\n\tx_03 = conv_block(tf.keras.layers.concatenate(\n\t\t[x_00, x_01, x_02, tf.keras.layers.UpSampling2D()(x_12)]), 64)\n\tx_13 = conv_block(tf.keras.layers.concatenate(\n\t\t[x_10, x_11, x_12, tf.keras.layers.UpSampling2D()(x_22)]), 128)\n\n\tx_04 = conv_block(tf.keras.layers.concatenate(\n\t\t[x_00, x_01, x_02, x_03, tf.keras.layers.UpSampling2D()(x_13)]), 64)\n\n\t# Deep Supervision Path\n\t# If deep supervision is enabled, then the model will output the segmentation maps\n\t# at each stage of the decoding path\n\tif deep_supervision:\n\t\toutputs = [\n\t\t\ttf.keras.layers.Conv2D(num_classes, 1)(x_01),\n\t\t\ttf.keras.layers.Conv2D(num_classes, 1)(x_02),\n\t\t\ttf.keras.layers.Conv2D(num_classes, 1)(x_03),\n\t\t\ttf.keras.layers.Conv2D(num_classes, 1)(x_04)\n\t\t]\n\t\t# Concatenating the segmentation maps\n\t\toutputs = tf.keras.layers.concatenate(outputs, axis=0)\n\n\t# If deep supervision is disabled, then the model will output the final segmentation map\n\t# which is the segmentation map at the end of the decoding path\n\telse:\n\t\toutputs = tf.keras.layers.Conv2D(num_classes, 1)(x_04)\n\n\t# Creating the model\n\tmodel = tf.keras.Model(\n\t\tinputs=inputs, outputs=outputs, name='Unet_plus_plus')\n\n\t# Returning the model\n\treturn model","metadata":{"_uuid":"43f8b391-d0a5-4b55-939d-e48095e9104d","_cell_guid":"c89d93fa-947f-43ab-bf80-1561e9e9d1df","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv_block(x, filters, kernel_size=(3, 3), padding='same', activation='relu'):\n    x = Conv2D(filters, kernel_size, padding=padding)(x)\n    x = BatchNormalization()(x)\n    x = Activation(activation)(x)\n    x = Conv2D(filters, kernel_size, padding=padding)(x)\n    x = BatchNormalization()(x)\n    x = Activation(activation)(x)\n    return x\n\ndef unet_plusplus_low_complexity(input_shape):\n    inputs = Input(input_shape)\n\n    # Encoder\n    conv1 = conv_block(inputs, 32)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = conv_block(pool1, 64)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = conv_block(pool2, 128)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = conv_block(pool3, 256)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    # Middle Block\n    conv5 = conv_block(pool4, 512)\n\n    # Decoder\n    up4 = UpSampling2D(size=(2, 2))(conv5)\n    concat4 = Concatenate()([up4, conv4])\n    conv6 = conv_block(concat4, 256)\n\n    up3 = UpSampling2D(size=(2, 2))(conv6)\n    concat3 = Concatenate()([up3, conv3])\n    conv7 = conv_block(concat3, 128)\n\n    up2 = UpSampling2D(size=(2, 2))(conv7)\n    concat2 = Concatenate()([up2, conv2])\n    conv8 = conv_block(concat2, 64)\n\n    up1 = UpSampling2D(size=(2, 2))(conv8)\n    concat1 = Concatenate()([up1, conv1])\n    conv9 = conv_block(concat1, 32)\n\n    # Output layer\n    output = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n    \n    with tf.device('/GPU:0'):\n        model = tf.keras.models.Model(inputs=inputs, outputs=output)\n    return model","metadata":{"_uuid":"986c7ac0-60fe-4f52-aa46-db74e497955a","_cell_guid":"202d043c-84ad-4e47-abfa-91d5928f6a67","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet_plus_plusmodel = unet_plusplus_low_complexity(input_shape=(\n\t\t512, 512, 3))\n\n\t# Printing the model summary\nunet_plus_plusmodel.summary()","metadata":{"_uuid":"3fb8c309-1b53-4741-a852-29fceabf1d8a","_cell_guid":"879fb2f8-05b4-47db-8bbe-9b0a0619f51a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = Adam(learning_rate=0.0002)\n\nunet_plus_plusmodel.compile(optimizer=opt, loss=bce_dice_loss,metrics=[dice_coef,iou_coef, 'accuracy'])","metadata":{"_uuid":"c311c06d-b782-428e-95f5-54ca5eac3143","_cell_guid":"2688b014-9d1e-4068-9467-8d893c2e8af1","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = ModelCheckpoint('./building_unet.h5', monitor='val_loss', save_best_only=True) \ncallback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=10, restore_best_weights=True)\nlr_scheduler = LearningRateScheduler(Lr_scheduler, verbose=1)","metadata":{"_uuid":"be881c85-e465-4015-b14e-a9369643e7c8","_cell_guid":"0a9d67e8-4198-47db-98dd-b35fd7ee24cb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = unet_plus_plusmodel.fit(train_dataset, validation_data=(x_val,y_val), epochs=50, verbose=1, callbacks=[model_checkpoint,callback])","metadata":{"_uuid":"ab1222c1-dbdb-4c63-bf7f-54c70e5e993e","_cell_guid":"da70a7b2-a2bb-4a21-85d3-c376f63d00fe","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'] , label = 'train_acc')\nplt.plot(history.history['val_accuracy'] ,'--', label = 'val_acc')\nplt.legend()\nplt.xlabel(\"No. of epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training and Validation Accuracy\")\nplt.show()\n\nplt.plot(history.history['loss'] , label = 'train_loss')\nplt.plot(history.history['val_loss'] ,'--', label = 'val_loss')\nplt.legend()\nplt.xlabel(\"No. of epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss\")\nplt.show()","metadata":{"_uuid":"ee78c2f5-cae9-429e-9a69-8d90269fa665","_cell_guid":"01245b7a-938e-49a0-8169-d218cabb351b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = unet_plus_plusmodel.predict(x_test)\ny_pred = y_pred>0.5","metadata":{"_uuid":"ddb3e40a-8e0f-4b49-80ef-dc656e010c9c","_cell_guid":"f434236f-e1b0-4423-a3d8-d46dd0321c9d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_test=y_test.numpy()\nmeaniou = MeanIoU(2, name=None, dtype=None)\nmeaniou.update_state(y_test, y_pred)\nprint(\"mean IoU = \",meaniou.result().numpy())\nmeaniou.reset_states()\n \nacc = Accuracy()\nacc.update_state(y_test, y_pred)\nprint(\"acc = \",acc.result().numpy())\nacc.reset_states()\n \nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test.ravel(), y_pred.ravel())\nprint(cm)\n \nfrom sklearn.metrics import classification_report\ncr = classification_report(y_test.ravel(), y_pred.ravel())\nprint(cr)\n \nfrom sklearn.metrics import cohen_kappa_score\nk = cohen_kappa_score(y_test.ravel(), y_pred.ravel())\nprint(\"k = \",k)\n \ndef get_dice(y_true, y_pred):\n \n    intersection = np.sum(y_true * y_pred, axis=(0, 1, 2))\n    union = np.sum(y_true**2, axis=(0, 1, 2)) + np.sum(y_pred**2, axis=(0, 1, 2))\n    dc = 2 * intersection / union\n    return dc\n \ndice_coeff = get_dice(y_test, y_pred)\nprint(\"dc = \",np.mean(dice_coeff))","metadata":{"_uuid":"dbe2efc7-bd48-429d-9984-53887674bd32","_cell_guid":"72170041-32d2-4cee-b233-61f0b80c20f4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure()\nfig.figsize=(50,50)\n\nax=fig.add_subplot(1,2,1)\nax.imshow(np.reshape(y_test[4],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Ground-truth\")\n\nax=fig.add_subplot(1,2,2)\nax.imshow(np.reshape(y_pred[4],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Predicted image\")","metadata":{"_uuid":"dd27fad5-a8e1-4d54-b346-955b159cf61c","_cell_guid":"b65371ba-3f25-475d-96a3-c6fce577f6d5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure()\nfig.figsize=(50,50)\n\nax=fig.add_subplot(1,2,1)\nax.imshow(np.reshape(y_test[2],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Ground-truth\")\n\nax=fig.add_subplot(1,2,2)\nax.imshow(np.reshape(y_pred[2],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Predicted image\")","metadata":{"_uuid":"ef47800a-2de8-4185-bb7c-95dc7415c487","_cell_guid":"9ec7c0bd-21c5-4e2c-8380-e34026155dfc","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"8e841631-db2c-478c-8ec7-bec207d76295","_cell_guid":"1525f6ef-7692-4025-adbd-8c26689a0790","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# HRNET","metadata":{"_uuid":"6eb77f16-d7cf-44e8-8636-49c3f159821e","_cell_guid":"a27ccfeb-4801-4181-ad10-0a8e4ebd6de7","trusted":true}},{"cell_type":"code","source":"import keras.backend as K\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, BatchNormalization, Activation\nfrom keras.layers import UpSampling2D, add, concatenate\n\n\ndef conv3x3(x, out_filters, strides=(1, 1)):\n    x = Conv2D(out_filters, 3, padding='same', strides=strides, use_bias=False, kernel_initializer='he_normal')(x)\n    return x\n\n\ndef basic_Block(input, out_filters, strides=(1, 1), with_conv_shortcut=False):\n    x = conv3x3(input, out_filters, strides)\n    x = BatchNormalization(axis=3)(x)\n    x = Activation('relu')(x)\n\n    x = conv3x3(x, out_filters)\n    x = BatchNormalization(axis=3)(x)\n\n    if with_conv_shortcut:\n        residual = Conv2D(out_filters, 1, strides=strides, use_bias=False, kernel_initializer='he_normal')(input)\n        residual = BatchNormalization(axis=3)(residual)\n        x = add([x, residual])\n    else:\n        x = add([x, input])\n\n    x = Activation('relu')(x)\n    return x\n\n\ndef bottleneck_Block(input, out_filters, strides=(1, 1), with_conv_shortcut=False):\n    expansion = 4\n    de_filters = int(out_filters / expansion)\n\n    x = Conv2D(de_filters, 1, use_bias=False, kernel_initializer='he_normal')(input)\n    x = BatchNormalization(axis=3)(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(de_filters, 3, strides=strides, padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n    x = BatchNormalization(axis=3)(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(out_filters, 1, use_bias=False, kernel_initializer='he_normal')(x)\n    x = BatchNormalization(axis=3)(x)\n\n    if with_conv_shortcut:\n        residual = Conv2D(out_filters, 1, strides=strides, use_bias=False, kernel_initializer='he_normal')(input)\n        residual = BatchNormalization(axis=3)(residual)\n        x = add([x, residual])\n    else:\n        x = add([x, input])\n\n    x = Activation('relu')(x)\n    return x\n\n\ndef stem_net(input):\n    x = Conv2D(64, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(input)\n    x = BatchNormalization(axis=3)(x)\n    x = Activation('relu')(x)\n\n    # x = Conv2D(64, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n    # x = BatchNormalization(axis=3)(x)\n    # x = Activation('relu')(x)\n\n    x = bottleneck_Block(x, 256, with_conv_shortcut=True)\n    x = bottleneck_Block(x, 256, with_conv_shortcut=False)\n    x = bottleneck_Block(x, 256, with_conv_shortcut=False)\n    x = bottleneck_Block(x, 256, with_conv_shortcut=False)\n\n    return x\n\n\ndef transition_layer1(x, out_filters_list=[32, 64]):\n    x0 = Conv2D(out_filters_list[0], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n    x0 = BatchNormalization(axis=3)(x0)\n    x0 = Activation('relu')(x0)\n\n    x1 = Conv2D(out_filters_list[1], 3, strides=(2, 2),\n                padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n    x1 = BatchNormalization(axis=3)(x1)\n    x1 = Activation('relu')(x1)\n\n    return [x0, x1]\n\n\ndef make_branch1_0(x, out_filters=32):\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    return x\n\n\ndef make_branch1_1(x, out_filters=64):\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    return x\n\n\ndef fuse_layer1(x):\n    x0_0 = x[0]\n    x0_1 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[1])\n    x0_1 = BatchNormalization(axis=3)(x0_1)\n    x0_1 = UpSampling2D(size=(2, 2))(x0_1)\n    x0 = add([x0_0, x0_1])\n\n    x1_0 = Conv2D(64, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n    x1_0 = BatchNormalization(axis=3)(x1_0)\n    x1_1 = x[1]\n    x1 = add([x1_0, x1_1])\n    return [x0, x1]\n\n\ndef transition_layer2(x, out_filters_list=[32, 64, 128]):\n    x0 = Conv2D(out_filters_list[0], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n    x0 = BatchNormalization(axis=3)(x0)\n    x0 = Activation('relu')(x0)\n\n    x1 = Conv2D(out_filters_list[1], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[1])\n    x1 = BatchNormalization(axis=3)(x1)\n    x1 = Activation('relu')(x1)\n\n    x2 = Conv2D(out_filters_list[2], 3, strides=(2, 2),\n                padding='same', use_bias=False, kernel_initializer='he_normal')(x[1])\n    x2 = BatchNormalization(axis=3)(x2)\n    x2 = Activation('relu')(x2)\n\n    return [x0, x1, x2]\n\n\ndef make_branch2_0(x, out_filters=32):\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    return x\n\n\ndef make_branch2_1(x, out_filters=64):\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    return x\n\n\ndef make_branch2_2(x, out_filters=128):\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    return x\n\n\ndef fuse_layer2(x):\n    x0_0 = x[0]\n    x0_1 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[1])\n    x0_1 = BatchNormalization(axis=3)(x0_1)\n    x0_1 = UpSampling2D(size=(2, 2))(x0_1)\n    x0_2 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[2])\n    x0_2 = BatchNormalization(axis=3)(x0_2)\n    x0_2 = UpSampling2D(size=(4, 4))(x0_2)\n    x0 = add([x0_0, x0_1, x0_2])\n\n    x1_0 = Conv2D(64, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n    x1_0 = BatchNormalization(axis=3)(x1_0)\n    x1_1 = x[1]\n    x1_2 = Conv2D(64, 1, use_bias=False, kernel_initializer='he_normal')(x[2])\n    x1_2 = BatchNormalization(axis=3)(x1_2)\n    x1_2 = UpSampling2D(size=(2, 2))(x1_2)\n    x1 = add([x1_0, x1_1, x1_2])\n\n    x2_0 = Conv2D(32, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n    x2_0 = BatchNormalization(axis=3)(x2_0)\n    x2_0 = Activation('relu')(x2_0)\n    x2_0 = Conv2D(128, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x2_0)\n    x2_0 = BatchNormalization(axis=3)(x2_0)\n    x2_1 = Conv2D(128, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x[1])\n    x2_1 = BatchNormalization(axis=3)(x2_1)\n    x2_2 = x[2]\n    x2 = add([x2_0, x2_1, x2_2])\n    return [x0, x1, x2]\n\n\ndef transition_layer3(x, out_filters_list=[32, 64, 128, 256]):\n    x0 = Conv2D(out_filters_list[0], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n    x0 = BatchNormalization(axis=3)(x0)\n    x0 = Activation('relu')(x0)\n\n    x1 = Conv2D(out_filters_list[1], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[1])\n    x1 = BatchNormalization(axis=3)(x1)\n    x1 = Activation('relu')(x1)\n\n    x2 = Conv2D(out_filters_list[2], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[2])\n    x2 = BatchNormalization(axis=3)(x2)\n    x2 = Activation('relu')(x2)\n\n    x3 = Conv2D(out_filters_list[3], 3, strides=(2, 2),\n                padding='same', use_bias=False, kernel_initializer='he_normal')(x[2])\n    x3 = BatchNormalization(axis=3)(x3)\n    x3 = Activation('relu')(x3)\n\n    return [x0, x1, x2, x3]\n\n\ndef make_branch3_0(x, out_filters=32):\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    return x\n\n\ndef make_branch3_1(x, out_filters=64):\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    return x\n\n\ndef make_branch3_2(x, out_filters=128):\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    return x\n\n\ndef make_branch3_3(x, out_filters=256):\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n    return x\n\n\ndef fuse_layer3(x):\n    x0_0 = x[0]\n    x0_1 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[1])\n    x0_1 = BatchNormalization(axis=3)(x0_1)\n    x0_1 = UpSampling2D(size=(2, 2))(x0_1)\n    x0_2 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[2])\n    x0_2 = BatchNormalization(axis=3)(x0_2)\n    x0_2 = UpSampling2D(size=(4, 4))(x0_2)\n    x0_3 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[3])\n    x0_3 = BatchNormalization(axis=3)(x0_3)\n    x0_3 = UpSampling2D(size=(8, 8))(x0_3)\n    x0 = concatenate([x0_0, x0_1, x0_2, x0_3], axis=-1)\n    return x0\n\n\ndef final_layer(x, classes=1):\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(classes, 1, use_bias=False, kernel_initializer='he_normal')(x)\n    x = BatchNormalization(axis=3)(x)\n    x = Activation('sigmoid', name='Classification')(x)\n    return x\n\n\ndef seg_hrnet(batch_size, height, width, channel, classes):\n    inputs = Input(batch_shape=(batch_size,) + (height, width, channel))\n\n    x = stem_net(inputs)\n\n    x = transition_layer1(x)\n    x0 = make_branch1_0(x[0])\n    x1 = make_branch1_1(x[1])\n    x = fuse_layer1([x0, x1])\n\n    x = transition_layer2(x)\n    x0 = make_branch2_0(x[0])\n    x1 = make_branch2_1(x[1])\n    x2 = make_branch2_2(x[2])\n    x = fuse_layer2([x0, x1, x2])\n\n    x = transition_layer3(x)\n    x0 = make_branch3_0(x[0])\n    x1 = make_branch3_1(x[1])\n    x2 = make_branch3_2(x[2])\n    x3 = make_branch3_3(x[3])\n    x = fuse_layer3([x0, x1, x2, x3])\n\n    out = final_layer(x, classes=classes)\n\n    model = Model(inputs=inputs, outputs=out)\n\n    return model\n\n\n# from keras.utils import plot_model\n# import os\n# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n#\n\n# plot_model(model, to_file='seg_hrnet.png', show_shapes=True)","metadata":{"_uuid":"914b6cb1-1b5f-4f22-96b5-2c34c9807006","_cell_guid":"a00a288a-d81b-42b0-bf34-f4539a60571c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = seg_hrnet(batch_size=2, height=512, width=512, channel=3, classes=1)\n#model.summary()","metadata":{"_uuid":"e0bc37e5-6aa0-4a99-838f-80a1c8a5de20","_cell_guid":"1f8f6306-7403-4434-b671-13cba67b3d99","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ParallelModelCheckpoint(ModelCheckpoint):\n    def __init__(self,model,filepath, monitor='val_loss', verbose=0,\n                 save_best_only=False, save_weights_only=False,\n                 mode='auto', period=1):\n        self.single_model = model\n        super(ParallelModelCheckpoint,self).__init__(filepath, monitor, verbose,save_best_only, save_weights_only,mode, period)\n\n    def set_model(self, model):\n        super(ParallelModelCheckpoint,self).set_model(self.single_model)","metadata":{"_uuid":"b59c9df8-e813-44e6-b6b3-514177f60449","_cell_guid":"dfb2923d-ad83-4dda-b8bd-a21272048ec9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#paralle_model = multi_gpu_model(model, gpus=4)\nopt = Adam(learning_rate=0.0002)\n\nmodel.compile(optimizer=opt, loss=bce_dice_loss,metrics=[dice_coef,iou_coef, 'accuracy'])\n#model_path = \"seg_hrnet-{epoch:02d}-{val_loss:.4f}-{val_acc:.4f}-{val_iou:.4f}.hdf5\"\n#model_checkpoint = ParallelModelCheckpoint(model, model_path, monitor='val_loss', mode='min', verbose=1, save_best_only=False)","metadata":{"_uuid":"25ec2e9d-8880-4438-b64a-89485697486e","_cell_guid":"77e60b97-c1c8-4715-9b0b-e4a83a978372","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\n\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', patience=10)\nlr_scheduler = LearningRateScheduler(Lr_scheduler, verbose=1)\n\n#reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1, patience=2)\ncheck_point_list = [early_stop, lr_scheduler]","metadata":{"_uuid":"b112937f-0722-46d6-b1f2-93f110aa4b5b","_cell_guid":"1b40529d-eed4-4adf-af33-4027dc20ff6f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = model.fit(\n    train_dataset, validation_data=(x_val,y_val), epochs=50, verbose=1,\n    callbacks=check_point_list)","metadata":{"_uuid":"b993787b-b287-4f3d-b674-e451a31467e1","_cell_guid":"3ac6f6d7-6e18-4590-8df7-668bfd78802e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(result.history['accuracy'] , label = 'train_acc')\nplt.plot(result.history['val_accuracy'] ,'--', label = 'val_acc')\nplt.legend()\nplt.xlabel(\"No. of epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training and Validation Accuracy\")\nplt.show()\n\nplt.plot(result.history['loss'] , label = 'train_loss')\nplt.plot(result.history['val_loss'] ,'--', label = 'val_loss')\nplt.legend()\nplt.xlabel(\"No. of epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss\")\nplt.show()","metadata":{"_uuid":"fa83cf89-12d8-429b-aa63-1fab19323914","_cell_guid":"749521f5-93bb-4c4e-9709-4925e95546bb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_test)\ny_pred = y_pred>0.5","metadata":{"_uuid":"fb74fbd0-52f6-46f6-81b1-2c0af6372731","_cell_guid":"82a65f81-7f80-4ec4-b48d-97b1ffedf8e7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure()\nfig.figsize=(50,50)\n\nax=fig.add_subplot(1,2,1)\nax.imshow(np.reshape(y_test[4],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Ground-truth\")\n\nax=fig.add_subplot(1,2,2)\nax.imshow(np.reshape(y_pred[4],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Predicted image\")","metadata":{"_uuid":"70f62bd5-6ac7-4df3-a5f7-123a69071424","_cell_guid":"ba8d3de6-1dce-4ecf-8542-5a4d1279c00f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nfig.figsize = (30,30)\n\nax = fig.add_subplot(1,2,1)\nax.imshow(np.reshape(y_test[2],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Ground-truth\")\n\nax = fig.add_subplot(1,2,2)\nax.imshow(np.reshape(y_pred[2],(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Predicted image\")","metadata":{"_uuid":"47697678-d135-42f1-ac65-8513ca0c6240","_cell_guid":"9179fb37-9e74-4bd5-acab-ce7f989fc071","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meaniou = MeanIoU(2, name=None, dtype=None)\nmeaniou.update_state(y_test, y_pred)\nprint(\"mean IoU = \",meaniou.result().numpy())\nmeaniou.reset_states()\n\nacc = Accuracy()\nacc.update_state(y_test, y_pred)\nprint(\"acc = \",acc.result().numpy())\nacc.reset_states()\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test.ravel(), y_pred.ravel())\nprint(cm)\n\nfrom sklearn.metrics import classification_report\ncr = classification_report(y_test.ravel(), y_pred.ravel())\nprint(cr)\n\nfrom sklearn.metrics import cohen_kappa_score\nk = cohen_kappa_score(y_test.ravel(), y_pred.ravel())\nprint(\"k = \",k)\n\ndef get_dice(y_true, y_pred):\n\n    intersection = np.sum(y_true * y_pred, axis=(0, 1, 2))\n    union = np.sum(y_true**2, axis=(0, 1, 2)) + np.sum(y_pred**2, axis=(0, 1, 2))\n    dc = 2 * intersection / union\n    return dc\n\ndice_coeff = get_dice(y_test, y_pred)\nprint(\"dc = \",np.mean(dice_coeff))","metadata":{"_uuid":"d4c5178b-75a8-4e92-95d3-52785c87a71b","_cell_guid":"2016396c-0837-4839-b8d6-850ef95f7e21","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"7b2b2ec2-de0a-494c-a08b-5e55f6397274","_cell_guid":"6f249150-19c9-4456-a88c-538dddfe5d33","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}