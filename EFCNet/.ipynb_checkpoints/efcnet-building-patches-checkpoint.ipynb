{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"UNet_Tutorial.ipynb","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7432584,"sourceType":"datasetVersion","datasetId":4325289}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Building Segmentation","metadata":{}},{"cell_type":"code","source":"import glob\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tifffile as tiff\nimport cv2\n\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\nfrom tensorflow.keras.metrics import MeanIoU, Accuracy","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:00.626157Z","iopub.execute_input":"2024-03-12T06:54:00.626996Z","iopub.status.idle":"2024-03-12T06:54:00.682514Z","shell.execute_reply.started":"2024-03-12T06:54:00.62696Z","shell.execute_reply":"2024-03-12T06:54:00.681633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n    except RuntimeError as e:\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:00.795384Z","iopub.execute_input":"2024-03-12T06:54:00.796414Z","iopub.status.idle":"2024-03-12T06:54:00.80338Z","shell.execute_reply.started":"2024-03-12T06:54:00.796378Z","shell.execute_reply":"2024-03-12T06:54:00.802207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:00.988114Z","iopub.execute_input":"2024-03-12T06:54:00.988547Z","iopub.status.idle":"2024-03-12T06:54:00.995307Z","shell.execute_reply.started":"2024-03-12T06:54:00.988512Z","shell.execute_reply":"2024-03-12T06:54:00.994134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n\n# def extract_padded_patches(image, patch_size=(512, 512)):\n#     height, width = image.shape[:2]\n#     patch_height, patch_width = patch_size\n\n#     num_patches_y = (height + patch_height - 1) // patch_height\n#     num_patches_x = (width + patch_width - 1) // patch_width\n\n#     # Calculate padding\n#     pad_y = num_patches_y * patch_height - height\n#     pad_x = num_patches_x * patch_width - width\n\n#     # Pad the image\n#     padded_image = np.pad(image, ((0, pad_y), (0, pad_x), (0, 0)), mode='constant')\n#     #print(padded_image.shape)\n    \n#     # Extract patches\n#     patches = []\n\n#     for y in range(0, num_patches_y * patch_height, patch_height):\n#         for x in range(0, num_patches_x * patch_width, patch_width):\n#             patch = padded_image[y:y+patch_height, x:x+patch_width]\n#             #plt.imshow(patch/255)\n#             patches.append(patch)\n\n#     return np.array(patches)\n\n# #load the .npz file\n# def load_images(path,name, labels):\n#     npzfile=np.load(path+\"{}.npz\".format(name))\n#     images=npzfile['arr_0']\n#     #patches_image=np.zeros()\n#     images =[extract_padded_patches(image, (512, 512)) for image in images]\n#     images = [patch for patches in images for patch in patches]\n\n\n#     npzfile=np.load(path+\"{}.npz\".format(labels))\n#     labels=npzfile['arr_0']\n#     #labels=[color.rgb2gray(resize(x,(512,512),mode='constant', preserve_range=True)) for x in labels]\n    \n#     labels =[extract_padded_patches(image, (512, 512)) for image in labels]\n#     labels = [patch for patches in labels for patch in patches]\n#     labels = np.array(labels)\n#     labels=[cv2.threshold(color.rgb2gray(gt), 128, 1, cv2.THRESH_BINARY)[1] for gt in labels]\n    \n#     return np.array(images),  np.reshape(np.array(labels), (-1, 512, 512, 1))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-12T06:54:01.148537Z","iopub.execute_input":"2024-03-12T06:54:01.148965Z","iopub.status.idle":"2024-03-12T06:54:01.155831Z","shell.execute_reply.started":"2024-03-12T06:54:01.148932Z","shell.execute_reply":"2024-03-12T06:54:01.154594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n\n# # Assume 'patches' is a list of images obtained from extract_padded_patches function\n\n# # Create a figure with subplots\n# fig, axs = plt.subplots(1, len(patches), figsize=(15, 5))\n\n# # Iterate through patches and display them\n# for i, patch in enumerate(patches):\n#     axs[i].imshow(patch/255)\n#     axs[i].axis('off')\n#     axs[i].set_title(f'Patch {i + 1}')\n\n# # Show the plot\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:01.330421Z","iopub.execute_input":"2024-03-12T06:54:01.330829Z","iopub.status.idle":"2024-03-12T06:54:01.335767Z","shell.execute_reply.started":"2024-03-12T06:54:01.330799Z","shell.execute_reply":"2024-03-12T06:54:01.334665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load the .npz file\ndef load_images(path, name, labels):\n    npzfile=np.load(path+\"{}.npz\".format(name))\n    images=npzfile['arr_0']\n\n\n    npzfile=np.load(path+\"{}.npz\".format(labels))\n    labels=npzfile['arr_0']\n\n    return images, labels","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:01.48434Z","iopub.execute_input":"2024-03-12T06:54:01.485359Z","iopub.status.idle":"2024-03-12T06:54:01.491056Z","shell.execute_reply.started":"2024-03-12T06:54:01.485317Z","shell.execute_reply":"2024-03-12T06:54:01.489905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path='/kaggle/input/building-patches-512/'\n\nx_train,y_train = load_images(path,'x_train_patches','y_train_patches')\n\n\nx_val,y_val = load_images(path,'x_val_patches','y_val_patches')\n\n\nx_test,y_test = load_images(path,'x_test_patches','y_test_patches')\n\n\nx_train.sort()\ny_train.sort()\n\nx_val.sort()\ny_val.sort()\n\nx_test.sort()\ny_test.sort()\n\nprint(x_train.shape, y_train.shape, x_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:01.646478Z","iopub.execute_input":"2024-03-12T06:54:01.646847Z","iopub.status.idle":"2024-03-12T06:54:35.343287Z","shell.execute_reply.started":"2024-03-12T06:54:01.646821Z","shell.execute_reply":"2024-03-12T06:54:35.342137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import Sequence\nimport numpy as np \nclass DataGenerator(Sequence):\n    def __init__(self, x_set, y_set, batch_size):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return int(np.ceil(len(self.x) / float(self.batch_size)))\n\n    def __getitem__(self, idx):\n        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n        return batch_x, batch_y\n\ntrain_gen = DataGenerator(x_train, y_train, 16)\nval_gen = DataGenerator(x_val, y_val, 16)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:35.345545Z","iopub.execute_input":"2024-03-12T06:54:35.346341Z","iopub.status.idle":"2024-03-12T06:54:35.355644Z","shell.execute_reply.started":"2024-03-12T06:54:35.346299Z","shell.execute_reply":"2024-03-12T06:54:35.354501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig = plt.figure()\nfig.figsize = (30,30)\n\nax = fig.add_subplot(1,2,1)\nax.imshow(np.reshape(y_train[2]/255,(512,512)),cmap=\"gray\")\nplt.axis('off')\nplt.title(\"Ground-truth\")\n\nax = fig.add_subplot(1,2,2)\nax.imshow(x_train[2]/255)\nplt.axis('off')\nplt.title(\"Actual image\")","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:35.357003Z","iopub.execute_input":"2024-03-12T06:54:35.357442Z","iopub.status.idle":"2024-03-12T06:54:35.721684Z","shell.execute_reply.started":"2024-03-12T06:54:35.357406Z","shell.execute_reply":"2024-03-12T06:54:35.720493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{}},{"cell_type":"code","source":"from keras import backend as K\nfrom keras.losses import binary_crossentropy\nimport tensorflow as tf\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef iou_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n    return iou\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + 0.5 * dice_loss(tf.cast(y_true, tf.float32), y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:35.724857Z","iopub.execute_input":"2024-03-12T06:54:35.725742Z","iopub.status.idle":"2024-03-12T06:54:35.737991Z","shell.execute_reply.started":"2024-03-12T06:54:35.725704Z","shell.execute_reply":"2024-03-12T06:54:35.7369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\ndef create_callbacks():\n    # Reduce learning rate on plateau\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        mode='min',\n        factor=0.5,\n        patience=10,\n        verbose=1,\n        cooldown=1,\n        min_delta=0.0001\n    )\n\n    # Early stopping\n    early_stop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_accuracy',\n        min_delta=0.0001,\n        patience=30,\n        verbose=1,\n        mode='max',\n        restore_best_weights=True\n    )\n\n    # Model checkpoint\n    # Define the path using os.path.join for cross-platform compatibility\n    check_path = os.path.join('.', 'macunet_building.weights.h5')\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        check_path,\n        monitor='val_loss',\n        verbose=1,\n        save_best_only=True,\n        save_weights_only=True,\n        mode='min'\n    )\n\n    return [reduce_lr, early_stop, checkpoint]\n\n# Usage example:\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:35.739247Z","iopub.execute_input":"2024-03-12T06:54:35.739589Z","iopub.status.idle":"2024-03-12T06:54:35.752513Z","shell.execute_reply.started":"2024-03-12T06:54:35.73955Z","shell.execute_reply":"2024-03-12T06:54:35.751575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_history(history):\n    # Accuracy plot\n    plt.plot(history.history['accuracy'], label='train_acc')\n    plt.plot(history.history['val_accuracy'], '--', label='val_acc')\n    plt.legend()\n    plt.xlabel(\"No. of epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(\"Training and Validation Accuracy\")\n    plt.show()\n\n    # Loss plot\n    plt.plot(history.history['loss'], label='train_loss')\n    plt.plot(history.history['val_loss'], '--', label='val_loss')\n    plt.legend()\n    plt.xlabel(\"No. of epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Training and Validation Loss\")\n    plt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:35.754122Z","iopub.execute_input":"2024-03-12T06:54:35.75453Z","iopub.status.idle":"2024-03-12T06:54:35.764663Z","shell.execute_reply.started":"2024-03-12T06:54:35.754494Z","shell.execute_reply":"2024-03-12T06:54:35.763558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score, precision_score, recall_score\n\ndef get_dice(y_true, y_pred):\n    intersection = np.sum(y_true * y_pred, axis=(0, 1, 2))\n    union = np.sum(y_true**2, axis=(0, 1, 2)) + np.sum(y_pred**2, axis=(0, 1, 2))\n    dc = 2 * intersection / union\n    return dc\n\n\ndef evaluate_segmentation(y_test, y_pred):\n    # Mean Intersection over Union\n    mean_iou = MeanIoU(2)\n    mean_iou.update_state(y_test, y_pred)\n    class_iou = mean_iou.result().numpy()\n    mean_iou.reset_states()\n    \n    # Accuracy\n    acc = Accuracy()\n    acc.update_state(y_test, y_pred)\n    accuracy = acc.result().numpy()\n    acc.reset_states()\n    \n    # Precision\n    precision = precision_score(y_test.ravel(), y_pred.ravel(), average='binary')\n    \n    # Recall\n    recall = recall_score(y_test.ravel(), y_pred.ravel(), average='binary')\n    \n    # Confusion Matrix\n    cm = confusion_matrix(y_test.ravel(), y_pred.ravel())\n    \n    # Classification Report\n    cr = classification_report(y_test.ravel(), y_pred.ravel())\n    \n    # Cohen's Kappa Score\n    kappa = cohen_kappa_score(y_test.ravel(), y_pred.ravel())\n    \n    # Dice Coefficient\n    dice_coeff = get_dice(y_test, y_pred)\n    mean_dice_coeff = np.mean(dice_coeff)\n    \n    return {\n        \"mean_iou\": mean_iou,\n        \"class_iou\": class_iou,\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"confusion_matrix\": cm,\n        \"classification_report\": cr,\n        \"cohen_kappa_score\": kappa,\n        \"dice_coefficient\": dice_coeff,\n        \"mean_dice_coefficient\": mean_dice_coeff\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:35.765874Z","iopub.execute_input":"2024-03-12T06:54:35.766161Z","iopub.status.idle":"2024-03-12T06:54:36.183676Z","shell.execute_reply.started":"2024-03-12T06:54:35.766136Z","shell.execute_reply":"2024-03-12T06:54:36.182698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef visualize_predictions(x_test, y_test, y_pred, num_samples=10):\n    fig = plt.figure(figsize=(100, 100))\n\n    for i in range(num_samples):\n        # Plot input image\n        ax = fig.add_subplot(num_samples, 3, 3*i+1)\n        ax.imshow(np.reshape(x_test[i]/255, (512, 512,3)))\n        plt.axis('off')\n        plt.title(\"Input image\")\n\n        # Plot ground truth\n        ax = fig.add_subplot(num_samples, 3, 3*i+2)\n        ax.imshow(np.reshape(y_test[i], (512, 512)), cmap=\"gray\")\n        plt.axis('off')\n        plt.title(\"Ground-truth\")\n\n        # Plot predicted image\n        ax = fig.add_subplot(num_samples, 3, 3*i+3)\n        ax.imshow(np.reshape(y_pred[i], (512, 512)), cmap=\"gray\")\n        plt.axis('off')\n        plt.title(\"Predicted image\")\n\n    plt.tight_layout(pad=0)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:36.184889Z","iopub.execute_input":"2024-03-12T06:54:36.185708Z","iopub.status.idle":"2024-03-12T06:54:36.197659Z","shell.execute_reply.started":"2024-03-12T06:54:36.185657Z","shell.execute_reply":"2024-03-12T06:54:36.196517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **EFC Net**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf                                                                                                                                                   ","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:36.198711Z","iopub.execute_input":"2024-03-12T06:54:36.199021Z","iopub.status.idle":"2024-03-12T06:54:36.210182Z","shell.execute_reply.started":"2024-03-12T06:54:36.198996Z","shell.execute_reply":"2024-03-12T06:54:36.209059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass AFM(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(AFM, self).__init__(**kwargs)\n        # Define the weights for the two-layer neural network\n        self.conv2d3x3elu=tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='elu', padding='same')\n        self.gap=tf.keras.layers.GlobalAveragePooling2D(keepdims=True)\n    def call(self, inputs):\n        x_inputs = self.conv2d3x3elu(inputs)\n        #Global avg Pooling\n        x = self.gap(x_inputs)\n        # Encode features\n        h=tf.keras.Sequential([tf.keras.layers.Dense(x_inputs.shape[-1], activation='relu'),\n                               tf.keras.layers.Dense(x_inputs.shape[-1], activation='sigmoid')])(x)\n\n        # Attention weights\n        weights = tf.math.multiply(h, x_inputs)\n        # Combine and return\n        return tf.reduce_sum(weights, axis=3)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:50:53.645248Z","iopub.execute_input":"2024-03-12T06:50:53.646497Z","iopub.status.idle":"2024-03-12T06:50:53.658789Z","shell.execute_reply.started":"2024-03-12T06:50:53.646455Z","shell.execute_reply":"2024-03-12T06:50:53.657575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SeparableConvBlock(tf.keras.layers.Layer):\n    def __init__(self, filters, depth_activation=tf.nn.elu, pointwise_activation=None, **kwargs):\n        super(SeparableConvBlock, self).__init__(**kwargs)\n        self.depthwise = tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same')\n        self.depth_activation = depth_activation\n        self.pointwise = tf.keras.layers.Conv2D(filters=filters, kernel_size=1, use_bias=False, activation=pointwise_activation, padding='same')\n    \n    def call(self, inputs):\n        x = self.depthwise(inputs)\n        if self.depth_activation:\n            x = self.depth_activation(x)\n        x = self.pointwise(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:50:53.660227Z","iopub.execute_input":"2024-03-12T06:50:53.660632Z","iopub.status.idle":"2024-03-12T06:50:53.671909Z","shell.execute_reply.started":"2024-03-12T06:50:53.660597Z","shell.execute_reply":"2024-03-12T06:50:53.67095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class conv2DElU3x3(tf.keras.layers.Layer):\n    def __init__(self, filters=32):\n        super(conv2DElU3x3, self).__init__()\n        self.conv1=tf.keras.layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', activation=tf.nn.elu)\n        self.conv2=tf.keras.layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', activation=tf.nn.elu)\n        self.filters=filters\n    def call(self, inputs):\n        #print('input shape, filters', inputs.shape, self.filters)\n        x=self.conv1(inputs)\n        #print('conv 1', x.shape)\n        x=self.conv2(x)\n        #print('conv 2', x.shape)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:50:54.219211Z","iopub.execute_input":"2024-03-12T06:50:54.219626Z","iopub.status.idle":"2024-03-12T06:50:54.228657Z","shell.execute_reply.started":"2024-03-12T06:50:54.219594Z","shell.execute_reply":"2024-03-12T06:50:54.227535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv1x1Sigmoid_layer(inputs, num_classes):\n    # Convolutional layer with 1x1 kernel sizeand sigmoid activation\n    x = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='sigmoid', padding='same')(inputs)\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:50:54.894552Z","iopub.execute_input":"2024-03-12T06:50:54.894967Z","iopub.status.idle":"2024-03-12T06:50:54.932726Z","shell.execute_reply.started":"2024-03-12T06:50:54.894932Z","shell.execute_reply":"2024-03-12T06:50:54.931626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(num_classes, image_size=(512, 512, 3)):\n    inputs = tf.keras.Input(shape=image_size)\n    \n    layer1=conv2DElU3x3(32)\n    layer2=conv2DElU3x3(64)\n    layer3=conv2DElU3x3(128)\n    layer4=conv2DElU3x3(256)\n    layer5=conv2DElU3x3(512)\n\n    print('input shape', inputs.shape)\n    layer1_out = layer1(inputs)\n    print('layer1_out shape', layer1_out.shape)\n    out2= conv1x1Sigmoid_layer(layer1_out,1)\n    print('out2 shape', out2.shape)\n    x = tf.keras.layers.MaxPooling2D((2,2))(layer1_out)\n    print('max pool shape', x.shape)\n\n    \n    layer2_out = layer2(x)\n    print('layer2_out shape', layer2_out.shape)\n    x = tf.keras.layers.MaxPooling2D((2,2))(layer2_out)\n    print('max pool shape', x.shape)\n    y4 = tf.keras.layers.UpSampling2D((2,2))(layer2_out)\n    print('up pool shape', y4.shape)\n    \n    layer3_out = layer3(x)\n    print('layer3_out shape', layer3_out.shape)\n    x = tf.keras.layers.MaxPooling2D((2,2))(layer3_out)\n    print('max pool shape', x.shape)\n    y3 = tf.keras.layers.UpSampling2D((2,2))(layer3_out)\n    print('up pool shape', y3.shape)\n    \n    layer4_out = layer4(x)\n    print('layer4_out shape', layer4_out.shape)\n    x = tf.keras.layers.MaxPooling2D((2,2))(layer4_out)\n    print('max pool shape', x.shape)\n    y2 = tf.keras.layers.UpSampling2D((2,2))(layer4_out)\n    print('up pool shape', y2.shape)    \n    \n    layer5_out = layer5(x)\n    print('layer5_out shape', layer5_out.shape)\n    y1 = tf.keras.layers.UpSampling2D((2,2))(layer5_out)\n    print('up pool shape', y1.shape)\n    \n    layer1=conv2DElU3x3(32)\n    layer2=conv2DElU3x3(64)\n    layer3=conv2DElU3x3(128)\n    layer4=conv2DElU3x3(256)\n    \n    con_out = tf.keras.layers.Concatenate()([y1, layer4_out])\n    decoder1_out=layer4(con_out)\n    \n    y6 = tf.keras.layers.UpSampling2D((2,2))(decoder1_out)\n    print('up pool shape', y6.shape)\n    \n    con_out = tf.keras.layers.Concatenate()([y6, layer3_out])\n    decoder2_out=layer3(con_out)\n    \n    y7 = tf.keras.layers.UpSampling2D((2,2))(decoder2_out)\n    print('up pool shape', y7.shape)\n    \n    con_out = tf.keras.layers.Concatenate()([y7, layer2_out])\n    decoder3_out=layer2(con_out)\n    \n    y8 = tf.keras.layers.UpSampling2D((2,2))(decoder3_out)\n    print('up pool shape', y8.shape)\n    \n    con_out = tf.keras.layers.Concatenate()([y8, layer1_out])\n    decoder4_out=layer1(con_out)\n    \n    out1=conv1x1Sigmoid_layer(decoder4_out,1)\n    print('out1 shape', out1.shape)\n    \n    \n    \n    con_out3 = tf.keras.layers.Concatenate()([y2, layer3_out])\n    scm=SeparableConvBlock(128)\n    con_out3=scm(con_out3)\n    y9=tf.keras.layers.UpSampling2D((2,2))(con_out3)\n    \n    con_out4 = tf.keras.layers.Concatenate()([y9, layer2_out])\n    scm=SeparableConvBlock(64)\n    con_out4=scm(con_out4)\n    y10=tf.keras.layers.UpSampling2D((2,2))(con_out4)\n    \n    con_out5 = tf.keras.layers.Concatenate()([y10, layer1_out])\n    scm=SeparableConvBlock(32)\n    con_out5=scm(con_out5)\n    out3=conv1x1Sigmoid_layer(con_out5, 1)\n    print('out3 shape', out3.shape)\n    \n    \n    \n    \n    con_out21 = tf.keras.layers.Concatenate()([y3, layer2_out])\n    scm=SeparableConvBlock(128)\n    con_out21=scm(con_out21)\n    y11=tf.keras.layers.UpSampling2D((2,2))(con_out21)\n    \n    con_out22 = tf.keras.layers.Concatenate()([y11, layer1_out])\n    scm=SeparableConvBlock(64)\n    con_out22=scm(con_out22)\n    out4=conv1x1Sigmoid_layer(con_out22, 1)\n    print('out4 shape', out4.shape)\n    \n    con_out1 = tf.keras.layers.Concatenate()([y4, layer1_out])\n    scm=SeparableConvBlock(32)\n    con_out1=scm(con_out1)\n    out5=conv1x1Sigmoid_layer(con_out1, 1)\n    print('out5 shape', out5.shape)\n    \n    \n    out_concat= tf.keras.layers.Concatenate()([out1, out2, out3,out4,out5])\n    outputs=AFM()(out_concat)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    return model\n    \n  # # Initial block\n \n\n  # # SCM + AFM stages\n  # for filters in [64, 128, 256]:\n  #   x = SeparableConvBlock(filters=filters, depth_activation=tf.nn.elu)(x)\n  #   x = AFM()(x)\n  #   x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n\n  # # Flatten and classification head\n  # x = tf.keras.layers.GlobalAveragePooling2D()(x)\n  # outputs = tf.keras.layers.Dense(num_classes, activation='sigmoid')(x)\n\n ","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:53:30.977616Z","iopub.execute_input":"2024-03-12T06:53:30.978193Z","iopub.status.idle":"2024-03-12T06:53:37.002664Z","shell.execute_reply.started":"2024-03-12T06:53:30.97816Z","shell.execute_reply":"2024-03-12T06:53:37.001557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model= create_model(1, (512, 512, 3))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:50:58.317227Z","iopub.status.idle":"2024-03-12T06:50:58.317612Z","shell.execute_reply.started":"2024-03-12T06:50:58.317432Z","shell.execute_reply":"2024-03-12T06:50:58.317448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.losses import binary_crossentropy\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1\n    intersection = tf.reduce_sum(y_true * y_pred)\n    return 1 - (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=(1e-4)*3)\nmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:53:43.263021Z","iopub.execute_input":"2024-03-12T06:53:43.26354Z","iopub.status.idle":"2024-03-12T06:53:43.279688Z","shell.execute_reply.started":"2024-03-12T06:53:43.263507Z","shell.execute_reply":"2024-03-12T06:53:43.278804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = create_callbacks()\nhistory = model.fit(train_gen, validation_data=val_gen, batch_size=16,shuffle=True, verbose=1\n                                  ,epochs = 100, callbacks = callbacks )\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T06:54:36.213562Z","iopub.execute_input":"2024-03-12T06:54:36.21396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"edgeNetModel.load_weights(\"C:\\\\Users\\\\shyamlal\\\\Documents\\\\Building_Road_Segm\\\\macunet_building.weights.h5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = edgeNetModel.predict(x_test)\ny_pred = y_pred>0.5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred[1]>0.5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_predictions(x_test, y_test, y_pred, num_samples=9)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import *\ngt=(y_test.ravel()).astype('int')\npd=(np.array(y_pred).ravel()).astype('int')\nf1 = f1_score(gt,pd,average='macro')\nkappa = cohen_kappa_score(gt,pd)\naccuracy = accuracy_score(gt,pd)\njaccard = jaccard_score(gt,pd,average='macro')\nprecision = precision_score(gt,pd,average='macro')\nrecall = recall_score(gt,pd,average='macro')\n#print(np.unique(gt),np.unique(pd))\nprint(\"F1 SCORE:\", f1)\nprint(\"Kappa:\",kappa)\nprint(\"Accuracy:\",accuracy)\nprint(\"Jaccard Score:\",jaccard)\nprint(\"Precision:\",precision)\nprint(\"Recall:\",recall)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **CTMU_Net**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nclass LipPooling(tf.keras.layers.Layer):\n    def __init__(self, filters=1):\n        super(LipPooling, self).__init__()\n        self.conv1=tf.keras.layers.Conv2D(filters, 3, padding='valid')\n        self.batch_norm=tf.keras.layers.BatchNormalization()\n        self.window_size=(3,3)\n    def call(inputs):\n        x=self.conv1(inputs)\n        x=self.batch_norm(x)\n        x=tf.keras.activations.sigmoid(x)\n        e_x=tf.keras.activations.exponential(x)\n        m_x= inputs*e_x\n        e_x=tf.nn.pool(e_x, self.window_size, pooling_type='SUM', padding='VALID')\n        m_x=tf.nn.pool(m_x, self.window_size, pooling_type='SUM', padding='VALID')\n        x=tf.divide(m_x, e_x+1e-8)\n\n        return x      ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def channel_attention(input_feature, ratio=8):\n\t\n\tchannel_axis = -1\n\tchannel = input_feature._keras_shape[channel_axis]\n\t\n\tshared_layer_one = Dense(channel//ratio,\n\t\t\t\t\t\t\t activation='relu',\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\tshared_layer_two = Dense(channel,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\t\n\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n\tavg_pool = Reshape((1,1,channel))(avg_pool)\n\tassert avg_pool._keras_shape[1:] == (1,1,channel)\n\tavg_pool = shared_layer_one(avg_pool)\n\tassert avg_pool._keras_shape[1:] == (1,1,channel//ratio)\n\tavg_pool = shared_layer_two(avg_pool)\n\tassert avg_pool._keras_shape[1:] == (1,1,channel)\n\t\n\tmax_pool = GlobalMaxPooling2D()(input_feature)\n\tmax_pool = Reshape((1,1,channel))(max_pool)\n\tassert max_pool._keras_shape[1:] == (1,1,channel)\n\tmax_pool = shared_layer_one(max_pool)\n\tassert max_pool._keras_shape[1:] == (1,1,channel//ratio)\n\tmax_pool = shared_layer_two(max_pool)\n\tassert max_pool._keras_shape[1:] == (1,1,channel)\n\t\n\tcbam_feature = Add()([avg_pool,max_pool])\n\tcbam_feature = Activation('sigmoid')(cbam_feature)\n\t\n\t# if K.image_data_format() == \"channels_first\":\n\t# \tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\n\treturn multiply([input_feature, cbam_feature])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CTM module\n\nimport tensorflow as tf\n\ndef get_row_attention(q, k, f):\n  \"\"\"\n  Calculates row attention based on Q, K, and F feature maps.\n\n  Args:\n    q: A tensor of shape (batch_size, height, width, reduced_channels).\n    k: A tensor of the same shape as q.\n    f: A tensor of shape (batch_size, height, width, channels).\n\n  Returns:\n    A tensor of shape (batch_size, height, width, channels).\n  \"\"\"\n  \n  # Get dimensions\n  batch_size, height, width, reduced_channels = q.shape\n  channels = f.shape[-1]\n\n  # Calculate correlations\n  correlations = tf.matmul(q, tf.transpose(k))  # (batch_size, H, W, H)\n  correlations = tf.nn.softmax(correlations, axis=-1)  # (batch_size, H, W, H)\n\n  # Generate V feature map\n  v = tf.keras.layers.Conv2D(channels, kernel_size=1, activation=None, padding='same')(f)\n\n  # Calculate row attention scores\n  row_attention = []\n  for i in range(height):\n    # Extract relevant feature vectors for row i\n    qi = q[:, i, :, :]  # (batch_size, 1, W, reduced_channels)\n    ki = k[:, i, :, :]  # (batch_size, W, reduced_channels)\n    vi = v[:, i, :, :]  # (batch_size, 1, W, channels)\n    phi_i = k[:, :, i, :]  # (batch_size, W, channels)\n\n    # Calculate attention for row i\n    row_i_attention = tf.reduce_sum(correlations[:, i, :, :] * phi_i, axis=1) + vi\n    row_attention.append(row_i_attention)\n  row_attention = tf.stack(row_attention, axis=1)  # (batch_size, H, W, channels)\n\n  return row_attention\n\n# # Example usage (assuming Q, K, and F are defined elsewhere)\n# row_attention = get_row_attention(q, k, f)\n# print(f\"Row attention shape: {row_attention.shape}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\ndef get_column_attention(yrow, q, k, f):\n  \"\"\"\n  Calculates column attention based on Yrow, Q, K, and F feature maps.\n\n  Args:\n    yrow: A tensor of shape (batch_size, height, width, channels).\n    q: A tensor of the same shape as yrow.\n    k: A tensor of the same shape as q.\n    f: A tensor of shape (batch_size, height, width, channels).\n\n  Returns:\n    A tensor of shape (batch_size, height, width, channels).\n  \"\"\"\n  \n  # Get dimensions\n  batch_size, height, width, channels = yrow.shape\n\n  # Calculate correlations\n  correlations = tf.matmul(yrow, tf.transpose(k, perm=[0, 2, 1, 3]))  # (batch_size, H, W, C)\n  correlations = tf.nn.softmax(correlations, axis=-1)  # (batch_size, H, W, C)\n\n  # Calculate column attention scores\n  column_attention = []\n  for i in range(width):\n    # Extract relevant feature vectors for column i\n    yrow_i = yrow[:, :, i, :]  # (batch_size, H, 1, channels)\n    ki = k[:, :, i, :]  # (batch_size, H, channels)\n    fi = f[:, :, i, :]  # (batch_size, H, 1, channels)\n    phi_col_i = k[:, :, :, i]  # (batch_size, H, channels)\n\n    # Calculate attention for column i\n    col_i_attention = tf.reduce_sum(correlations[:, :, i, :] * phi_col_i, axis=-1) + fi\n    column_attention.append(col_i_attention)\n  column_attention = tf.stack(column_attention, axis=2)  # (batch_size, H, W, channels)\n\n  return column_attention\n\n# # Example usage (assuming Yrow, Q, K, and F are defined elsewhere)\n# column_attention = get_column_attention(yrow, q, k, f)\n# print(f\"Column attention shape: {column_attention.shape}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (4, 512, 512, 3)\ninputs= tf.keras.Input(shape=(512, 512, 3))\n# row attention\nx=tf.keras.layers.Conv2D(16,1, activation='relu', padding='same',input_shape=input_shape[1:])(inputs)\n\nq=tf.keras.layers.Conv2D(16,1, activation='relu', padding='same')(x)\nk=q\nf=x\nyrow= get_row_attention(q,k,f)\n# column attention\nq=tf.keras.layers.Conv2D(512,1, activation='relu', padding='same')(yrow)\nk=q\nf=yrow\noutput= get_column_attention(yrow,q,k,f)\n\nmodel=tf.keras.Model(inputs=inputs, outputs=output)\n\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"?tf.keras.layers.Conv2D","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_patches(feature_map, patch_size=4):\n    patches=tf.image.extract_patches(images=feature_map, \n                                     sizes=[1, patch_size, patch_size,1],\n                                     strides=[1, patch_size, patch_size,1],\n                                    padding='VALID')\n    return patches","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=DPM_UNet((512,512,3))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = Adam(learning_rate=0.001)\nmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', iou_coef])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = create_callbacks()\nhistory = model.fit(train_gen, validation_data=val_gen, batch_size=4,shuffle=True, verbose=1\n                                  ,epochs = 100, callbacks = callbacks )\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = dppnetmodel.predict(x_test)\ny_pred = y_pred>0.5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_predictions(x_test, y_test, y_pred, num_samples=9)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('C:\\\\Users\\\\Admin\\\\Documents\\\\road_segmentation\\\\dpp_ROAD.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predicted=[]\nfor i in range(len(x_test)):\n    image= np.expand_dims(x_test[i], axis=0)\n\n    y_pred = dppnetmodel.predict(image)\n    y_pred=y_pred>0.5\n    y_predicted.append(y_pred)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import *\ngt=(y_test.ravel()).astype('int')\npd=(np.array(y_predicted).ravel()).astype('int')\nf1 = f1_score(gt,pd,average='macro')\nkappa = cohen_kappa_score(gt,pd)\naccuracy = accuracy_score(gt,pd)\njaccard = jaccard_score(gt,pd,average='macro')\nprecision = precision_score(gt,pd,average='macro')\nrecall = recall_score(gt,pd,average='macro')\nprint(np.unique(gt),np.unique(pd))\nprint(\"F1 SCORE:\", f1)\nprint(\"Kappa:\",kappa)\nprint(\"Accuracy:\",accuracy)\nprint(\"Jaccard Score:\",jaccard)\nprint(\"Precision:\",precision)\nprint(\"Recall:\",recall)\n","metadata":{},"execution_count":null,"outputs":[]}]}